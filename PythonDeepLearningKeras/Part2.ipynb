{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ch01. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- underfitting\n",
    "- overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- hyperparameter\n",
    "  - 학습 방법을 결정하는 파라미터\n",
    "  - validation  set으로 튜닝\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- overfitting 현상으로 간주\n",
    "  - training set의 평가는 오류가 낮아지지만\n",
    "  - validation set의 평가는 오류가 높아지는 현상 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cross-validation: 교차 검증\n",
    "  - 적용 방법\n",
    "    - 1차: data1, data2, data3, data4, (data5)\n",
    "    - 2차: data1, data2, data3, (data4), data5\n",
    "    - 3차: data1, data2, (data3), data4, data5\n",
    "    - 4차: data1, (data2), data3, data4, data5\n",
    "    - 5차: (data1), data2, data3, data4, data5\n",
    "    - 평균으로 검증\n",
    "    - 각회차에서 학습 결과는 초기화 시킴\n",
    "  - 데이터가 많지 않을 경우에 사용 함 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ch02. 학습과정 이야기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "model.fit(x, y, batch_size=32, epoch=10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ch03. 학습과정 살펴보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "hist = model.fit(x_train, y_train, epochs=5, batch_size=32)\n",
    "hist.history['loss']\n",
    "hist.history['acc']\n",
    "hist.history['val_loss']\n",
    "hist.history['val_acc']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- loss: epoch 별 훈련 손실값\n",
    "- acc:  epoch 별 훈련 정확도\n",
    "- val_loss: epoch 별 검증 손실값\n",
    "- val_acc: epoch 별 검증 정확도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 과정 모니터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training/Test/Validation Set 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[50000:]\n",
    "y_val = y_train[50000:]\n",
    "x_train = x_train[:50000]\n",
    "y_train = y_train[:50000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((50000, 28*28)).astype(\"float\")/255.0\n",
    "x_val = x_val.reshape((10000, 28*28)).astype(\"float\")/255.0\n",
    "x_test = x_test.reshape((10000, 28*28)).astype('float')/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 훈련셋과 검승셋 고르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rand_index = np.random.choice(50000, 700)\n",
    "val_rand_index = np.random.choice(10000, 300)\n",
    "x_train = x_train[train_rand_index]\n",
    "y_train = y_train[train_rand_index]\n",
    "x_val = x_val[val_rand_index]\n",
    "y_val = y_val[val_rand_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 라벨 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_val = np_utils.to_categorical(y_val)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=64, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 학습과정 설정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "700/700 [==============================] - 0s 267us/step - loss: 2.1192 - acc: 0.2929 - val_loss: 1.9095 - val_acc: 0.4467\n",
      "Epoch 2/1000\n",
      "700/700 [==============================] - 0s 182us/step - loss: 1.6806 - acc: 0.5886 - val_loss: 1.5444 - val_acc: 0.6267\n",
      "Epoch 3/1000\n",
      "700/700 [==============================] - 0s 157us/step - loss: 1.3294 - acc: 0.7229 - val_loss: 1.2420 - val_acc: 0.7400\n",
      "Epoch 4/1000\n",
      "700/700 [==============================] - 0s 153us/step - loss: 1.0708 - acc: 0.8000 - val_loss: 1.0379 - val_acc: 0.7633\n",
      "Epoch 5/1000\n",
      "700/700 [==============================] - 0s 162us/step - loss: 0.8955 - acc: 0.8300 - val_loss: 0.9051 - val_acc: 0.7700\n",
      "Epoch 6/1000\n",
      "700/700 [==============================] - 0s 153us/step - loss: 0.7695 - acc: 0.8514 - val_loss: 0.8144 - val_acc: 0.7933\n",
      "Epoch 7/1000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 0.6783 - acc: 0.8729 - val_loss: 0.7430 - val_acc: 0.8033\n",
      "Epoch 8/1000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 0.6074 - acc: 0.8814 - val_loss: 0.6849 - val_acc: 0.8033\n",
      "Epoch 9/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 0.5550 - acc: 0.8786 - val_loss: 0.6474 - val_acc: 0.8100\n",
      "Epoch 10/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 0.5093 - acc: 0.8986 - val_loss: 0.6199 - val_acc: 0.8200\n",
      "Epoch 11/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 0.4707 - acc: 0.8900 - val_loss: 0.5956 - val_acc: 0.8200\n",
      "Epoch 12/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 0.4392 - acc: 0.9071 - val_loss: 0.5767 - val_acc: 0.8300\n",
      "Epoch 13/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 0.4125 - acc: 0.9100 - val_loss: 0.5606 - val_acc: 0.8267\n",
      "Epoch 14/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 0.3891 - acc: 0.9171 - val_loss: 0.5397 - val_acc: 0.8367\n",
      "Epoch 15/1000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 0.3686 - acc: 0.9286 - val_loss: 0.5292 - val_acc: 0.8467\n",
      "Epoch 16/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 0.3465 - acc: 0.9371 - val_loss: 0.5228 - val_acc: 0.8467\n",
      "Epoch 17/1000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 0.3308 - acc: 0.9386 - val_loss: 0.5123 - val_acc: 0.8533\n",
      "Epoch 18/1000\n",
      "700/700 [==============================] - 0s 153us/step - loss: 0.3141 - acc: 0.9414 - val_loss: 0.5104 - val_acc: 0.8500\n",
      "Epoch 19/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 0.3005 - acc: 0.9500 - val_loss: 0.4989 - val_acc: 0.8533\n",
      "Epoch 20/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 0.2855 - acc: 0.9471 - val_loss: 0.4968 - val_acc: 0.8367\n",
      "Epoch 21/1000\n",
      "700/700 [==============================] - 0s 164us/step - loss: 0.2712 - acc: 0.9514 - val_loss: 0.5101 - val_acc: 0.8333\n",
      "Epoch 22/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 0.2623 - acc: 0.9529 - val_loss: 0.4843 - val_acc: 0.8500\n",
      "Epoch 23/1000\n",
      "700/700 [==============================] - 0s 163us/step - loss: 0.2508 - acc: 0.9557 - val_loss: 0.4833 - val_acc: 0.8500\n",
      "Epoch 24/1000\n",
      "700/700 [==============================] - 0s 156us/step - loss: 0.2404 - acc: 0.9614 - val_loss: 0.4832 - val_acc: 0.8467\n",
      "Epoch 25/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 0.2308 - acc: 0.9614 - val_loss: 0.4766 - val_acc: 0.8500\n",
      "Epoch 26/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 0.2222 - acc: 0.9629 - val_loss: 0.4750 - val_acc: 0.8533\n",
      "Epoch 27/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 0.2139 - acc: 0.9671 - val_loss: 0.4708 - val_acc: 0.8533\n",
      "Epoch 28/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 0.2040 - acc: 0.9657 - val_loss: 0.4732 - val_acc: 0.8500\n",
      "Epoch 29/1000\n",
      "700/700 [==============================] - 0s 157us/step - loss: 0.1979 - acc: 0.9686 - val_loss: 0.4724 - val_acc: 0.8500\n",
      "Epoch 30/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 0.1905 - acc: 0.9714 - val_loss: 0.4695 - val_acc: 0.8533\n",
      "Epoch 31/1000\n",
      "700/700 [==============================] - 0s 153us/step - loss: 0.1827 - acc: 0.9714 - val_loss: 0.4704 - val_acc: 0.8500\n",
      "Epoch 32/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 0.1770 - acc: 0.9743 - val_loss: 0.4698 - val_acc: 0.8500\n",
      "Epoch 33/1000\n",
      "700/700 [==============================] - 0s 157us/step - loss: 0.1709 - acc: 0.9757 - val_loss: 0.4688 - val_acc: 0.8500\n",
      "Epoch 34/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 0.1652 - acc: 0.9757 - val_loss: 0.4659 - val_acc: 0.8533\n",
      "Epoch 35/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 0.1594 - acc: 0.9743 - val_loss: 0.4677 - val_acc: 0.8567\n",
      "Epoch 36/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 0.1555 - acc: 0.9757 - val_loss: 0.4637 - val_acc: 0.8533\n",
      "Epoch 37/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 0.1480 - acc: 0.9771 - val_loss: 0.4682 - val_acc: 0.8500\n",
      "Epoch 38/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 0.1445 - acc: 0.9757 - val_loss: 0.4676 - val_acc: 0.8533\n",
      "Epoch 39/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 0.1391 - acc: 0.9786 - val_loss: 0.4615 - val_acc: 0.8600\n",
      "Epoch 40/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 0.1353 - acc: 0.9771 - val_loss: 0.4667 - val_acc: 0.8533\n",
      "Epoch 41/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.1317 - acc: 0.9814 - val_loss: 0.4658 - val_acc: 0.8533\n",
      "Epoch 42/1000\n",
      "700/700 [==============================] - 0s 161us/step - loss: 0.1271 - acc: 0.9829 - val_loss: 0.4718 - val_acc: 0.8567\n",
      "Epoch 43/1000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 0.1238 - acc: 0.9771 - val_loss: 0.4668 - val_acc: 0.8533\n",
      "Epoch 44/1000\n",
      "700/700 [==============================] - 0s 153us/step - loss: 0.1195 - acc: 0.9843 - val_loss: 0.4757 - val_acc: 0.8533\n",
      "Epoch 45/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 0.1164 - acc: 0.9857 - val_loss: 0.4659 - val_acc: 0.8600\n",
      "Epoch 46/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 0.1132 - acc: 0.9829 - val_loss: 0.4699 - val_acc: 0.8533\n",
      "Epoch 47/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 0.1094 - acc: 0.9843 - val_loss: 0.4670 - val_acc: 0.8600\n",
      "Epoch 48/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 0.1062 - acc: 0.9886 - val_loss: 0.4703 - val_acc: 0.8500\n",
      "Epoch 49/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 0.1040 - acc: 0.9886 - val_loss: 0.4671 - val_acc: 0.8567\n",
      "Epoch 50/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 0.1005 - acc: 0.9886 - val_loss: 0.4659 - val_acc: 0.8633\n",
      "Epoch 51/1000\n",
      "700/700 [==============================] - 0s 156us/step - loss: 0.0976 - acc: 0.9914 - val_loss: 0.4654 - val_acc: 0.8633\n",
      "Epoch 52/1000\n",
      "700/700 [==============================] - 0s 164us/step - loss: 0.0951 - acc: 0.9900 - val_loss: 0.4694 - val_acc: 0.8567\n",
      "Epoch 53/1000\n",
      "700/700 [==============================] - 0s 168us/step - loss: 0.0926 - acc: 0.9929 - val_loss: 0.4692 - val_acc: 0.8600\n",
      "Epoch 54/1000\n",
      "700/700 [==============================] - 0s 161us/step - loss: 0.0904 - acc: 0.9929 - val_loss: 0.4700 - val_acc: 0.8567\n",
      "Epoch 55/1000\n",
      "700/700 [==============================] - 0s 157us/step - loss: 0.0873 - acc: 0.9914 - val_loss: 0.4715 - val_acc: 0.8633\n",
      "Epoch 56/1000\n",
      "700/700 [==============================] - 0s 167us/step - loss: 0.0857 - acc: 0.9929 - val_loss: 0.4739 - val_acc: 0.8567\n",
      "Epoch 57/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 0.0832 - acc: 0.9943 - val_loss: 0.4717 - val_acc: 0.8600\n",
      "Epoch 58/1000\n",
      "700/700 [==============================] - 0s 169us/step - loss: 0.0815 - acc: 0.9914 - val_loss: 0.4747 - val_acc: 0.8567\n",
      "Epoch 59/1000\n",
      "700/700 [==============================] - 0s 166us/step - loss: 0.0791 - acc: 0.9943 - val_loss: 0.4727 - val_acc: 0.8600\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 173us/step - loss: 0.0771 - acc: 0.9943 - val_loss: 0.4768 - val_acc: 0.8533\n",
      "Epoch 61/1000\n",
      "700/700 [==============================] - 0s 164us/step - loss: 0.0756 - acc: 0.9929 - val_loss: 0.4758 - val_acc: 0.8567\n",
      "Epoch 62/1000\n",
      "700/700 [==============================] - 0s 165us/step - loss: 0.0736 - acc: 0.9957 - val_loss: 0.4766 - val_acc: 0.8567\n",
      "Epoch 63/1000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 0.0722 - acc: 0.9957 - val_loss: 0.4761 - val_acc: 0.8600\n",
      "Epoch 64/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0702 - acc: 0.9971 - val_loss: 0.4744 - val_acc: 0.8600\n",
      "Epoch 65/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0685 - acc: 0.9971 - val_loss: 0.4769 - val_acc: 0.8600\n",
      "Epoch 66/1000\n",
      "700/700 [==============================] - 0s 169us/step - loss: 0.0668 - acc: 0.9986 - val_loss: 0.4811 - val_acc: 0.8633\n",
      "Epoch 67/1000\n",
      "700/700 [==============================] - 0s 171us/step - loss: 0.0655 - acc: 0.9971 - val_loss: 0.4763 - val_acc: 0.8633\n",
      "Epoch 68/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 0.0641 - acc: 0.9971 - val_loss: 0.4800 - val_acc: 0.8600\n",
      "Epoch 69/1000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 0.0626 - acc: 0.9986 - val_loss: 0.4803 - val_acc: 0.8633\n",
      "Epoch 70/1000\n",
      "700/700 [==============================] - 0s 181us/step - loss: 0.0612 - acc: 0.9971 - val_loss: 0.4819 - val_acc: 0.8633\n",
      "Epoch 71/1000\n",
      "700/700 [==============================] - 0s 168us/step - loss: 0.0598 - acc: 0.9971 - val_loss: 0.4792 - val_acc: 0.8600\n",
      "Epoch 72/1000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 0.0585 - acc: 0.9971 - val_loss: 0.4816 - val_acc: 0.8633\n",
      "Epoch 73/1000\n",
      "700/700 [==============================] - 0s 174us/step - loss: 0.0574 - acc: 0.9971 - val_loss: 0.4765 - val_acc: 0.8733\n",
      "Epoch 74/1000\n",
      "700/700 [==============================] - 0s 172us/step - loss: 0.0563 - acc: 0.9971 - val_loss: 0.4815 - val_acc: 0.8600\n",
      "Epoch 75/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 0.0550 - acc: 1.0000 - val_loss: 0.4799 - val_acc: 0.8633\n",
      "Epoch 76/1000\n",
      "700/700 [==============================] - 0s 180us/step - loss: 0.0540 - acc: 0.9986 - val_loss: 0.4849 - val_acc: 0.8633\n",
      "Epoch 77/1000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 0.0527 - acc: 0.9986 - val_loss: 0.4837 - val_acc: 0.8633\n",
      "Epoch 78/1000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 0.0519 - acc: 1.0000 - val_loss: 0.4841 - val_acc: 0.8667\n",
      "Epoch 79/1000\n",
      "700/700 [==============================] - 0s 176us/step - loss: 0.0507 - acc: 1.0000 - val_loss: 0.4829 - val_acc: 0.8633\n",
      "Epoch 80/1000\n",
      "700/700 [==============================] - 0s 168us/step - loss: 0.0496 - acc: 0.9986 - val_loss: 0.4841 - val_acc: 0.8667\n",
      "Epoch 81/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0490 - acc: 1.0000 - val_loss: 0.4862 - val_acc: 0.8700\n",
      "Epoch 82/1000\n",
      "700/700 [==============================] - 0s 196us/step - loss: 0.0480 - acc: 1.0000 - val_loss: 0.4896 - val_acc: 0.8633\n",
      "Epoch 83/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 0.0471 - acc: 1.0000 - val_loss: 0.4879 - val_acc: 0.8633\n",
      "Epoch 84/1000\n",
      "700/700 [==============================] - 0s 192us/step - loss: 0.0461 - acc: 1.0000 - val_loss: 0.4885 - val_acc: 0.8600\n",
      "Epoch 85/1000\n",
      "700/700 [==============================] - 0s 184us/step - loss: 0.0449 - acc: 1.0000 - val_loss: 0.4903 - val_acc: 0.8633\n",
      "Epoch 86/1000\n",
      "700/700 [==============================] - 0s 197us/step - loss: 0.0447 - acc: 1.0000 - val_loss: 0.4895 - val_acc: 0.8667\n",
      "Epoch 87/1000\n",
      "700/700 [==============================] - 0s 239us/step - loss: 0.0438 - acc: 1.0000 - val_loss: 0.4895 - val_acc: 0.8667\n",
      "Epoch 88/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 0.0430 - acc: 1.0000 - val_loss: 0.4891 - val_acc: 0.8600\n",
      "Epoch 89/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 0.0422 - acc: 1.0000 - val_loss: 0.4907 - val_acc: 0.8600\n",
      "Epoch 90/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 0.0416 - acc: 1.0000 - val_loss: 0.4912 - val_acc: 0.8700\n",
      "Epoch 91/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 0.0410 - acc: 1.0000 - val_loss: 0.4919 - val_acc: 0.8667\n",
      "Epoch 92/1000\n",
      "700/700 [==============================] - 0s 208us/step - loss: 0.0403 - acc: 1.0000 - val_loss: 0.4906 - val_acc: 0.8667\n",
      "Epoch 93/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 0.0395 - acc: 1.0000 - val_loss: 0.4923 - val_acc: 0.8700\n",
      "Epoch 94/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 0.0389 - acc: 1.0000 - val_loss: 0.4925 - val_acc: 0.8667\n",
      "Epoch 95/1000\n",
      "700/700 [==============================] - 0s 195us/step - loss: 0.0382 - acc: 1.0000 - val_loss: 0.4914 - val_acc: 0.8633\n",
      "Epoch 96/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 0.0377 - acc: 1.0000 - val_loss: 0.4942 - val_acc: 0.8667\n",
      "Epoch 97/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 0.0370 - acc: 1.0000 - val_loss: 0.4954 - val_acc: 0.8633\n",
      "Epoch 98/1000\n",
      "700/700 [==============================] - 0s 201us/step - loss: 0.0364 - acc: 1.0000 - val_loss: 0.4970 - val_acc: 0.8600\n",
      "Epoch 99/1000\n",
      "700/700 [==============================] - 0s 179us/step - loss: 0.0359 - acc: 1.0000 - val_loss: 0.4972 - val_acc: 0.8633\n",
      "Epoch 100/1000\n",
      "700/700 [==============================] - 0s 201us/step - loss: 0.0352 - acc: 1.0000 - val_loss: 0.4981 - val_acc: 0.8633\n",
      "Epoch 101/1000\n",
      "700/700 [==============================] - 0s 195us/step - loss: 0.0349 - acc: 1.0000 - val_loss: 0.4983 - val_acc: 0.8633\n",
      "Epoch 102/1000\n",
      "700/700 [==============================] - 0s 201us/step - loss: 0.0343 - acc: 1.0000 - val_loss: 0.4977 - val_acc: 0.8667\n",
      "Epoch 103/1000\n",
      "700/700 [==============================] - 0s 178us/step - loss: 0.0338 - acc: 1.0000 - val_loss: 0.4987 - val_acc: 0.8700\n",
      "Epoch 104/1000\n",
      "700/700 [==============================] - 0s 191us/step - loss: 0.0333 - acc: 1.0000 - val_loss: 0.4999 - val_acc: 0.8667\n",
      "Epoch 105/1000\n",
      "700/700 [==============================] - 0s 188us/step - loss: 0.0328 - acc: 1.0000 - val_loss: 0.4990 - val_acc: 0.8667\n",
      "Epoch 106/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 0.0324 - acc: 1.0000 - val_loss: 0.4998 - val_acc: 0.8633\n",
      "Epoch 107/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 0.0319 - acc: 1.0000 - val_loss: 0.5000 - val_acc: 0.8633\n",
      "Epoch 108/1000\n",
      "700/700 [==============================] - 0s 193us/step - loss: 0.0313 - acc: 1.0000 - val_loss: 0.4994 - val_acc: 0.8667\n",
      "Epoch 109/1000\n",
      "700/700 [==============================] - 0s 203us/step - loss: 0.0310 - acc: 1.0000 - val_loss: 0.5004 - val_acc: 0.8700\n",
      "Epoch 110/1000\n",
      "700/700 [==============================] - 0s 207us/step - loss: 0.0305 - acc: 1.0000 - val_loss: 0.5024 - val_acc: 0.8667\n",
      "Epoch 111/1000\n",
      "700/700 [==============================] - 0s 205us/step - loss: 0.0302 - acc: 1.0000 - val_loss: 0.5023 - val_acc: 0.8667\n",
      "Epoch 112/1000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 0.0297 - acc: 1.0000 - val_loss: 0.4999 - val_acc: 0.8667\n",
      "Epoch 113/1000\n",
      "700/700 [==============================] - 0s 216us/step - loss: 0.0294 - acc: 1.0000 - val_loss: 0.5017 - val_acc: 0.8667\n",
      "Epoch 114/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 0.0288 - acc: 1.0000 - val_loss: 0.5028 - val_acc: 0.8667\n",
      "Epoch 115/1000\n",
      "700/700 [==============================] - 0s 208us/step - loss: 0.0284 - acc: 1.0000 - val_loss: 0.5059 - val_acc: 0.8667\n",
      "Epoch 116/1000\n",
      "700/700 [==============================] - 0s 193us/step - loss: 0.0282 - acc: 1.0000 - val_loss: 0.5043 - val_acc: 0.8667\n",
      "Epoch 117/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 0.0277 - acc: 1.0000 - val_loss: 0.5063 - val_acc: 0.8667\n",
      "Epoch 118/1000\n",
      "700/700 [==============================] - 0s 188us/step - loss: 0.0274 - acc: 1.0000 - val_loss: 0.5071 - val_acc: 0.8667\n",
      "Epoch 119/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0270 - acc: 1.0000 - val_loss: 0.5073 - val_acc: 0.8667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "700/700 [==============================] - 0s 212us/step - loss: 0.0267 - acc: 1.0000 - val_loss: 0.5063 - val_acc: 0.8667\n",
      "Epoch 121/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 0.0264 - acc: 1.0000 - val_loss: 0.5060 - val_acc: 0.8667\n",
      "Epoch 122/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 0.0261 - acc: 1.0000 - val_loss: 0.5072 - val_acc: 0.8667\n",
      "Epoch 123/1000\n",
      "700/700 [==============================] - 0s 200us/step - loss: 0.0257 - acc: 1.0000 - val_loss: 0.5084 - val_acc: 0.8667\n",
      "Epoch 124/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 0.0254 - acc: 1.0000 - val_loss: 0.5104 - val_acc: 0.8667\n",
      "Epoch 125/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 0.0251 - acc: 1.0000 - val_loss: 0.5083 - val_acc: 0.8667\n",
      "Epoch 126/1000\n",
      "700/700 [==============================] - 0s 195us/step - loss: 0.0248 - acc: 1.0000 - val_loss: 0.5101 - val_acc: 0.8700\n",
      "Epoch 127/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 0.0245 - acc: 1.0000 - val_loss: 0.5104 - val_acc: 0.8667\n",
      "Epoch 128/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 0.0242 - acc: 1.0000 - val_loss: 0.5090 - val_acc: 0.8700\n",
      "Epoch 129/1000\n",
      "700/700 [==============================] - 0s 196us/step - loss: 0.0240 - acc: 1.0000 - val_loss: 0.5095 - val_acc: 0.8700\n",
      "Epoch 130/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 0.0235 - acc: 1.0000 - val_loss: 0.5109 - val_acc: 0.8667\n",
      "Epoch 131/1000\n",
      "700/700 [==============================] - 0s 208us/step - loss: 0.0235 - acc: 1.0000 - val_loss: 0.5111 - val_acc: 0.8700\n",
      "Epoch 132/1000\n",
      "700/700 [==============================] - 0s 203us/step - loss: 0.0231 - acc: 1.0000 - val_loss: 0.5111 - val_acc: 0.8667\n",
      "Epoch 133/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 0.0229 - acc: 1.0000 - val_loss: 0.5125 - val_acc: 0.8667\n",
      "Epoch 134/1000\n",
      "700/700 [==============================] - 0s 201us/step - loss: 0.0226 - acc: 1.0000 - val_loss: 0.5136 - val_acc: 0.8667\n",
      "Epoch 135/1000\n",
      "700/700 [==============================] - 0s 192us/step - loss: 0.0223 - acc: 1.0000 - val_loss: 0.5130 - val_acc: 0.8667\n",
      "Epoch 136/1000\n",
      "700/700 [==============================] - 0s 195us/step - loss: 0.0221 - acc: 1.0000 - val_loss: 0.5140 - val_acc: 0.8700\n",
      "Epoch 137/1000\n",
      "700/700 [==============================] - 0s 212us/step - loss: 0.0218 - acc: 1.0000 - val_loss: 0.5142 - val_acc: 0.8667\n",
      "Epoch 138/1000\n",
      "700/700 [==============================] - 0s 195us/step - loss: 0.0216 - acc: 1.0000 - val_loss: 0.5158 - val_acc: 0.8667\n",
      "Epoch 139/1000\n",
      "700/700 [==============================] - 0s 195us/step - loss: 0.0214 - acc: 1.0000 - val_loss: 0.5149 - val_acc: 0.8667\n",
      "Epoch 140/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 0.0212 - acc: 1.0000 - val_loss: 0.5159 - val_acc: 0.8633\n",
      "Epoch 141/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 0.0209 - acc: 1.0000 - val_loss: 0.5177 - val_acc: 0.8633\n",
      "Epoch 142/1000\n",
      "700/700 [==============================] - 0s 208us/step - loss: 0.0207 - acc: 1.0000 - val_loss: 0.5177 - val_acc: 0.8667\n",
      "Epoch 143/1000\n",
      "700/700 [==============================] - 0s 201us/step - loss: 0.0205 - acc: 1.0000 - val_loss: 0.5179 - val_acc: 0.8633\n",
      "Epoch 144/1000\n",
      "700/700 [==============================] - 0s 188us/step - loss: 0.0203 - acc: 1.0000 - val_loss: 0.5174 - val_acc: 0.8700\n",
      "Epoch 145/1000\n",
      "700/700 [==============================] - 0s 202us/step - loss: 0.0200 - acc: 1.0000 - val_loss: 0.5173 - val_acc: 0.8700\n",
      "Epoch 146/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 0.0199 - acc: 1.0000 - val_loss: 0.5188 - val_acc: 0.8667\n",
      "Epoch 147/1000\n",
      "700/700 [==============================] - 0s 197us/step - loss: 0.0197 - acc: 1.0000 - val_loss: 0.5181 - val_acc: 0.8667\n",
      "Epoch 148/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 0.0195 - acc: 1.0000 - val_loss: 0.5188 - val_acc: 0.8667\n",
      "Epoch 149/1000\n",
      "700/700 [==============================] - 0s 205us/step - loss: 0.0193 - acc: 1.0000 - val_loss: 0.5195 - val_acc: 0.8667\n",
      "Epoch 150/1000\n",
      "700/700 [==============================] - 0s 215us/step - loss: 0.0191 - acc: 1.0000 - val_loss: 0.5197 - val_acc: 0.8700\n",
      "Epoch 151/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 0.0189 - acc: 1.0000 - val_loss: 0.5203 - val_acc: 0.8667\n",
      "Epoch 152/1000\n",
      "700/700 [==============================] - 0s 184us/step - loss: 0.0187 - acc: 1.0000 - val_loss: 0.5213 - val_acc: 0.8667\n",
      "Epoch 153/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0185 - acc: 1.0000 - val_loss: 0.5216 - val_acc: 0.8667\n",
      "Epoch 154/1000\n",
      "700/700 [==============================] - 0s 193us/step - loss: 0.0184 - acc: 1.0000 - val_loss: 0.5215 - val_acc: 0.8700\n",
      "Epoch 155/1000\n",
      "700/700 [==============================] - 0s 191us/step - loss: 0.0182 - acc: 1.0000 - val_loss: 0.5234 - val_acc: 0.8667\n",
      "Epoch 156/1000\n",
      "700/700 [==============================] - 0s 192us/step - loss: 0.0180 - acc: 1.0000 - val_loss: 0.5229 - val_acc: 0.8700\n",
      "Epoch 157/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 0.0178 - acc: 1.0000 - val_loss: 0.5235 - val_acc: 0.8667\n",
      "Epoch 158/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 0.0177 - acc: 1.0000 - val_loss: 0.5236 - val_acc: 0.8700\n",
      "Epoch 159/1000\n",
      "700/700 [==============================] - 0s 188us/step - loss: 0.0175 - acc: 1.0000 - val_loss: 0.5240 - val_acc: 0.8700\n",
      "Epoch 160/1000\n",
      "700/700 [==============================] - 0s 190us/step - loss: 0.0173 - acc: 1.0000 - val_loss: 0.5248 - val_acc: 0.8700\n",
      "Epoch 161/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 0.0172 - acc: 1.0000 - val_loss: 0.5240 - val_acc: 0.8700\n",
      "Epoch 162/1000\n",
      "700/700 [==============================] - 0s 190us/step - loss: 0.0170 - acc: 1.0000 - val_loss: 0.5245 - val_acc: 0.8667\n",
      "Epoch 163/1000\n",
      "700/700 [==============================] - 0s 192us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.5252 - val_acc: 0.8700\n",
      "Epoch 164/1000\n",
      "700/700 [==============================] - 0s 193us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.5255 - val_acc: 0.8667\n",
      "Epoch 165/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.5260 - val_acc: 0.8700\n",
      "Epoch 166/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0164 - acc: 1.0000 - val_loss: 0.5255 - val_acc: 0.8700\n",
      "Epoch 167/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 0.0163 - acc: 1.0000 - val_loss: 0.5271 - val_acc: 0.8700\n",
      "Epoch 168/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 0.0161 - acc: 1.0000 - val_loss: 0.5277 - val_acc: 0.8700\n",
      "Epoch 169/1000\n",
      "700/700 [==============================] - 0s 190us/step - loss: 0.0160 - acc: 1.0000 - val_loss: 0.5280 - val_acc: 0.8700\n",
      "Epoch 170/1000\n",
      "700/700 [==============================] - 0s 196us/step - loss: 0.0158 - acc: 1.0000 - val_loss: 0.5279 - val_acc: 0.8700\n",
      "Epoch 171/1000\n",
      "700/700 [==============================] - 0s 184us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 0.5284 - val_acc: 0.8700\n",
      "Epoch 172/1000\n",
      "700/700 [==============================] - 0s 178us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.5299 - val_acc: 0.8667\n",
      "Epoch 173/1000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.5305 - val_acc: 0.8667\n",
      "Epoch 174/1000\n",
      "700/700 [==============================] - 0s 169us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 0.5300 - val_acc: 0.8700\n",
      "Epoch 175/1000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 0.0152 - acc: 1.0000 - val_loss: 0.5298 - val_acc: 0.8700\n",
      "Epoch 176/1000\n",
      "700/700 [==============================] - 0s 192us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.5305 - val_acc: 0.8700\n",
      "Epoch 177/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.5303 - val_acc: 0.8700\n",
      "Epoch 178/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 0.0148 - acc: 1.0000 - val_loss: 0.5308 - val_acc: 0.8700\n",
      "Epoch 179/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 175us/step - loss: 0.0147 - acc: 1.0000 - val_loss: 0.5321 - val_acc: 0.8700\n",
      "Epoch 180/1000\n",
      "700/700 [==============================] - 0s 176us/step - loss: 0.0146 - acc: 1.0000 - val_loss: 0.5318 - val_acc: 0.8700\n",
      "Epoch 181/1000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.5325 - val_acc: 0.8700\n",
      "Epoch 182/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.5330 - val_acc: 0.8700\n",
      "Epoch 183/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 0.5336 - val_acc: 0.8700\n",
      "Epoch 184/1000\n",
      "700/700 [==============================] - 0s 193us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 0.5335 - val_acc: 0.8667\n",
      "Epoch 185/1000\n",
      "700/700 [==============================] - 0s 172us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.5334 - val_acc: 0.8700\n",
      "Epoch 186/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.5338 - val_acc: 0.8700\n",
      "Epoch 187/1000\n",
      "700/700 [==============================] - 0s 180us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 0.5341 - val_acc: 0.8700\n",
      "Epoch 188/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.5351 - val_acc: 0.8667\n",
      "Epoch 189/1000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.5347 - val_acc: 0.8667\n",
      "Epoch 190/1000\n",
      "700/700 [==============================] - 0s 174us/step - loss: 0.0134 - acc: 1.0000 - val_loss: 0.5355 - val_acc: 0.8633\n",
      "Epoch 191/1000\n",
      "700/700 [==============================] - 0s 184us/step - loss: 0.0134 - acc: 1.0000 - val_loss: 0.5361 - val_acc: 0.8667\n",
      "Epoch 192/1000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.5368 - val_acc: 0.8633\n",
      "Epoch 193/1000\n",
      "700/700 [==============================] - 0s 183us/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.5371 - val_acc: 0.8633\n",
      "Epoch 194/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 0.5371 - val_acc: 0.8667\n",
      "Epoch 195/1000\n",
      "700/700 [==============================] - 0s 176us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.5380 - val_acc: 0.8667\n",
      "Epoch 196/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.5387 - val_acc: 0.8667\n",
      "Epoch 197/1000\n",
      "700/700 [==============================] - 0s 172us/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.5387 - val_acc: 0.8667\n",
      "Epoch 198/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0127 - acc: 1.0000 - val_loss: 0.5385 - val_acc: 0.8667\n",
      "Epoch 199/1000\n",
      "700/700 [==============================] - 0s 179us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.5391 - val_acc: 0.8667\n",
      "Epoch 200/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.5395 - val_acc: 0.8667\n",
      "Epoch 201/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.5398 - val_acc: 0.8667\n",
      "Epoch 202/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.5406 - val_acc: 0.8667\n",
      "Epoch 203/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.5406 - val_acc: 0.8667\n",
      "Epoch 204/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.5413 - val_acc: 0.8667\n",
      "Epoch 205/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.5416 - val_acc: 0.8667\n",
      "Epoch 206/1000\n",
      "700/700 [==============================] - 0s 178us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.5414 - val_acc: 0.8667\n",
      "Epoch 207/1000\n",
      "700/700 [==============================] - 0s 193us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.5417 - val_acc: 0.8667\n",
      "Epoch 208/1000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.5419 - val_acc: 0.8667\n",
      "Epoch 209/1000\n",
      "700/700 [==============================] - 0s 183us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.5422 - val_acc: 0.8667\n",
      "Epoch 210/1000\n",
      "700/700 [==============================] - 0s 182us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.5430 - val_acc: 0.8667\n",
      "Epoch 211/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.5436 - val_acc: 0.8667\n",
      "Epoch 212/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.5440 - val_acc: 0.8667\n",
      "Epoch 213/1000\n",
      "700/700 [==============================] - 0s 169us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.5441 - val_acc: 0.8667\n",
      "Epoch 214/1000\n",
      "700/700 [==============================] - 0s 171us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.5441 - val_acc: 0.8667\n",
      "Epoch 215/1000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.5442 - val_acc: 0.8667\n",
      "Epoch 216/1000\n",
      "700/700 [==============================] - 0s 201us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.5446 - val_acc: 0.8667\n",
      "Epoch 217/1000\n",
      "700/700 [==============================] - 0s 183us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.5453 - val_acc: 0.8667\n",
      "Epoch 218/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.5458 - val_acc: 0.8667\n",
      "Epoch 219/1000\n",
      "700/700 [==============================] - 0s 169us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.5460 - val_acc: 0.8667\n",
      "Epoch 220/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.5466 - val_acc: 0.8667\n",
      "Epoch 221/1000\n",
      "700/700 [==============================] - 0s 174us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.5471 - val_acc: 0.8667\n",
      "Epoch 222/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.5470 - val_acc: 0.8667\n",
      "Epoch 223/1000\n",
      "700/700 [==============================] - 0s 169us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.5471 - val_acc: 0.8667\n",
      "Epoch 224/1000\n",
      "700/700 [==============================] - 0s 169us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.5480 - val_acc: 0.8667\n",
      "Epoch 225/1000\n",
      "700/700 [==============================] - 0s 172us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.5479 - val_acc: 0.8667\n",
      "Epoch 226/1000\n",
      "700/700 [==============================] - 0s 169us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.5476 - val_acc: 0.8667\n",
      "Epoch 227/1000\n",
      "700/700 [==============================] - 0s 169us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.5484 - val_acc: 0.8667\n",
      "Epoch 228/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.5483 - val_acc: 0.8667\n",
      "Epoch 229/1000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.5487 - val_acc: 0.8667\n",
      "Epoch 230/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.5490 - val_acc: 0.8667\n",
      "Epoch 231/1000\n",
      "700/700 [==============================] - 0s 169us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.5497 - val_acc: 0.8667\n",
      "Epoch 232/1000\n",
      "700/700 [==============================] - 0s 167us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.5505 - val_acc: 0.8667\n",
      "Epoch 233/1000\n",
      "700/700 [==============================] - 0s 190us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.5506 - val_acc: 0.8667\n",
      "Epoch 234/1000\n",
      "700/700 [==============================] - 0s 179us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.5507 - val_acc: 0.8667\n",
      "Epoch 235/1000\n",
      "700/700 [==============================] - 0s 166us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.5508 - val_acc: 0.8667\n",
      "Epoch 236/1000\n",
      "700/700 [==============================] - 0s 165us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.5515 - val_acc: 0.8667\n",
      "Epoch 237/1000\n",
      "700/700 [==============================] - 0s 174us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.5517 - val_acc: 0.8667\n",
      "Epoch 238/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 172us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.5520 - val_acc: 0.8667\n",
      "Epoch 239/1000\n",
      "700/700 [==============================] - 0s 171us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.5523 - val_acc: 0.8633\n",
      "Epoch 240/1000\n",
      "700/700 [==============================] - 0s 172us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.5526 - val_acc: 0.8667\n",
      "Epoch 241/1000\n",
      "700/700 [==============================] - 0s 176us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.5527 - val_acc: 0.8667\n",
      "Epoch 242/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.5533 - val_acc: 0.8667\n",
      "Epoch 243/1000\n",
      "700/700 [==============================] - 0s 191us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.5531 - val_acc: 0.8667\n",
      "Epoch 244/1000\n",
      "700/700 [==============================] - 0s 166us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.5534 - val_acc: 0.8667\n",
      "Epoch 245/1000\n",
      "700/700 [==============================] - 0s 168us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.5535 - val_acc: 0.8667\n",
      "Epoch 246/1000\n",
      "700/700 [==============================] - 0s 176us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.5545 - val_acc: 0.8667\n",
      "Epoch 247/1000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.5547 - val_acc: 0.8667\n",
      "Epoch 248/1000\n",
      "700/700 [==============================] - 0s 172us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.5550 - val_acc: 0.8667\n",
      "Epoch 249/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.5552 - val_acc: 0.8667\n",
      "Epoch 250/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.5551 - val_acc: 0.8667\n",
      "Epoch 251/1000\n",
      "700/700 [==============================] - 0s 182us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.5555 - val_acc: 0.8667\n",
      "Epoch 252/1000\n",
      "700/700 [==============================] - 0s 167us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.5564 - val_acc: 0.8667\n",
      "Epoch 253/1000\n",
      "700/700 [==============================] - 0s 172us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.5563 - val_acc: 0.8667\n",
      "Epoch 254/1000\n",
      "700/700 [==============================] - 0s 172us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.5564 - val_acc: 0.8633\n",
      "Epoch 255/1000\n",
      "700/700 [==============================] - 0s 176us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.5571 - val_acc: 0.8667\n",
      "Epoch 256/1000\n",
      "700/700 [==============================] - 0s 172us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.5567 - val_acc: 0.8667\n",
      "Epoch 257/1000\n",
      "700/700 [==============================] - 0s 174us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.5577 - val_acc: 0.8667\n",
      "Epoch 258/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.5581 - val_acc: 0.8667\n",
      "Epoch 259/1000\n",
      "700/700 [==============================] - 0s 181us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.5578 - val_acc: 0.8700\n",
      "Epoch 260/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.5579 - val_acc: 0.8667\n",
      "Epoch 261/1000\n",
      "700/700 [==============================] - 0s 169us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.5583 - val_acc: 0.8633\n",
      "Epoch 262/1000\n",
      "700/700 [==============================] - 0s 168us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.5589 - val_acc: 0.8633\n",
      "Epoch 263/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.5590 - val_acc: 0.8633\n",
      "Epoch 264/1000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.5594 - val_acc: 0.8633\n",
      "Epoch 265/1000\n",
      "700/700 [==============================] - 0s 184us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.5594 - val_acc: 0.8633\n",
      "Epoch 266/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.5593 - val_acc: 0.8667\n",
      "Epoch 267/1000\n",
      "700/700 [==============================] - 0s 166us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.5597 - val_acc: 0.8633\n",
      "Epoch 268/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.5602 - val_acc: 0.8633\n",
      "Epoch 269/1000\n",
      "700/700 [==============================] - 0s 181us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.5606 - val_acc: 0.8633\n",
      "Epoch 270/1000\n",
      "700/700 [==============================] - 0s 181us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.5603 - val_acc: 0.8667\n",
      "Epoch 271/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.5610 - val_acc: 0.8633\n",
      "Epoch 272/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.5617 - val_acc: 0.8633\n",
      "Epoch 273/1000\n",
      "700/700 [==============================] - 0s 184us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.5618 - val_acc: 0.8633\n",
      "Epoch 274/1000\n",
      "700/700 [==============================] - 0s 183us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.5620 - val_acc: 0.8633\n",
      "Epoch 275/1000\n",
      "700/700 [==============================] - 0s 169us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.5623 - val_acc: 0.8633\n",
      "Epoch 276/1000\n",
      "700/700 [==============================] - 0s 169us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.5624 - val_acc: 0.8667\n",
      "Epoch 277/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.5628 - val_acc: 0.8633\n",
      "Epoch 278/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.5629 - val_acc: 0.8633\n",
      "Epoch 279/1000\n",
      "700/700 [==============================] - 0s 168us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.5633 - val_acc: 0.8633\n",
      "Epoch 280/1000\n",
      "700/700 [==============================] - 0s 168us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.5634 - val_acc: 0.8667\n",
      "Epoch 281/1000\n",
      "700/700 [==============================] - 0s 169us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.5638 - val_acc: 0.8667\n",
      "Epoch 282/1000\n",
      "700/700 [==============================] - 0s 172us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.5643 - val_acc: 0.8667\n",
      "Epoch 283/1000\n",
      "700/700 [==============================] - 0s 167us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.5643 - val_acc: 0.8633\n",
      "Epoch 284/1000\n",
      "700/700 [==============================] - 0s 167us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.5645 - val_acc: 0.8667\n",
      "Epoch 285/1000\n",
      "700/700 [==============================] - 0s 179us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.5648 - val_acc: 0.8633\n",
      "Epoch 286/1000\n",
      "700/700 [==============================] - 0s 166us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.5649 - val_acc: 0.8633\n",
      "Epoch 287/1000\n",
      "700/700 [==============================] - 0s 169us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.5649 - val_acc: 0.8667\n",
      "Epoch 288/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.5649 - val_acc: 0.8667\n",
      "Epoch 289/1000\n",
      "700/700 [==============================] - 0s 174us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.5653 - val_acc: 0.8667\n",
      "Epoch 290/1000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.5655 - val_acc: 0.8667\n",
      "Epoch 291/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.5661 - val_acc: 0.8667\n",
      "Epoch 292/1000\n",
      "700/700 [==============================] - 0s 174us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.5666 - val_acc: 0.8667\n",
      "Epoch 293/1000\n",
      "700/700 [==============================] - 0s 172us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.5670 - val_acc: 0.8667\n",
      "Epoch 294/1000\n",
      "700/700 [==============================] - 0s 182us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.5672 - val_acc: 0.8667\n",
      "Epoch 295/1000\n",
      "700/700 [==============================] - 0s 174us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.5672 - val_acc: 0.8667\n",
      "Epoch 296/1000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.5676 - val_acc: 0.8667\n",
      "Epoch 297/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 174us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.5676 - val_acc: 0.8667\n",
      "Epoch 298/1000\n",
      "700/700 [==============================] - 0s 182us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.5682 - val_acc: 0.8667\n",
      "Epoch 299/1000\n",
      "700/700 [==============================] - 0s 168us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.5685 - val_acc: 0.8667\n",
      "Epoch 300/1000\n",
      "700/700 [==============================] - 0s 165us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.5686 - val_acc: 0.8667\n",
      "Epoch 301/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.5685 - val_acc: 0.8667\n",
      "Epoch 302/1000\n",
      "700/700 [==============================] - 0s 184us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.5690 - val_acc: 0.8667\n",
      "Epoch 303/1000\n",
      "700/700 [==============================] - 0s 174us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.5691 - val_acc: 0.8667\n",
      "Epoch 304/1000\n",
      "700/700 [==============================] - 0s 169us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.5694 - val_acc: 0.8667\n",
      "Epoch 305/1000\n",
      "700/700 [==============================] - 0s 174us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.5696 - val_acc: 0.8667\n",
      "Epoch 306/1000\n",
      "700/700 [==============================] - 0s 174us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.5695 - val_acc: 0.8667\n",
      "Epoch 307/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.5695 - val_acc: 0.8667\n",
      "Epoch 308/1000\n",
      "700/700 [==============================] - 0s 182us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.5698 - val_acc: 0.8667\n",
      "Epoch 309/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.5703 - val_acc: 0.8667\n",
      "Epoch 310/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.5707 - val_acc: 0.8667\n",
      "Epoch 311/1000\n",
      "700/700 [==============================] - 0s 165us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.5712 - val_acc: 0.8667\n",
      "Epoch 312/1000\n",
      "700/700 [==============================] - 0s 174us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.5711 - val_acc: 0.8667\n",
      "Epoch 313/1000\n",
      "700/700 [==============================] - 0s 167us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.5714 - val_acc: 0.8667\n",
      "Epoch 314/1000\n",
      "700/700 [==============================] - 0s 171us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.5713 - val_acc: 0.8667\n",
      "Epoch 315/1000\n",
      "700/700 [==============================] - 0s 164us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.5717 - val_acc: 0.8667\n",
      "Epoch 316/1000\n",
      "700/700 [==============================] - 0s 174us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.5719 - val_acc: 0.8667\n",
      "Epoch 317/1000\n",
      "700/700 [==============================] - 0s 171us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.5723 - val_acc: 0.8667\n",
      "Epoch 318/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.5727 - val_acc: 0.8667\n",
      "Epoch 319/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.5727 - val_acc: 0.8667\n",
      "Epoch 320/1000\n",
      "700/700 [==============================] - 0s 167us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.5729 - val_acc: 0.8667\n",
      "Epoch 321/1000\n",
      "700/700 [==============================] - 0s 176us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.5734 - val_acc: 0.8667\n",
      "Epoch 322/1000\n",
      "700/700 [==============================] - 0s 169us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.5736 - val_acc: 0.8667\n",
      "Epoch 323/1000\n",
      "700/700 [==============================] - 0s 184us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.5734 - val_acc: 0.8667\n",
      "Epoch 324/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.5738 - val_acc: 0.8667\n",
      "Epoch 325/1000\n",
      "700/700 [==============================] - 0s 169us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.5739 - val_acc: 0.8667\n",
      "Epoch 326/1000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.5740 - val_acc: 0.8667\n",
      "Epoch 327/1000\n",
      "700/700 [==============================] - 0s 165us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.5743 - val_acc: 0.8667\n",
      "Epoch 328/1000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.5746 - val_acc: 0.8667\n",
      "Epoch 329/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.5749 - val_acc: 0.8667\n",
      "Epoch 330/1000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.5750 - val_acc: 0.8667\n",
      "Epoch 331/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.5754 - val_acc: 0.8667\n",
      "Epoch 332/1000\n",
      "700/700 [==============================] - 0s 174us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.5756 - val_acc: 0.8667\n",
      "Epoch 333/1000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.5759 - val_acc: 0.8667\n",
      "Epoch 334/1000\n",
      "700/700 [==============================] - 0s 174us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.5760 - val_acc: 0.8667\n",
      "Epoch 335/1000\n",
      "700/700 [==============================] - 0s 171us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.5763 - val_acc: 0.8667\n",
      "Epoch 336/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.5764 - val_acc: 0.8667\n",
      "Epoch 337/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.5764 - val_acc: 0.8667\n",
      "Epoch 338/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.5769 - val_acc: 0.8667\n",
      "Epoch 339/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.5774 - val_acc: 0.8667\n",
      "Epoch 340/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.5774 - val_acc: 0.8667\n",
      "Epoch 341/1000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.5774 - val_acc: 0.8667\n",
      "Epoch 342/1000\n",
      "700/700 [==============================] - 0s 176us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.5777 - val_acc: 0.8667\n",
      "Epoch 343/1000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.5778 - val_acc: 0.8667\n",
      "Epoch 344/1000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.5780 - val_acc: 0.8700\n",
      "Epoch 345/1000\n",
      "700/700 [==============================] - 0s 165us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.5785 - val_acc: 0.8667\n",
      "Epoch 346/1000\n",
      "700/700 [==============================] - 0s 171us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.5787 - val_acc: 0.8667\n",
      "Epoch 347/1000\n",
      "700/700 [==============================] - 0s 201us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.5790 - val_acc: 0.8667\n",
      "Epoch 348/1000\n",
      "700/700 [==============================] - 0s 172us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.5791 - val_acc: 0.8667\n",
      "Epoch 349/1000\n",
      "700/700 [==============================] - 0s 174us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.5792 - val_acc: 0.8700\n",
      "Epoch 350/1000\n",
      "700/700 [==============================] - 0s 183us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.5794 - val_acc: 0.8700\n",
      "Epoch 351/1000\n",
      "700/700 [==============================] - 0s 164us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.5799 - val_acc: 0.8667\n",
      "Epoch 352/1000\n",
      "700/700 [==============================] - 0s 169us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.5803 - val_acc: 0.8633\n",
      "Epoch 353/1000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.5804 - val_acc: 0.8667\n",
      "Epoch 354/1000\n",
      "700/700 [==============================] - 0s 179us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.5803 - val_acc: 0.8700\n",
      "Epoch 355/1000\n",
      "700/700 [==============================] - 0s 183us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.5805 - val_acc: 0.8700\n",
      "Epoch 356/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 172us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.5807 - val_acc: 0.8700\n",
      "Epoch 357/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.5807 - val_acc: 0.8700\n",
      "Epoch 358/1000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.5812 - val_acc: 0.8700\n",
      "Epoch 359/1000\n",
      "700/700 [==============================] - 0s 171us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.5815 - val_acc: 0.8700\n",
      "Epoch 360/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.5816 - val_acc: 0.8700\n",
      "Epoch 361/1000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.5817 - val_acc: 0.8700\n",
      "Epoch 362/1000\n",
      "700/700 [==============================] - 0s 174us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.5819 - val_acc: 0.8700\n",
      "Epoch 363/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.5821 - val_acc: 0.8700\n",
      "Epoch 364/1000\n",
      "700/700 [==============================] - 0s 176us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.5822 - val_acc: 0.8700\n",
      "Epoch 365/1000\n",
      "700/700 [==============================] - 0s 179us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.5825 - val_acc: 0.8700\n",
      "Epoch 366/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.5828 - val_acc: 0.8700\n",
      "Epoch 367/1000\n",
      "700/700 [==============================] - 0s 176us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.5829 - val_acc: 0.8700\n",
      "Epoch 368/1000\n",
      "700/700 [==============================] - 0s 183us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.5830 - val_acc: 0.8700\n",
      "Epoch 369/1000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.5833 - val_acc: 0.8700\n",
      "Epoch 370/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.5836 - val_acc: 0.8700\n",
      "Epoch 371/1000\n",
      "700/700 [==============================] - 0s 182us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.5837 - val_acc: 0.8700\n",
      "Epoch 372/1000\n",
      "700/700 [==============================] - 0s 182us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.5838 - val_acc: 0.8700\n",
      "Epoch 373/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.5839 - val_acc: 0.8700\n",
      "Epoch 374/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.5843 - val_acc: 0.8700\n",
      "Epoch 375/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.5845 - val_acc: 0.8700\n",
      "Epoch 376/1000\n",
      "700/700 [==============================] - 0s 183us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.5846 - val_acc: 0.8700\n",
      "Epoch 377/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.5848 - val_acc: 0.8700\n",
      "Epoch 378/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.5848 - val_acc: 0.8700\n",
      "Epoch 379/1000\n",
      "700/700 [==============================] - 0s 179us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.5851 - val_acc: 0.8700\n",
      "Epoch 380/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.5855 - val_acc: 0.8700\n",
      "Epoch 381/1000\n",
      "700/700 [==============================] - 0s 195us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.5857 - val_acc: 0.8700\n",
      "Epoch 382/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.5860 - val_acc: 0.8700\n",
      "Epoch 383/1000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.5863 - val_acc: 0.8700\n",
      "Epoch 384/1000\n",
      "700/700 [==============================] - 0s 190us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.5863 - val_acc: 0.8700\n",
      "Epoch 385/1000\n",
      "700/700 [==============================] - 0s 183us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.5863 - val_acc: 0.8700\n",
      "Epoch 386/1000\n",
      "700/700 [==============================] - 0s 192us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.5867 - val_acc: 0.8700\n",
      "Epoch 387/1000\n",
      "700/700 [==============================] - 0s 188us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.5871 - val_acc: 0.8667\n",
      "Epoch 388/1000\n",
      "700/700 [==============================] - 0s 179us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.5873 - val_acc: 0.8667\n",
      "Epoch 389/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.5873 - val_acc: 0.8700\n",
      "Epoch 390/1000\n",
      "700/700 [==============================] - 0s 174us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.5871 - val_acc: 0.8700\n",
      "Epoch 391/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.5874 - val_acc: 0.8700\n",
      "Epoch 392/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.5878 - val_acc: 0.8667\n",
      "Epoch 393/1000\n",
      "700/700 [==============================] - 0s 182us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.5880 - val_acc: 0.8700\n",
      "Epoch 394/1000\n",
      "700/700 [==============================] - 0s 183us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.5883 - val_acc: 0.8667\n",
      "Epoch 395/1000\n",
      "700/700 [==============================] - 0s 190us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.5885 - val_acc: 0.8667\n",
      "Epoch 396/1000\n",
      "700/700 [==============================] - 0s 178us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.5887 - val_acc: 0.8667\n",
      "Epoch 397/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.5887 - val_acc: 0.8700\n",
      "Epoch 398/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.5889 - val_acc: 0.8700\n",
      "Epoch 399/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.5890 - val_acc: 0.8700\n",
      "Epoch 400/1000\n",
      "700/700 [==============================] - 0s 176us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.5892 - val_acc: 0.8700\n",
      "Epoch 401/1000\n",
      "700/700 [==============================] - 0s 190us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.5894 - val_acc: 0.8700\n",
      "Epoch 402/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.5894 - val_acc: 0.8700\n",
      "Epoch 403/1000\n",
      "700/700 [==============================] - 0s 172us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.5897 - val_acc: 0.8700\n",
      "Epoch 404/1000\n",
      "700/700 [==============================] - 0s 174us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.5900 - val_acc: 0.8700\n",
      "Epoch 405/1000\n",
      "700/700 [==============================] - 0s 183us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.5900 - val_acc: 0.8700\n",
      "Epoch 406/1000\n",
      "700/700 [==============================] - 0s 171us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.5902 - val_acc: 0.8700\n",
      "Epoch 407/1000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.5905 - val_acc: 0.8700\n",
      "Epoch 408/1000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.5907 - val_acc: 0.8700\n",
      "Epoch 409/1000\n",
      "700/700 [==============================] - 0s 183us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.5909 - val_acc: 0.8667\n",
      "Epoch 410/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.5910 - val_acc: 0.8700\n",
      "Epoch 411/1000\n",
      "700/700 [==============================] - 0s 176us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.5913 - val_acc: 0.8700\n",
      "Epoch 412/1000\n",
      "700/700 [==============================] - 0s 184us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.5916 - val_acc: 0.8700\n",
      "Epoch 413/1000\n",
      "700/700 [==============================] - 0s 174us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.5916 - val_acc: 0.8700\n",
      "Epoch 414/1000\n",
      "700/700 [==============================] - 0s 172us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.5919 - val_acc: 0.8667\n",
      "Epoch 415/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 173us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.5921 - val_acc: 0.8667\n",
      "Epoch 416/1000\n",
      "700/700 [==============================] - 0s 183us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.5922 - val_acc: 0.8667\n",
      "Epoch 417/1000\n",
      "700/700 [==============================] - 0s 174us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.5923 - val_acc: 0.8667\n",
      "Epoch 418/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.5926 - val_acc: 0.8700\n",
      "Epoch 419/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.5927 - val_acc: 0.8700\n",
      "Epoch 420/1000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.5930 - val_acc: 0.8667\n",
      "Epoch 421/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.5932 - val_acc: 0.8667\n",
      "Epoch 422/1000\n",
      "700/700 [==============================] - 0s 190us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.5935 - val_acc: 0.8667\n",
      "Epoch 423/1000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.5936 - val_acc: 0.8667\n",
      "Epoch 424/1000\n",
      "700/700 [==============================] - 0s 172us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.5938 - val_acc: 0.8667\n",
      "Epoch 425/1000\n",
      "700/700 [==============================] - 0s 195us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.5940 - val_acc: 0.8667\n",
      "Epoch 426/1000\n",
      "700/700 [==============================] - 0s 183us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.5940 - val_acc: 0.8667\n",
      "Epoch 427/1000\n",
      "700/700 [==============================] - 0s 181us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.5943 - val_acc: 0.8667\n",
      "Epoch 428/1000\n",
      "700/700 [==============================] - 0s 178us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.5944 - val_acc: 0.8667\n",
      "Epoch 429/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.5945 - val_acc: 0.8667\n",
      "Epoch 430/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.5947 - val_acc: 0.8667\n",
      "Epoch 431/1000\n",
      "700/700 [==============================] - 0s 174us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.5948 - val_acc: 0.8667\n",
      "Epoch 432/1000\n",
      "700/700 [==============================] - 0s 176us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.5951 - val_acc: 0.8667\n",
      "Epoch 433/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.5952 - val_acc: 0.8667\n",
      "Epoch 434/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.5953 - val_acc: 0.8700\n",
      "Epoch 435/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.5954 - val_acc: 0.8700\n",
      "Epoch 436/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.5956 - val_acc: 0.8700\n",
      "Epoch 437/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.5958 - val_acc: 0.8700\n",
      "Epoch 438/1000\n",
      "700/700 [==============================] - 0s 181us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.5959 - val_acc: 0.8667\n",
      "Epoch 439/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.5962 - val_acc: 0.8667\n",
      "Epoch 440/1000\n",
      "700/700 [==============================] - 0s 174us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.5965 - val_acc: 0.8667\n",
      "Epoch 441/1000\n",
      "700/700 [==============================] - 0s 195us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.5966 - val_acc: 0.8667\n",
      "Epoch 442/1000\n",
      "700/700 [==============================] - 0s 180us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.5968 - val_acc: 0.8667\n",
      "Epoch 443/1000\n",
      "700/700 [==============================] - 0s 188us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.5968 - val_acc: 0.8667\n",
      "Epoch 444/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.5970 - val_acc: 0.8667\n",
      "Epoch 445/1000\n",
      "700/700 [==============================] - 0s 183us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.5971 - val_acc: 0.8667\n",
      "Epoch 446/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.5971 - val_acc: 0.8667\n",
      "Epoch 447/1000\n",
      "700/700 [==============================] - 0s 188us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.5975 - val_acc: 0.8667\n",
      "Epoch 448/1000\n",
      "700/700 [==============================] - 0s 191us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.5978 - val_acc: 0.8667\n",
      "Epoch 449/1000\n",
      "700/700 [==============================] - 0s 190us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.5978 - val_acc: 0.8667\n",
      "Epoch 450/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.5981 - val_acc: 0.8667\n",
      "Epoch 451/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.5982 - val_acc: 0.8667\n",
      "Epoch 452/1000\n",
      "700/700 [==============================] - 0s 190us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.5983 - val_acc: 0.8667\n",
      "Epoch 453/1000\n",
      "700/700 [==============================] - 0s 172us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.5984 - val_acc: 0.8667\n",
      "Epoch 454/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.5986 - val_acc: 0.8667\n",
      "Epoch 455/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.5988 - val_acc: 0.8667\n",
      "Epoch 456/1000\n",
      "700/700 [==============================] - 0s 191us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.5989 - val_acc: 0.8667\n",
      "Epoch 457/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.5991 - val_acc: 0.8667\n",
      "Epoch 458/1000\n",
      "700/700 [==============================] - 0s 190us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.5994 - val_acc: 0.8667\n",
      "Epoch 459/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.5996 - val_acc: 0.8667\n",
      "Epoch 460/1000\n",
      "700/700 [==============================] - 0s 176us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.5997 - val_acc: 0.8667\n",
      "Epoch 461/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.5999 - val_acc: 0.8667\n",
      "Epoch 462/1000\n",
      "700/700 [==============================] - 0s 200us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.6000 - val_acc: 0.8667\n",
      "Epoch 463/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.6001 - val_acc: 0.8667\n",
      "Epoch 464/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.6001 - val_acc: 0.8667\n",
      "Epoch 465/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.6005 - val_acc: 0.8667\n",
      "Epoch 466/1000\n",
      "700/700 [==============================] - 0s 190us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.6005 - val_acc: 0.8667\n",
      "Epoch 467/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.6007 - val_acc: 0.8667\n",
      "Epoch 468/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.6007 - val_acc: 0.8667\n",
      "Epoch 469/1000\n",
      "700/700 [==============================] - 0s 172us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.6010 - val_acc: 0.8667\n",
      "Epoch 470/1000\n",
      "700/700 [==============================] - 0s 176us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.6012 - val_acc: 0.8667\n",
      "Epoch 471/1000\n",
      "700/700 [==============================] - 0s 183us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.6013 - val_acc: 0.8667\n",
      "Epoch 472/1000\n",
      "700/700 [==============================] - 0s 192us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.6015 - val_acc: 0.8667\n",
      "Epoch 473/1000\n",
      "700/700 [==============================] - 0s 171us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.6016 - val_acc: 0.8667\n",
      "Epoch 474/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 183us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.6017 - val_acc: 0.8667\n",
      "Epoch 475/1000\n",
      "700/700 [==============================] - 0s 179us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.6019 - val_acc: 0.8667\n",
      "Epoch 476/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.6020 - val_acc: 0.8667\n",
      "Epoch 477/1000\n",
      "700/700 [==============================] - 0s 180us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.6023 - val_acc: 0.8667\n",
      "Epoch 478/1000\n",
      "700/700 [==============================] - 0s 178us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.6024 - val_acc: 0.8667\n",
      "Epoch 479/1000\n",
      "700/700 [==============================] - 0s 180us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.6025 - val_acc: 0.8667\n",
      "Epoch 480/1000\n",
      "700/700 [==============================] - 0s 178us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.6027 - val_acc: 0.8667\n",
      "Epoch 481/1000\n",
      "700/700 [==============================] - 0s 184us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.6028 - val_acc: 0.8667\n",
      "Epoch 482/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.6030 - val_acc: 0.8667\n",
      "Epoch 483/1000\n",
      "700/700 [==============================] - 0s 179us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.6031 - val_acc: 0.8667\n",
      "Epoch 484/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.6032 - val_acc: 0.8700\n",
      "Epoch 485/1000\n",
      "700/700 [==============================] - 0s 188us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.6035 - val_acc: 0.8667\n",
      "Epoch 486/1000\n",
      "700/700 [==============================] - 0s 172us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.6037 - val_acc: 0.8667\n",
      "Epoch 487/1000\n",
      "700/700 [==============================] - 0s 179us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.6038 - val_acc: 0.8667\n",
      "Epoch 488/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.6039 - val_acc: 0.8667\n",
      "Epoch 489/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.6040 - val_acc: 0.8667\n",
      "Epoch 490/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.6043 - val_acc: 0.8667\n",
      "Epoch 491/1000\n",
      "700/700 [==============================] - 0s 190us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.6044 - val_acc: 0.8667\n",
      "Epoch 492/1000\n",
      "700/700 [==============================] - 0s 174us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.6046 - val_acc: 0.8667\n",
      "Epoch 493/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.6047 - val_acc: 0.8667\n",
      "Epoch 494/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.6047 - val_acc: 0.8700\n",
      "Epoch 495/1000\n",
      "700/700 [==============================] - 0s 188us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.6049 - val_acc: 0.8667\n",
      "Epoch 496/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.6052 - val_acc: 0.8667\n",
      "Epoch 497/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.6054 - val_acc: 0.8667\n",
      "Epoch 498/1000\n",
      "700/700 [==============================] - 0s 178us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.6056 - val_acc: 0.8667\n",
      "Epoch 499/1000\n",
      "700/700 [==============================] - 0s 192us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.6058 - val_acc: 0.8667\n",
      "Epoch 500/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.6059 - val_acc: 0.8667\n",
      "Epoch 501/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.6060 - val_acc: 0.8667\n",
      "Epoch 502/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.6062 - val_acc: 0.8667\n",
      "Epoch 503/1000\n",
      "700/700 [==============================] - 0s 195us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.6062 - val_acc: 0.8667\n",
      "Epoch 504/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.6064 - val_acc: 0.8667\n",
      "Epoch 505/1000\n",
      "700/700 [==============================] - 0s 174us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.6066 - val_acc: 0.8667\n",
      "Epoch 506/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.6068 - val_acc: 0.8667\n",
      "Epoch 507/1000\n",
      "700/700 [==============================] - 0s 172us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.6069 - val_acc: 0.8667\n",
      "Epoch 508/1000\n",
      "700/700 [==============================] - 0s 203us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.6070 - val_acc: 0.8667\n",
      "Epoch 509/1000\n",
      "700/700 [==============================] - 0s 172us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.6071 - val_acc: 0.8667\n",
      "Epoch 510/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.6073 - val_acc: 0.8667\n",
      "Epoch 511/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.6074 - val_acc: 0.8667\n",
      "Epoch 512/1000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.6076 - val_acc: 0.8667\n",
      "Epoch 513/1000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.6077 - val_acc: 0.8667\n",
      "Epoch 514/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.6079 - val_acc: 0.8667\n",
      "Epoch 515/1000\n",
      "700/700 [==============================] - 0s 172us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.6081 - val_acc: 0.8667\n",
      "Epoch 516/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.6081 - val_acc: 0.8667\n",
      "Epoch 517/1000\n",
      "700/700 [==============================] - 0s 182us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.6083 - val_acc: 0.8667\n",
      "Epoch 518/1000\n",
      "700/700 [==============================] - 0s 178us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.6085 - val_acc: 0.8667\n",
      "Epoch 519/1000\n",
      "700/700 [==============================] - 0s 184us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.6087 - val_acc: 0.8667\n",
      "Epoch 520/1000\n",
      "700/700 [==============================] - 0s 184us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.6089 - val_acc: 0.8667\n",
      "Epoch 521/1000\n",
      "700/700 [==============================] - 0s 183us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.6090 - val_acc: 0.8667\n",
      "Epoch 522/1000\n",
      "700/700 [==============================] - 0s 184us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.6091 - val_acc: 0.8667\n",
      "Epoch 523/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.6093 - val_acc: 0.8667\n",
      "Epoch 524/1000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.6095 - val_acc: 0.8667\n",
      "Epoch 525/1000\n",
      "700/700 [==============================] - 0s 172us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.6096 - val_acc: 0.8667\n",
      "Epoch 526/1000\n",
      "700/700 [==============================] - 0s 201us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.6097 - val_acc: 0.8667\n",
      "Epoch 527/1000\n",
      "700/700 [==============================] - 0s 176us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.6097 - val_acc: 0.8633\n",
      "Epoch 528/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.6101 - val_acc: 0.8667\n",
      "Epoch 529/1000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.6102 - val_acc: 0.8667\n",
      "Epoch 530/1000\n",
      "700/700 [==============================] - 0s 178us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.6103 - val_acc: 0.8667\n",
      "Epoch 531/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.6103 - val_acc: 0.8667\n",
      "Epoch 532/1000\n",
      "700/700 [==============================] - 0s 176us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.6105 - val_acc: 0.8667\n",
      "Epoch 533/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 178us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.6108 - val_acc: 0.8667\n",
      "Epoch 534/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.6107 - val_acc: 0.8667\n",
      "Epoch 535/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.6109 - val_acc: 0.8633\n",
      "Epoch 536/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.6112 - val_acc: 0.8633\n",
      "Epoch 537/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.6111 - val_acc: 0.8633\n",
      "Epoch 538/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.6114 - val_acc: 0.8700\n",
      "Epoch 539/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.6114 - val_acc: 0.8633\n",
      "Epoch 540/1000\n",
      "700/700 [==============================] - 0s 197us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.6115 - val_acc: 0.8633\n",
      "Epoch 541/1000\n",
      "700/700 [==============================] - 0s 180us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.6117 - val_acc: 0.8633\n",
      "Epoch 542/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.6118 - val_acc: 0.8633\n",
      "Epoch 543/1000\n",
      "700/700 [==============================] - 0s 193us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.6120 - val_acc: 0.8667\n",
      "Epoch 544/1000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.6122 - val_acc: 0.8700\n",
      "Epoch 545/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.6123 - val_acc: 0.8667\n",
      "Epoch 546/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.6124 - val_acc: 0.8667\n",
      "Epoch 547/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.6125 - val_acc: 0.8667\n",
      "Epoch 548/1000\n",
      "700/700 [==============================] - 0s 184us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.6127 - val_acc: 0.8700\n",
      "Epoch 549/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.6129 - val_acc: 0.8667\n",
      "Epoch 550/1000\n",
      "700/700 [==============================] - 0s 190us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.6130 - val_acc: 0.8667\n",
      "Epoch 551/1000\n",
      "700/700 [==============================] - 0s 193us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.6129 - val_acc: 0.8667\n",
      "Epoch 552/1000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.6131 - val_acc: 0.8700\n",
      "Epoch 553/1000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.6132 - val_acc: 0.8700\n",
      "Epoch 554/1000\n",
      "700/700 [==============================] - 0s 183us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.6134 - val_acc: 0.8700\n",
      "Epoch 555/1000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.6135 - val_acc: 0.8700\n",
      "Epoch 556/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.6137 - val_acc: 0.8700\n",
      "Epoch 557/1000\n",
      "700/700 [==============================] - 0s 206us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.6138 - val_acc: 0.8700\n",
      "Epoch 558/1000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.6140 - val_acc: 0.8700\n",
      "Epoch 559/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.6141 - val_acc: 0.8700\n",
      "Epoch 560/1000\n",
      "700/700 [==============================] - 0s 191us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.6143 - val_acc: 0.8667\n",
      "Epoch 561/1000\n",
      "700/700 [==============================] - 0s 184us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.6143 - val_acc: 0.8667\n",
      "Epoch 562/1000\n",
      "700/700 [==============================] - 0s 190us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.6145 - val_acc: 0.8700\n",
      "Epoch 563/1000\n",
      "700/700 [==============================] - 0s 196us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.6147 - val_acc: 0.8667\n",
      "Epoch 564/1000\n",
      "700/700 [==============================] - 0s 192us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.6148 - val_acc: 0.8700\n",
      "Epoch 565/1000\n",
      "700/700 [==============================] - 0s 183us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.6149 - val_acc: 0.8667\n",
      "Epoch 566/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.6150 - val_acc: 0.8667\n",
      "Epoch 567/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.6151 - val_acc: 0.8667\n",
      "Epoch 568/1000\n",
      "700/700 [==============================] - 0s 183us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.6152 - val_acc: 0.8667\n",
      "Epoch 569/1000\n",
      "700/700 [==============================] - 0s 200us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.6153 - val_acc: 0.8667\n",
      "Epoch 570/1000\n",
      "700/700 [==============================] - 0s 200us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.6155 - val_acc: 0.8667\n",
      "Epoch 571/1000\n",
      "700/700 [==============================] - 0s 200us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.6156 - val_acc: 0.8667\n",
      "Epoch 572/1000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.6158 - val_acc: 0.8667\n",
      "Epoch 573/1000\n",
      "700/700 [==============================] - 0s 197us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.6159 - val_acc: 0.8667\n",
      "Epoch 574/1000\n",
      "700/700 [==============================] - 0s 193us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.6160 - val_acc: 0.8667\n",
      "Epoch 575/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.6160 - val_acc: 0.8667\n",
      "Epoch 576/1000\n",
      "700/700 [==============================] - 0s 180us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.6162 - val_acc: 0.8667\n",
      "Epoch 577/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.6163 - val_acc: 0.8667\n",
      "Epoch 578/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.6165 - val_acc: 0.8667\n",
      "Epoch 579/1000\n",
      "700/700 [==============================] - 0s 200us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.6167 - val_acc: 0.8667\n",
      "Epoch 580/1000\n",
      "700/700 [==============================] - 0s 191us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.6169 - val_acc: 0.8667\n",
      "Epoch 581/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.6170 - val_acc: 0.8667\n",
      "Epoch 582/1000\n",
      "700/700 [==============================] - 0s 208us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.6170 - val_acc: 0.8667\n",
      "Epoch 583/1000\n",
      "700/700 [==============================] - 0s 191us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.6171 - val_acc: 0.8667\n",
      "Epoch 584/1000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.6173 - val_acc: 0.8667\n",
      "Epoch 585/1000\n",
      "700/700 [==============================] - 0s 193us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.6174 - val_acc: 0.8667\n",
      "Epoch 586/1000\n",
      "700/700 [==============================] - 0s 192us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.6176 - val_acc: 0.8667\n",
      "Epoch 587/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.6177 - val_acc: 0.8667\n",
      "Epoch 588/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.6178 - val_acc: 0.8667\n",
      "Epoch 589/1000\n",
      "700/700 [==============================] - 0s 195us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.6180 - val_acc: 0.8667\n",
      "Epoch 590/1000\n",
      "700/700 [==============================] - 0s 190us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.6181 - val_acc: 0.8667\n",
      "Epoch 591/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.6181 - val_acc: 0.8667\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 191us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.6183 - val_acc: 0.8667\n",
      "Epoch 593/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.6183 - val_acc: 0.8667\n",
      "Epoch 594/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.6186 - val_acc: 0.8667\n",
      "Epoch 595/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.6187 - val_acc: 0.8667\n",
      "Epoch 596/1000\n",
      "700/700 [==============================] - 0s 195us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.6189 - val_acc: 0.8667\n",
      "Epoch 597/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.6191 - val_acc: 0.8667\n",
      "Epoch 598/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.6192 - val_acc: 0.8667\n",
      "Epoch 599/1000\n",
      "700/700 [==============================] - 0s 191us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.6193 - val_acc: 0.8667\n",
      "Epoch 600/1000\n",
      "700/700 [==============================] - 0s 176us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.6193 - val_acc: 0.8667\n",
      "Epoch 601/1000\n",
      "700/700 [==============================] - 0s 188us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.6196 - val_acc: 0.8667\n",
      "Epoch 602/1000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.6197 - val_acc: 0.8667\n",
      "Epoch 603/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.6198 - val_acc: 0.8667\n",
      "Epoch 604/1000\n",
      "700/700 [==============================] - 0s 193us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.6199 - val_acc: 0.8667\n",
      "Epoch 605/1000\n",
      "700/700 [==============================] - 0s 188us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.6200 - val_acc: 0.8667\n",
      "Epoch 606/1000\n",
      "700/700 [==============================] - 0s 191us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.6201 - val_acc: 0.8667\n",
      "Epoch 607/1000\n",
      "700/700 [==============================] - 0s 188us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.6202 - val_acc: 0.8667\n",
      "Epoch 608/1000\n",
      "700/700 [==============================] - 0s 196us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.6204 - val_acc: 0.8667\n",
      "Epoch 609/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.6206 - val_acc: 0.8667\n",
      "Epoch 610/1000\n",
      "700/700 [==============================] - 0s 188us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.6207 - val_acc: 0.8667\n",
      "Epoch 611/1000\n",
      "700/700 [==============================] - 0s 190us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.6207 - val_acc: 0.8667\n",
      "Epoch 612/1000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.6208 - val_acc: 0.8667\n",
      "Epoch 613/1000\n",
      "700/700 [==============================] - 0s 206us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.6210 - val_acc: 0.8667\n",
      "Epoch 614/1000\n",
      "700/700 [==============================] - 0s 182us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.6210 - val_acc: 0.8667\n",
      "Epoch 615/1000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.6211 - val_acc: 0.8667\n",
      "Epoch 616/1000\n",
      "700/700 [==============================] - 0s 195us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.6212 - val_acc: 0.8667\n",
      "Epoch 617/1000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.6212 - val_acc: 0.8667\n",
      "Epoch 618/1000\n",
      "700/700 [==============================] - 0s 180us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.6214 - val_acc: 0.8667\n",
      "Epoch 619/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.6216 - val_acc: 0.8667\n",
      "Epoch 620/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.6216 - val_acc: 0.8667\n",
      "Epoch 621/1000\n",
      "700/700 [==============================] - 0s 195us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.6218 - val_acc: 0.8667\n",
      "Epoch 622/1000\n",
      "700/700 [==============================] - 0s 200us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.6219 - val_acc: 0.8667\n",
      "Epoch 623/1000\n",
      "700/700 [==============================] - 0s 206us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.6220 - val_acc: 0.8667\n",
      "Epoch 624/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.6222 - val_acc: 0.8667\n",
      "Epoch 625/1000\n",
      "700/700 [==============================] - 0s 195us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.6223 - val_acc: 0.8667\n",
      "Epoch 626/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.6224 - val_acc: 0.8667\n",
      "Epoch 627/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.6225 - val_acc: 0.8667\n",
      "Epoch 628/1000\n",
      "700/700 [==============================] - 0s 206us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.6226 - val_acc: 0.8667\n",
      "Epoch 629/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.6228 - val_acc: 0.8667\n",
      "Epoch 630/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.6229 - val_acc: 0.8667\n",
      "Epoch 631/1000\n",
      "700/700 [==============================] - 0s 190us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.6231 - val_acc: 0.8667\n",
      "Epoch 632/1000\n",
      "700/700 [==============================] - 0s 197us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.6232 - val_acc: 0.8667\n",
      "Epoch 633/1000\n",
      "700/700 [==============================] - 0s 200us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.6233 - val_acc: 0.8667\n",
      "Epoch 634/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.6234 - val_acc: 0.8667\n",
      "Epoch 635/1000\n",
      "700/700 [==============================] - 0s 206us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.6235 - val_acc: 0.8667\n",
      "Epoch 636/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.6236 - val_acc: 0.8667\n",
      "Epoch 637/1000\n",
      "700/700 [==============================] - 0s 202us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.6236 - val_acc: 0.8667\n",
      "Epoch 638/1000\n",
      "700/700 [==============================] - 0s 196us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.6237 - val_acc: 0.8667\n",
      "Epoch 639/1000\n",
      "700/700 [==============================] - 0s 200us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.6238 - val_acc: 0.8667\n",
      "Epoch 640/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.6239 - val_acc: 0.8667\n",
      "Epoch 641/1000\n",
      "700/700 [==============================] - 0s 196us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.6241 - val_acc: 0.8667\n",
      "Epoch 642/1000\n",
      "700/700 [==============================] - 0s 193us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.6243 - val_acc: 0.8667\n",
      "Epoch 643/1000\n",
      "700/700 [==============================] - 0s 201us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.6245 - val_acc: 0.8667\n",
      "Epoch 644/1000\n",
      "700/700 [==============================] - 0s 201us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.6246 - val_acc: 0.8667\n",
      "Epoch 645/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.6246 - val_acc: 0.8667\n",
      "Epoch 646/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.6248 - val_acc: 0.8667\n",
      "Epoch 647/1000\n",
      "700/700 [==============================] - 0s 190us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.6249 - val_acc: 0.8667\n",
      "Epoch 648/1000\n",
      "700/700 [==============================] - 0s 192us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.6250 - val_acc: 0.8667\n",
      "Epoch 649/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.6252 - val_acc: 0.8667\n",
      "Epoch 650/1000\n",
      "700/700 [==============================] - 0s 200us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.6253 - val_acc: 0.8667\n",
      "Epoch 651/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 188us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.6254 - val_acc: 0.8667\n",
      "Epoch 652/1000\n",
      "700/700 [==============================] - 0s 207us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.6255 - val_acc: 0.8667\n",
      "Epoch 653/1000\n",
      "700/700 [==============================] - 0s 208us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.6257 - val_acc: 0.8667\n",
      "Epoch 654/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.6258 - val_acc: 0.8667\n",
      "Epoch 655/1000\n",
      "700/700 [==============================] - 0s 208us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.6259 - val_acc: 0.8667\n",
      "Epoch 656/1000\n",
      "700/700 [==============================] - 0s 184us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.6261 - val_acc: 0.8667\n",
      "Epoch 657/1000\n",
      "700/700 [==============================] - 0s 192us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.6262 - val_acc: 0.8667\n",
      "Epoch 658/1000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.6263 - val_acc: 0.8667\n",
      "Epoch 659/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.6263 - val_acc: 0.8667\n",
      "Epoch 660/1000\n",
      "700/700 [==============================] - 0s 201us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.6265 - val_acc: 0.8667\n",
      "Epoch 661/1000\n",
      "700/700 [==============================] - 0s 192us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.6266 - val_acc: 0.8667\n",
      "Epoch 662/1000\n",
      "700/700 [==============================] - 0s 205us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.6267 - val_acc: 0.8667\n",
      "Epoch 663/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.6268 - val_acc: 0.8667\n",
      "Epoch 664/1000\n",
      "700/700 [==============================] - 0s 196us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.6270 - val_acc: 0.8667\n",
      "Epoch 665/1000\n",
      "700/700 [==============================] - 0s 205us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.6270 - val_acc: 0.8667\n",
      "Epoch 666/1000\n",
      "700/700 [==============================] - 0s 193us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.6271 - val_acc: 0.8667\n",
      "Epoch 667/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6274 - val_acc: 0.8667\n",
      "Epoch 668/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6274 - val_acc: 0.8667\n",
      "Epoch 669/1000\n",
      "700/700 [==============================] - 0s 197us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6275 - val_acc: 0.8667\n",
      "Epoch 670/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6276 - val_acc: 0.8667\n",
      "Epoch 671/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6276 - val_acc: 0.8667\n",
      "Epoch 672/1000\n",
      "700/700 [==============================] - 0s 200us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6277 - val_acc: 0.8667\n",
      "Epoch 673/1000\n",
      "700/700 [==============================] - 0s 195us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6279 - val_acc: 0.8667\n",
      "Epoch 674/1000\n",
      "700/700 [==============================] - 0s 192us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6280 - val_acc: 0.8667\n",
      "Epoch 675/1000\n",
      "700/700 [==============================] - 0s 196us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6281 - val_acc: 0.8667\n",
      "Epoch 676/1000\n",
      "700/700 [==============================] - 0s 197us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6283 - val_acc: 0.8667\n",
      "Epoch 677/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6284 - val_acc: 0.8667\n",
      "Epoch 678/1000\n",
      "700/700 [==============================] - 0s 202us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6285 - val_acc: 0.8667\n",
      "Epoch 679/1000\n",
      "700/700 [==============================] - 0s 197us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6286 - val_acc: 0.8667\n",
      "Epoch 680/1000\n",
      "700/700 [==============================] - 0s 203us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6287 - val_acc: 0.8667\n",
      "Epoch 681/1000\n",
      "700/700 [==============================] - 0s 196us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6288 - val_acc: 0.8667\n",
      "Epoch 682/1000\n",
      "700/700 [==============================] - 0s 201us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6289 - val_acc: 0.8667\n",
      "Epoch 683/1000\n",
      "700/700 [==============================] - 0s 207us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6290 - val_acc: 0.8667\n",
      "Epoch 684/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6291 - val_acc: 0.8667\n",
      "Epoch 685/1000\n",
      "700/700 [==============================] - 0s 203us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6292 - val_acc: 0.8667\n",
      "Epoch 686/1000\n",
      "700/700 [==============================] - 0s 203us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6293 - val_acc: 0.8667\n",
      "Epoch 687/1000\n",
      "700/700 [==============================] - 0s 208us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6294 - val_acc: 0.8667\n",
      "Epoch 688/1000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6296 - val_acc: 0.8667\n",
      "Epoch 689/1000\n",
      "700/700 [==============================] - 0s 217us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6297 - val_acc: 0.8667\n",
      "Epoch 690/1000\n",
      "700/700 [==============================] - 0s 195us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6298 - val_acc: 0.8667\n",
      "Epoch 691/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6299 - val_acc: 0.8667\n",
      "Epoch 692/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6301 - val_acc: 0.8667\n",
      "Epoch 693/1000\n",
      "700/700 [==============================] - 0s 196us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6301 - val_acc: 0.8667\n",
      "Epoch 694/1000\n",
      "700/700 [==============================] - 0s 207us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6302 - val_acc: 0.8667\n",
      "Epoch 695/1000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6304 - val_acc: 0.8667\n",
      "Epoch 696/1000\n",
      "700/700 [==============================] - 0s 192us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6305 - val_acc: 0.8667\n",
      "Epoch 697/1000\n",
      "700/700 [==============================] - 0s 193us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6306 - val_acc: 0.8667\n",
      "Epoch 698/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6307 - val_acc: 0.8667\n",
      "Epoch 699/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6308 - val_acc: 0.8667\n",
      "Epoch 700/1000\n",
      "700/700 [==============================] - 0s 195us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6309 - val_acc: 0.8667\n",
      "Epoch 701/1000\n",
      "700/700 [==============================] - 0s 205us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6311 - val_acc: 0.8667\n",
      "Epoch 702/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6311 - val_acc: 0.8667\n",
      "Epoch 703/1000\n",
      "700/700 [==============================] - 0s 201us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6312 - val_acc: 0.8667\n",
      "Epoch 704/1000\n",
      "700/700 [==============================] - 0s 195us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6313 - val_acc: 0.8700\n",
      "Epoch 705/1000\n",
      "700/700 [==============================] - 0s 188us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6314 - val_acc: 0.8700\n",
      "Epoch 706/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6316 - val_acc: 0.8700\n",
      "Epoch 707/1000\n",
      "700/700 [==============================] - 0s 202us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6317 - val_acc: 0.8700\n",
      "Epoch 708/1000\n",
      "700/700 [==============================] - 0s 206us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6318 - val_acc: 0.8700\n",
      "Epoch 709/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6319 - val_acc: 0.8700\n",
      "Epoch 710/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 197us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6320 - val_acc: 0.8700\n",
      "Epoch 711/1000\n",
      "700/700 [==============================] - 0s 193us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6320 - val_acc: 0.8700\n",
      "Epoch 712/1000\n",
      "700/700 [==============================] - 0s 192us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6321 - val_acc: 0.8700\n",
      "Epoch 713/1000\n",
      "700/700 [==============================] - 0s 196us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6322 - val_acc: 0.8700\n",
      "Epoch 714/1000\n",
      "700/700 [==============================] - 0s 201us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6324 - val_acc: 0.8700\n",
      "Epoch 715/1000\n",
      "700/700 [==============================] - 0s 201us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6324 - val_acc: 0.8700\n",
      "Epoch 716/1000\n",
      "700/700 [==============================] - 0s 197us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6326 - val_acc: 0.8700\n",
      "Epoch 717/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6328 - val_acc: 0.8700\n",
      "Epoch 718/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6329 - val_acc: 0.8700\n",
      "Epoch 719/1000\n",
      "700/700 [==============================] - 0s 219us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6330 - val_acc: 0.8667\n",
      "Epoch 720/1000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6331 - val_acc: 0.8700\n",
      "Epoch 721/1000\n",
      "700/700 [==============================] - 0s 200us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6332 - val_acc: 0.8700\n",
      "Epoch 722/1000\n",
      "700/700 [==============================] - 0s 207us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6333 - val_acc: 0.8700\n",
      "Epoch 723/1000\n",
      "700/700 [==============================] - 0s 200us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6335 - val_acc: 0.8700\n",
      "Epoch 724/1000\n",
      "700/700 [==============================] - 0s 221us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6335 - val_acc: 0.8700\n",
      "Epoch 725/1000\n",
      "700/700 [==============================] - 0s 206us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6336 - val_acc: 0.8700\n",
      "Epoch 726/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6337 - val_acc: 0.8700\n",
      "Epoch 727/1000\n",
      "700/700 [==============================] - 0s 205us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6338 - val_acc: 0.8700\n",
      "Epoch 728/1000\n",
      "700/700 [==============================] - 0s 214us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6339 - val_acc: 0.8700\n",
      "Epoch 729/1000\n",
      "700/700 [==============================] - 0s 219us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6340 - val_acc: 0.8700\n",
      "Epoch 730/1000\n",
      "700/700 [==============================] - 0s 214us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6341 - val_acc: 0.8700\n",
      "Epoch 731/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6342 - val_acc: 0.8700\n",
      "Epoch 732/1000\n",
      "700/700 [==============================] - 0s 220us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6343 - val_acc: 0.8700\n",
      "Epoch 733/1000\n",
      "700/700 [==============================] - 0s 217us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6344 - val_acc: 0.8700\n",
      "Epoch 734/1000\n",
      "700/700 [==============================] - 0s 218us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6345 - val_acc: 0.8700\n",
      "Epoch 735/1000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6346 - val_acc: 0.8700\n",
      "Epoch 736/1000\n",
      "700/700 [==============================] - 0s 214us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6348 - val_acc: 0.8700\n",
      "Epoch 737/1000\n",
      "700/700 [==============================] - 0s 221us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6348 - val_acc: 0.8700\n",
      "Epoch 738/1000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6349 - val_acc: 0.8700\n",
      "Epoch 739/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6350 - val_acc: 0.8700\n",
      "Epoch 740/1000\n",
      "700/700 [==============================] - 0s 221us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6351 - val_acc: 0.8700\n",
      "Epoch 741/1000\n",
      "700/700 [==============================] - 0s 201us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6353 - val_acc: 0.8700\n",
      "Epoch 742/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6353 - val_acc: 0.8700\n",
      "Epoch 743/1000\n",
      "700/700 [==============================] - 0s 200us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6355 - val_acc: 0.8700\n",
      "Epoch 744/1000\n",
      "700/700 [==============================] - 0s 203us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6355 - val_acc: 0.8700\n",
      "Epoch 745/1000\n",
      "700/700 [==============================] - 0s 205us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6355 - val_acc: 0.8700\n",
      "Epoch 746/1000\n",
      "700/700 [==============================] - 0s 193us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6356 - val_acc: 0.8700\n",
      "Epoch 747/1000\n",
      "700/700 [==============================] - 0s 205us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6357 - val_acc: 0.8700\n",
      "Epoch 748/1000\n",
      "700/700 [==============================] - 0s 203us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6358 - val_acc: 0.8700\n",
      "Epoch 749/1000\n",
      "700/700 [==============================] - 0s 206us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6359 - val_acc: 0.8700\n",
      "Epoch 750/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6361 - val_acc: 0.8700\n",
      "Epoch 751/1000\n",
      "700/700 [==============================] - 0s 197us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6363 - val_acc: 0.8700\n",
      "Epoch 752/1000\n",
      "700/700 [==============================] - 0s 200us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6363 - val_acc: 0.8700\n",
      "Epoch 753/1000\n",
      "700/700 [==============================] - 0s 196us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6364 - val_acc: 0.8700\n",
      "Epoch 754/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6364 - val_acc: 0.8700\n",
      "Epoch 755/1000\n",
      "700/700 [==============================] - 0s 201us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6366 - val_acc: 0.8700\n",
      "Epoch 756/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6367 - val_acc: 0.8700\n",
      "Epoch 757/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6368 - val_acc: 0.8700\n",
      "Epoch 758/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6369 - val_acc: 0.8700\n",
      "Epoch 759/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6370 - val_acc: 0.8700\n",
      "Epoch 760/1000\n",
      "700/700 [==============================] - 0s 192us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6370 - val_acc: 0.8700\n",
      "Epoch 761/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6372 - val_acc: 0.8700\n",
      "Epoch 762/1000\n",
      "700/700 [==============================] - 0s 196us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6373 - val_acc: 0.8700\n",
      "Epoch 763/1000\n",
      "700/700 [==============================] - 0s 207us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6373 - val_acc: 0.8700\n",
      "Epoch 764/1000\n",
      "700/700 [==============================] - 0s 203us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6375 - val_acc: 0.8700\n",
      "Epoch 765/1000\n",
      "700/700 [==============================] - 0s 215us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6375 - val_acc: 0.8700\n",
      "Epoch 766/1000\n",
      "700/700 [==============================] - 0s 208us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6376 - val_acc: 0.8700\n",
      "Epoch 767/1000\n",
      "700/700 [==============================] - 0s 201us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6378 - val_acc: 0.8700\n",
      "Epoch 768/1000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6378 - val_acc: 0.8700\n",
      "Epoch 769/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 231us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6379 - val_acc: 0.8700\n",
      "Epoch 770/1000\n",
      "700/700 [==============================] - 0s 207us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6380 - val_acc: 0.8700\n",
      "Epoch 771/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6380 - val_acc: 0.8700\n",
      "Epoch 772/1000\n",
      "700/700 [==============================] - 0s 217us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6382 - val_acc: 0.8700\n",
      "Epoch 773/1000\n",
      "700/700 [==============================] - 0s 205us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6382 - val_acc: 0.8700\n",
      "Epoch 774/1000\n",
      "700/700 [==============================] - 0s 210us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6383 - val_acc: 0.8700\n",
      "Epoch 775/1000\n",
      "700/700 [==============================] - 0s 201us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6384 - val_acc: 0.8700\n",
      "Epoch 776/1000\n",
      "700/700 [==============================] - 0s 222us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6385 - val_acc: 0.8700\n",
      "Epoch 777/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6386 - val_acc: 0.8700\n",
      "Epoch 778/1000\n",
      "700/700 [==============================] - 0s 215us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6387 - val_acc: 0.8700\n",
      "Epoch 779/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6388 - val_acc: 0.8700\n",
      "Epoch 780/1000\n",
      "700/700 [==============================] - 0s 206us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6389 - val_acc: 0.8700\n",
      "Epoch 781/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6389 - val_acc: 0.8700\n",
      "Epoch 782/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6390 - val_acc: 0.8700\n",
      "Epoch 783/1000\n",
      "700/700 [==============================] - 0s 218us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6391 - val_acc: 0.8700\n",
      "Epoch 784/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6392 - val_acc: 0.8700\n",
      "Epoch 785/1000\n",
      "700/700 [==============================] - 0s 196us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6393 - val_acc: 0.8700\n",
      "Epoch 786/1000\n",
      "700/700 [==============================] - 0s 205us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6393 - val_acc: 0.8700\n",
      "Epoch 787/1000\n",
      "700/700 [==============================] - 0s 198us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6394 - val_acc: 0.8700\n",
      "Epoch 788/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6395 - val_acc: 0.8700\n",
      "Epoch 789/1000\n",
      "700/700 [==============================] - 0s 196us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6397 - val_acc: 0.8700\n",
      "Epoch 790/1000\n",
      "700/700 [==============================] - 0s 215us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6398 - val_acc: 0.8700\n",
      "Epoch 791/1000\n",
      "700/700 [==============================] - 0s 217us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6398 - val_acc: 0.8700\n",
      "Epoch 792/1000\n",
      "700/700 [==============================] - 0s 220us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6400 - val_acc: 0.8700\n",
      "Epoch 793/1000\n",
      "700/700 [==============================] - 0s 203us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6400 - val_acc: 0.8700\n",
      "Epoch 794/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6401 - val_acc: 0.8700\n",
      "Epoch 795/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6402 - val_acc: 0.8700\n",
      "Epoch 796/1000\n",
      "700/700 [==============================] - 0s 208us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6404 - val_acc: 0.8700\n",
      "Epoch 797/1000\n",
      "700/700 [==============================] - 0s 207us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6404 - val_acc: 0.8700\n",
      "Epoch 798/1000\n",
      "700/700 [==============================] - 0s 203us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6405 - val_acc: 0.8700\n",
      "Epoch 799/1000\n",
      "700/700 [==============================] - 0s 205us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6405 - val_acc: 0.8700\n",
      "Epoch 800/1000\n",
      "700/700 [==============================] - 0s 216us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6406 - val_acc: 0.8700\n",
      "Epoch 801/1000\n",
      "700/700 [==============================] - 0s 205us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6406 - val_acc: 0.8700\n",
      "Epoch 802/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6407 - val_acc: 0.8700\n",
      "Epoch 803/1000\n",
      "700/700 [==============================] - 0s 207us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6409 - val_acc: 0.8700\n",
      "Epoch 804/1000\n",
      "700/700 [==============================] - 0s 212us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6409 - val_acc: 0.8700\n",
      "Epoch 805/1000\n",
      "700/700 [==============================] - 0s 208us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6410 - val_acc: 0.8700\n",
      "Epoch 806/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6411 - val_acc: 0.8700\n",
      "Epoch 807/1000\n",
      "700/700 [==============================] - 0s 214us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6412 - val_acc: 0.8700\n",
      "Epoch 808/1000\n",
      "700/700 [==============================] - 0s 201us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6412 - val_acc: 0.8700\n",
      "Epoch 809/1000\n",
      "700/700 [==============================] - 0s 197us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6414 - val_acc: 0.8700\n",
      "Epoch 810/1000\n",
      "700/700 [==============================] - 0s 197us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6414 - val_acc: 0.8700\n",
      "Epoch 811/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6415 - val_acc: 0.8700\n",
      "Epoch 812/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6416 - val_acc: 0.8700\n",
      "Epoch 813/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6417 - val_acc: 0.8700\n",
      "Epoch 814/1000\n",
      "700/700 [==============================] - 0s 202us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6417 - val_acc: 0.8700\n",
      "Epoch 815/1000\n",
      "700/700 [==============================] - 0s 201us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6418 - val_acc: 0.8700\n",
      "Epoch 816/1000\n",
      "700/700 [==============================] - 0s 208us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6419 - val_acc: 0.8700\n",
      "Epoch 817/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6420 - val_acc: 0.8700\n",
      "Epoch 818/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6421 - val_acc: 0.8700\n",
      "Epoch 819/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6422 - val_acc: 0.8700\n",
      "Epoch 820/1000\n",
      "700/700 [==============================] - 0s 207us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6423 - val_acc: 0.8700\n",
      "Epoch 821/1000\n",
      "700/700 [==============================] - 0s 202us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6424 - val_acc: 0.8700\n",
      "Epoch 822/1000\n",
      "700/700 [==============================] - 0s 194us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6425 - val_acc: 0.8700\n",
      "Epoch 823/1000\n",
      "700/700 [==============================] - 0s 203us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6425 - val_acc: 0.8700\n",
      "Epoch 824/1000\n",
      "700/700 [==============================] - 0s 210us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6426 - val_acc: 0.8700\n",
      "Epoch 825/1000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6426 - val_acc: 0.8700\n",
      "Epoch 826/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6427 - val_acc: 0.8700\n",
      "Epoch 827/1000\n",
      "700/700 [==============================] - 0s 202us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6428 - val_acc: 0.8700\n",
      "Epoch 828/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 205us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6429 - val_acc: 0.8700\n",
      "Epoch 829/1000\n",
      "700/700 [==============================] - 0s 203us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6430 - val_acc: 0.8700\n",
      "Epoch 830/1000\n",
      "700/700 [==============================] - 0s 200us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6431 - val_acc: 0.8700\n",
      "Epoch 831/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6432 - val_acc: 0.8700\n",
      "Epoch 832/1000\n",
      "700/700 [==============================] - 0s 215us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6433 - val_acc: 0.8700\n",
      "Epoch 833/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6434 - val_acc: 0.8700\n",
      "Epoch 834/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.0018 - acc: 1.000 - 0s 222us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6435 - val_acc: 0.8700\n",
      "Epoch 835/1000\n",
      "700/700 [==============================] - 0s 208us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6435 - val_acc: 0.8700\n",
      "Epoch 836/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6436 - val_acc: 0.8700\n",
      "Epoch 837/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6437 - val_acc: 0.8700\n",
      "Epoch 838/1000\n",
      "700/700 [==============================] - 0s 220us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6438 - val_acc: 0.8700\n",
      "Epoch 839/1000\n",
      "700/700 [==============================] - 0s 208us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6438 - val_acc: 0.8700\n",
      "Epoch 840/1000\n",
      "700/700 [==============================] - 0s 216us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6439 - val_acc: 0.8700\n",
      "Epoch 841/1000\n",
      "700/700 [==============================] - 0s 208us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6440 - val_acc: 0.8700\n",
      "Epoch 842/1000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6441 - val_acc: 0.8700\n",
      "Epoch 843/1000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6441 - val_acc: 0.8700\n",
      "Epoch 844/1000\n",
      "700/700 [==============================] - 0s 218us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6442 - val_acc: 0.8667\n",
      "Epoch 845/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6442 - val_acc: 0.8667\n",
      "Epoch 846/1000\n",
      "700/700 [==============================] - 0s 214us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6443 - val_acc: 0.8700\n",
      "Epoch 847/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6444 - val_acc: 0.8667\n",
      "Epoch 848/1000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6445 - val_acc: 0.8667\n",
      "Epoch 849/1000\n",
      "700/700 [==============================] - 0s 214us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6446 - val_acc: 0.8667\n",
      "Epoch 850/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6447 - val_acc: 0.8667\n",
      "Epoch 851/1000\n",
      "700/700 [==============================] - 0s 218us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6448 - val_acc: 0.8667\n",
      "Epoch 852/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6449 - val_acc: 0.8667\n",
      "Epoch 853/1000\n",
      "700/700 [==============================] - 0s 225us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6450 - val_acc: 0.8667\n",
      "Epoch 854/1000\n",
      "700/700 [==============================] - 0s 206us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6451 - val_acc: 0.8667\n",
      "Epoch 855/1000\n",
      "700/700 [==============================] - 0s 203us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6451 - val_acc: 0.8667\n",
      "Epoch 856/1000\n",
      "700/700 [==============================] - 0s 215us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6452 - val_acc: 0.8667\n",
      "Epoch 857/1000\n",
      "700/700 [==============================] - 0s 210us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6453 - val_acc: 0.8700\n",
      "Epoch 858/1000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6453 - val_acc: 0.8700\n",
      "Epoch 859/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6454 - val_acc: 0.8667\n",
      "Epoch 860/1000\n",
      "700/700 [==============================] - 0s 208us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6455 - val_acc: 0.8667\n",
      "Epoch 861/1000\n",
      "700/700 [==============================] - 0s 214us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6455 - val_acc: 0.8700\n",
      "Epoch 862/1000\n",
      "700/700 [==============================] - 0s 210us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6456 - val_acc: 0.8667\n",
      "Epoch 863/1000\n",
      "700/700 [==============================] - 0s 217us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6457 - val_acc: 0.8667\n",
      "Epoch 864/1000\n",
      "700/700 [==============================] - 0s 220us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6458 - val_acc: 0.8667\n",
      "Epoch 865/1000\n",
      "700/700 [==============================] - 0s 212us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6459 - val_acc: 0.8667\n",
      "Epoch 866/1000\n",
      "700/700 [==============================] - 0s 214us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6459 - val_acc: 0.8667\n",
      "Epoch 867/1000\n",
      "700/700 [==============================] - 0s 222us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6460 - val_acc: 0.8667\n",
      "Epoch 868/1000\n",
      "700/700 [==============================] - 0s 216us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6461 - val_acc: 0.8667\n",
      "Epoch 869/1000\n",
      "700/700 [==============================] - 0s 219us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6461 - val_acc: 0.8667\n",
      "Epoch 870/1000\n",
      "700/700 [==============================] - 0s 208us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6462 - val_acc: 0.8667\n",
      "Epoch 871/1000\n",
      "700/700 [==============================] - 0s 225us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6462 - val_acc: 0.8667\n",
      "Epoch 872/1000\n",
      "700/700 [==============================] - 0s 207us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6464 - val_acc: 0.8667\n",
      "Epoch 873/1000\n",
      "700/700 [==============================] - 0s 208us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6465 - val_acc: 0.8667\n",
      "Epoch 874/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6466 - val_acc: 0.8667\n",
      "Epoch 875/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6467 - val_acc: 0.8667\n",
      "Epoch 876/1000\n",
      "700/700 [==============================] - 0s 217us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6467 - val_acc: 0.8667\n",
      "Epoch 877/1000\n",
      "700/700 [==============================] - 0s 215us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6468 - val_acc: 0.8667\n",
      "Epoch 878/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6469 - val_acc: 0.8667\n",
      "Epoch 879/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6469 - val_acc: 0.8667\n",
      "Epoch 880/1000\n",
      "700/700 [==============================] - 0s 214us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6470 - val_acc: 0.8667\n",
      "Epoch 881/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6471 - val_acc: 0.8667\n",
      "Epoch 882/1000\n",
      "700/700 [==============================] - 0s 208us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6472 - val_acc: 0.8667\n",
      "Epoch 883/1000\n",
      "700/700 [==============================] - 0s 207us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6473 - val_acc: 0.8667\n",
      "Epoch 884/1000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6474 - val_acc: 0.8667\n",
      "Epoch 885/1000\n",
      "700/700 [==============================] - 0s 210us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6475 - val_acc: 0.8667\n",
      "Epoch 886/1000\n",
      "700/700 [==============================] - 0s 210us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6475 - val_acc: 0.8667\n",
      "Epoch 887/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 221us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6476 - val_acc: 0.8667\n",
      "Epoch 888/1000\n",
      "700/700 [==============================] - 0s 220us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6477 - val_acc: 0.8667\n",
      "Epoch 889/1000\n",
      "700/700 [==============================] - 0s 216us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6479 - val_acc: 0.8667\n",
      "Epoch 890/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6479 - val_acc: 0.8667\n",
      "Epoch 891/1000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6480 - val_acc: 0.8667\n",
      "Epoch 892/1000\n",
      "700/700 [==============================] - 0s 221us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6480 - val_acc: 0.8667\n",
      "Epoch 893/1000\n",
      "700/700 [==============================] - 0s 216us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6480 - val_acc: 0.8667\n",
      "Epoch 894/1000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6482 - val_acc: 0.8667\n",
      "Epoch 895/1000\n",
      "700/700 [==============================] - 0s 210us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6482 - val_acc: 0.8667\n",
      "Epoch 896/1000\n",
      "700/700 [==============================] - 0s 210us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6483 - val_acc: 0.8667\n",
      "Epoch 897/1000\n",
      "700/700 [==============================] - 0s 216us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6484 - val_acc: 0.8667\n",
      "Epoch 898/1000\n",
      "700/700 [==============================] - 0s 219us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6485 - val_acc: 0.8667\n",
      "Epoch 899/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6485 - val_acc: 0.8667\n",
      "Epoch 900/1000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6486 - val_acc: 0.8667\n",
      "Epoch 901/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6487 - val_acc: 0.8667\n",
      "Epoch 902/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6487 - val_acc: 0.8667\n",
      "Epoch 903/1000\n",
      "700/700 [==============================] - 0s 205us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6488 - val_acc: 0.8667\n",
      "Epoch 904/1000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6488 - val_acc: 0.8667\n",
      "Epoch 905/1000\n",
      "700/700 [==============================] - 0s 216us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6489 - val_acc: 0.8667\n",
      "Epoch 906/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6489 - val_acc: 0.8667\n",
      "Epoch 907/1000\n",
      "700/700 [==============================] - 0s 212us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6490 - val_acc: 0.8667\n",
      "Epoch 908/1000\n",
      "700/700 [==============================] - 0s 220us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6491 - val_acc: 0.8667\n",
      "Epoch 909/1000\n",
      "700/700 [==============================] - 0s 210us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6492 - val_acc: 0.8667\n",
      "Epoch 910/1000\n",
      "700/700 [==============================] - 0s 216us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6494 - val_acc: 0.8667\n",
      "Epoch 911/1000\n",
      "700/700 [==============================] - 0s 212us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6494 - val_acc: 0.8667\n",
      "Epoch 912/1000\n",
      "700/700 [==============================] - 0s 221us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6495 - val_acc: 0.8667\n",
      "Epoch 913/1000\n",
      "700/700 [==============================] - 0s 214us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6495 - val_acc: 0.8667\n",
      "Epoch 914/1000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6496 - val_acc: 0.8667\n",
      "Epoch 915/1000\n",
      "700/700 [==============================] - 0s 218us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6497 - val_acc: 0.8667\n",
      "Epoch 916/1000\n",
      "700/700 [==============================] - 0s 219us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6498 - val_acc: 0.8667\n",
      "Epoch 917/1000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6499 - val_acc: 0.8667\n",
      "Epoch 918/1000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6499 - val_acc: 0.8667\n",
      "Epoch 919/1000\n",
      "700/700 [==============================] - 0s 206us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6499 - val_acc: 0.8667\n",
      "Epoch 920/1000\n",
      "700/700 [==============================] - 0s 210us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6500 - val_acc: 0.8667\n",
      "Epoch 921/1000\n",
      "700/700 [==============================] - 0s 204us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6501 - val_acc: 0.8667\n",
      "Epoch 922/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6502 - val_acc: 0.8667\n",
      "Epoch 923/1000\n",
      "700/700 [==============================] - 0s 220us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6503 - val_acc: 0.8667\n",
      "Epoch 924/1000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6504 - val_acc: 0.8667\n",
      "Epoch 925/1000\n",
      "700/700 [==============================] - 0s 219us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6504 - val_acc: 0.8667\n",
      "Epoch 926/1000\n",
      "700/700 [==============================] - 0s 218us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6505 - val_acc: 0.8667\n",
      "Epoch 927/1000\n",
      "700/700 [==============================] - 0s 216us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6506 - val_acc: 0.8667\n",
      "Epoch 928/1000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6506 - val_acc: 0.8667\n",
      "Epoch 929/1000\n",
      "700/700 [==============================] - 0s 219us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6507 - val_acc: 0.8667\n",
      "Epoch 930/1000\n",
      "700/700 [==============================] - 0s 225us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6508 - val_acc: 0.8667\n",
      "Epoch 931/1000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6509 - val_acc: 0.8667\n",
      "Epoch 932/1000\n",
      "700/700 [==============================] - 0s 222us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6509 - val_acc: 0.8667\n",
      "Epoch 933/1000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6510 - val_acc: 0.8667\n",
      "Epoch 934/1000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6511 - val_acc: 0.8667\n",
      "Epoch 935/1000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6512 - val_acc: 0.8667\n",
      "Epoch 936/1000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6512 - val_acc: 0.8667\n",
      "Epoch 937/1000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6513 - val_acc: 0.8667\n",
      "Epoch 938/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6514 - val_acc: 0.8667\n",
      "Epoch 939/1000\n",
      "700/700 [==============================] - 0s 218us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6515 - val_acc: 0.8667\n",
      "Epoch 940/1000\n",
      "700/700 [==============================] - 0s 215us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6516 - val_acc: 0.8667\n",
      "Epoch 941/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6517 - val_acc: 0.8667\n",
      "Epoch 942/1000\n",
      "700/700 [==============================] - 0s 232us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6517 - val_acc: 0.8667\n",
      "Epoch 943/1000\n",
      "700/700 [==============================] - 0s 218us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6518 - val_acc: 0.8667\n",
      "Epoch 944/1000\n",
      "700/700 [==============================] - 0s 215us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6519 - val_acc: 0.8667\n",
      "Epoch 945/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6520 - val_acc: 0.8667\n",
      "Epoch 946/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 218us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6520 - val_acc: 0.8667\n",
      "Epoch 947/1000\n",
      "700/700 [==============================] - 0s 222us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6521 - val_acc: 0.8667\n",
      "Epoch 948/1000\n",
      "700/700 [==============================] - 0s 212us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6522 - val_acc: 0.8667\n",
      "Epoch 949/1000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6522 - val_acc: 0.8667\n",
      "Epoch 950/1000\n",
      "700/700 [==============================] - 0s 232us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6523 - val_acc: 0.8667\n",
      "Epoch 951/1000\n",
      "700/700 [==============================] - 0s 218us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6524 - val_acc: 0.8667\n",
      "Epoch 952/1000\n",
      "700/700 [==============================] - 0s 221us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6525 - val_acc: 0.8667\n",
      "Epoch 953/1000\n",
      "700/700 [==============================] - 0s 218us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6525 - val_acc: 0.8667\n",
      "Epoch 954/1000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6526 - val_acc: 0.8667\n",
      "Epoch 955/1000\n",
      "700/700 [==============================] - 0s 233us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6527 - val_acc: 0.8667\n",
      "Epoch 956/1000\n",
      "700/700 [==============================] - 0s 207us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6527 - val_acc: 0.8667\n",
      "Epoch 957/1000\n",
      "700/700 [==============================] - 0s 210us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6527 - val_acc: 0.8667\n",
      "Epoch 958/1000\n",
      "700/700 [==============================] - 0s 220us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6528 - val_acc: 0.8667\n",
      "Epoch 959/1000\n",
      "700/700 [==============================] - 0s 234us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6529 - val_acc: 0.8667\n",
      "Epoch 960/1000\n",
      "700/700 [==============================] - 0s 216us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6529 - val_acc: 0.8667\n",
      "Epoch 961/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6530 - val_acc: 0.8667\n",
      "Epoch 962/1000\n",
      "700/700 [==============================] - 0s 235us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6531 - val_acc: 0.8667\n",
      "Epoch 963/1000\n",
      "700/700 [==============================] - 0s 219us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6532 - val_acc: 0.8667\n",
      "Epoch 964/1000\n",
      "700/700 [==============================] - 0s 221us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6532 - val_acc: 0.8667\n",
      "Epoch 965/1000\n",
      "700/700 [==============================] - 0s 216us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6533 - val_acc: 0.8667\n",
      "Epoch 966/1000\n",
      "700/700 [==============================] - 0s 222us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6534 - val_acc: 0.8667\n",
      "Epoch 967/1000\n",
      "700/700 [==============================] - 0s 213us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6535 - val_acc: 0.8667\n",
      "Epoch 968/1000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6535 - val_acc: 0.8667\n",
      "Epoch 969/1000\n",
      "700/700 [==============================] - 0s 219us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6536 - val_acc: 0.8667\n",
      "Epoch 970/1000\n",
      "700/700 [==============================] - 0s 220us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6536 - val_acc: 0.8667\n",
      "Epoch 971/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6537 - val_acc: 0.8667\n",
      "Epoch 972/1000\n",
      "700/700 [==============================] - 0s 219us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6538 - val_acc: 0.8667\n",
      "Epoch 973/1000\n",
      "700/700 [==============================] - 0s 220us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6538 - val_acc: 0.8667\n",
      "Epoch 974/1000\n",
      "700/700 [==============================] - 0s 217us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6539 - val_acc: 0.8667\n",
      "Epoch 975/1000\n",
      "700/700 [==============================] - 0s 225us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6540 - val_acc: 0.8667\n",
      "Epoch 976/1000\n",
      "700/700 [==============================] - 0s 220us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6541 - val_acc: 0.8667\n",
      "Epoch 977/1000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6542 - val_acc: 0.8667\n",
      "Epoch 978/1000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6542 - val_acc: 0.8667\n",
      "Epoch 979/1000\n",
      "700/700 [==============================] - 0s 216us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6543 - val_acc: 0.8667\n",
      "Epoch 980/1000\n",
      "700/700 [==============================] - 0s 227us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6544 - val_acc: 0.8667\n",
      "Epoch 981/1000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6545 - val_acc: 0.8667\n",
      "Epoch 982/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6545 - val_acc: 0.8667\n",
      "Epoch 983/1000\n",
      "700/700 [==============================] - 0s 217us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6545 - val_acc: 0.8667\n",
      "Epoch 984/1000\n",
      "700/700 [==============================] - 0s 208us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6546 - val_acc: 0.8667\n",
      "Epoch 985/1000\n",
      "700/700 [==============================] - 0s 205us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6547 - val_acc: 0.8667\n",
      "Epoch 986/1000\n",
      "700/700 [==============================] - 0s 217us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6548 - val_acc: 0.8667\n",
      "Epoch 987/1000\n",
      "700/700 [==============================] - 0s 222us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6549 - val_acc: 0.8667\n",
      "Epoch 988/1000\n",
      "700/700 [==============================] - 0s 216us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6549 - val_acc: 0.8667\n",
      "Epoch 989/1000\n",
      "700/700 [==============================] - 0s 228us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6550 - val_acc: 0.8667\n",
      "Epoch 990/1000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6551 - val_acc: 0.8667\n",
      "Epoch 991/1000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6552 - val_acc: 0.8667\n",
      "Epoch 992/1000\n",
      "700/700 [==============================] - 0s 214us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6552 - val_acc: 0.8667\n",
      "Epoch 993/1000\n",
      "700/700 [==============================] - 0s 214us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6553 - val_acc: 0.8667\n",
      "Epoch 994/1000\n",
      "700/700 [==============================] - 0s 223us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6554 - val_acc: 0.8667\n",
      "Epoch 995/1000\n",
      "700/700 [==============================] - 0s 217us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6554 - val_acc: 0.8667\n",
      "Epoch 996/1000\n",
      "700/700 [==============================] - 0s 219us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6555 - val_acc: 0.8667\n",
      "Epoch 997/1000\n",
      "700/700 [==============================] - 0s 216us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6556 - val_acc: 0.8667\n",
      "Epoch 998/1000\n",
      "700/700 [==============================] - 0s 212us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6556 - val_acc: 0.8667\n",
      "Epoch 999/1000\n",
      "700/700 [==============================] - 0s 230us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6557 - val_acc: 0.8667\n",
      "Epoch 1000/1000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6558 - val_acc: 0.8667\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train, epochs=1000, batch_size=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습 과정 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAEKCAYAAAC2bZqoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyckYY0zM+X/48gBYOmkN8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa6e7ec32e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서플로우 연동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 2.2576 - acc: 0.1643 - val_loss: 2.2272 - val_acc: 0.1633\n",
      "Epoch 2/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 2.2071 - acc: 0.1671 - val_loss: 2.1907 - val_acc: 0.1800\n",
      "Epoch 3/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 2.1728 - acc: 0.1729 - val_loss: 2.1629 - val_acc: 0.1867\n",
      "Epoch 4/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 2.1439 - acc: 0.1786 - val_loss: 2.1369 - val_acc: 0.1867\n",
      "Epoch 5/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 2.1174 - acc: 0.1900 - val_loss: 2.1138 - val_acc: 0.1867\n",
      "Epoch 6/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 2.0937 - acc: 0.2029 - val_loss: 2.0924 - val_acc: 0.2033\n",
      "Epoch 7/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 2.0715 - acc: 0.2086 - val_loss: 2.0723 - val_acc: 0.2067\n",
      "Epoch 8/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 2.0516 - acc: 0.2129 - val_loss: 2.0562 - val_acc: 0.2067\n",
      "Epoch 9/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 2.0337 - acc: 0.2157 - val_loss: 2.0407 - val_acc: 0.2033\n",
      "Epoch 10/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 2.0184 - acc: 0.2114 - val_loss: 2.0269 - val_acc: 0.2067\n",
      "Epoch 11/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 2.0038 - acc: 0.2200 - val_loss: 2.0121 - val_acc: 0.2100\n",
      "Epoch 12/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.9908 - acc: 0.2186 - val_loss: 2.0034 - val_acc: 0.2100\n",
      "Epoch 13/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.9784 - acc: 0.2271 - val_loss: 1.9951 - val_acc: 0.2100\n",
      "Epoch 14/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.9681 - acc: 0.2300 - val_loss: 1.9828 - val_acc: 0.2033\n",
      "Epoch 15/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.9578 - acc: 0.2200 - val_loss: 1.9749 - val_acc: 0.2067\n",
      "Epoch 16/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.9480 - acc: 0.2371 - val_loss: 1.9680 - val_acc: 0.2033\n",
      "Epoch 17/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.9389 - acc: 0.2343 - val_loss: 1.9608 - val_acc: 0.2033\n",
      "Epoch 18/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.9305 - acc: 0.2314 - val_loss: 1.9533 - val_acc: 0.2100\n",
      "Epoch 19/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.9228 - acc: 0.2271 - val_loss: 1.9448 - val_acc: 0.2100\n",
      "Epoch 20/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.9152 - acc: 0.2386 - val_loss: 1.9388 - val_acc: 0.2100\n",
      "Epoch 21/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.9081 - acc: 0.2300 - val_loss: 1.9357 - val_acc: 0.2067\n",
      "Epoch 22/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.9008 - acc: 0.2386 - val_loss: 1.9286 - val_acc: 0.2033\n",
      "Epoch 23/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.8950 - acc: 0.2357 - val_loss: 1.9230 - val_acc: 0.2100\n",
      "Epoch 24/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.8890 - acc: 0.2314 - val_loss: 1.9202 - val_acc: 0.2100\n",
      "Epoch 25/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.8826 - acc: 0.2357 - val_loss: 1.9176 - val_acc: 0.2167\n",
      "Epoch 26/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.8766 - acc: 0.2286 - val_loss: 1.9101 - val_acc: 0.2167\n",
      "Epoch 27/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.8711 - acc: 0.2357 - val_loss: 1.9097 - val_acc: 0.2167\n",
      "Epoch 28/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.8659 - acc: 0.2414 - val_loss: 1.9088 - val_acc: 0.2000\n",
      "Epoch 29/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.8611 - acc: 0.2400 - val_loss: 1.9057 - val_acc: 0.1900\n",
      "Epoch 30/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.8562 - acc: 0.2229 - val_loss: 1.8975 - val_acc: 0.2167\n",
      "Epoch 31/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.8510 - acc: 0.2471 - val_loss: 1.8971 - val_acc: 0.1933\n",
      "Epoch 32/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.8460 - acc: 0.2343 - val_loss: 1.8924 - val_acc: 0.1867\n",
      "Epoch 33/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.8420 - acc: 0.2214 - val_loss: 1.8874 - val_acc: 0.2067\n",
      "Epoch 34/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.8379 - acc: 0.2371 - val_loss: 1.8808 - val_acc: 0.1933\n",
      "Epoch 35/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.8331 - acc: 0.2471 - val_loss: 1.8836 - val_acc: 0.1800\n",
      "Epoch 36/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.8296 - acc: 0.2343 - val_loss: 1.8754 - val_acc: 0.1967\n",
      "Epoch 37/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.8254 - acc: 0.2486 - val_loss: 1.8744 - val_acc: 0.1767\n",
      "Epoch 38/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.8217 - acc: 0.2371 - val_loss: 1.8700 - val_acc: 0.1933\n",
      "Epoch 39/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.8181 - acc: 0.2443 - val_loss: 1.8706 - val_acc: 0.1800\n",
      "Epoch 40/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.8140 - acc: 0.2300 - val_loss: 1.8680 - val_acc: 0.2000\n",
      "Epoch 41/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.8102 - acc: 0.2429 - val_loss: 1.8669 - val_acc: 0.1833\n",
      "Epoch 42/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.8072 - acc: 0.2500 - val_loss: 1.8636 - val_acc: 0.1833\n",
      "Epoch 43/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.8041 - acc: 0.2429 - val_loss: 1.8610 - val_acc: 0.1700\n",
      "Epoch 44/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.7999 - acc: 0.2357 - val_loss: 1.8573 - val_acc: 0.2000\n",
      "Epoch 45/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.7966 - acc: 0.2457 - val_loss: 1.8566 - val_acc: 0.1700\n",
      "Epoch 46/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.7935 - acc: 0.2271 - val_loss: 1.8527 - val_acc: 0.1900\n",
      "Epoch 47/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.7910 - acc: 0.2614 - val_loss: 1.8552 - val_acc: 0.1767\n",
      "Epoch 48/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.7883 - acc: 0.2500 - val_loss: 1.8544 - val_acc: 0.1800\n",
      "Epoch 49/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.7855 - acc: 0.2471 - val_loss: 1.8505 - val_acc: 0.1900\n",
      "Epoch 50/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.7816 - acc: 0.2457 - val_loss: 1.8443 - val_acc: 0.2267\n",
      "Epoch 51/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.7791 - acc: 0.2629 - val_loss: 1.8469 - val_acc: 0.1867\n",
      "Epoch 52/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.7759 - acc: 0.2486 - val_loss: 1.8412 - val_acc: 0.1933\n",
      "Epoch 53/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.7740 - acc: 0.2514 - val_loss: 1.8489 - val_acc: 0.1967\n",
      "Epoch 54/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.7713 - acc: 0.2686 - val_loss: 1.8475 - val_acc: 0.1800\n",
      "Epoch 55/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.7684 - acc: 0.2514 - val_loss: 1.8366 - val_acc: 0.2067\n",
      "Epoch 56/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.7670 - acc: 0.2543 - val_loss: 1.8421 - val_acc: 0.2233\n",
      "Epoch 57/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.7637 - acc: 0.2714 - val_loss: 1.8389 - val_acc: 0.2167\n",
      "Epoch 58/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.7613 - acc: 0.2557 - val_loss: 1.8346 - val_acc: 0.2267\n",
      "Epoch 59/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.7587 - acc: 0.2671 - val_loss: 1.8331 - val_acc: 0.2233\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 154us/step - loss: 1.7549 - acc: 0.2614 - val_loss: 1.8262 - val_acc: 0.2467\n",
      "Epoch 61/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.7563 - acc: 0.2814 - val_loss: 1.8339 - val_acc: 0.2400\n",
      "Epoch 62/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.7528 - acc: 0.2700 - val_loss: 1.8314 - val_acc: 0.2267\n",
      "Epoch 63/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.7502 - acc: 0.2871 - val_loss: 1.8304 - val_acc: 0.2033\n",
      "Epoch 64/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.7481 - acc: 0.2771 - val_loss: 1.8269 - val_acc: 0.2200\n",
      "Epoch 65/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.7454 - acc: 0.2829 - val_loss: 1.8299 - val_acc: 0.2000\n",
      "Epoch 66/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.7436 - acc: 0.2800 - val_loss: 1.8299 - val_acc: 0.2067\n",
      "Epoch 67/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.7416 - acc: 0.2714 - val_loss: 1.8301 - val_acc: 0.2033\n",
      "Epoch 68/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.7402 - acc: 0.2729 - val_loss: 1.8245 - val_acc: 0.2000\n",
      "Epoch 69/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.7373 - acc: 0.2814 - val_loss: 1.8303 - val_acc: 0.2200\n",
      "Epoch 70/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.7354 - acc: 0.2829 - val_loss: 1.8277 - val_acc: 0.2433\n",
      "Epoch 71/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.7342 - acc: 0.2786 - val_loss: 1.8220 - val_acc: 0.2167\n",
      "Epoch 72/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.7326 - acc: 0.2843 - val_loss: 1.8224 - val_acc: 0.2133\n",
      "Epoch 73/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.7295 - acc: 0.2857 - val_loss: 1.8250 - val_acc: 0.2533\n",
      "Epoch 74/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.7281 - acc: 0.2857 - val_loss: 1.8255 - val_acc: 0.1967\n",
      "Epoch 75/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.7265 - acc: 0.2786 - val_loss: 1.8190 - val_acc: 0.2267\n",
      "Epoch 76/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.7252 - acc: 0.2871 - val_loss: 1.8197 - val_acc: 0.2233\n",
      "Epoch 77/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.7225 - acc: 0.3043 - val_loss: 1.8234 - val_acc: 0.2000\n",
      "Epoch 78/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.7210 - acc: 0.2857 - val_loss: 1.8190 - val_acc: 0.1900\n",
      "Epoch 79/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.7197 - acc: 0.2800 - val_loss: 1.8198 - val_acc: 0.2433\n",
      "Epoch 80/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.7185 - acc: 0.2957 - val_loss: 1.8200 - val_acc: 0.2067\n",
      "Epoch 81/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.7164 - acc: 0.2800 - val_loss: 1.8255 - val_acc: 0.2067\n",
      "Epoch 82/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.7139 - acc: 0.2743 - val_loss: 1.8160 - val_acc: 0.2700\n",
      "Epoch 83/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.7130 - acc: 0.2829 - val_loss: 1.8200 - val_acc: 0.2400\n",
      "Epoch 84/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.7125 - acc: 0.2957 - val_loss: 1.8223 - val_acc: 0.2133\n",
      "Epoch 85/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.7094 - acc: 0.2986 - val_loss: 1.8170 - val_acc: 0.2300\n",
      "Epoch 86/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.7079 - acc: 0.2814 - val_loss: 1.8155 - val_acc: 0.2600\n",
      "Epoch 87/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.7048 - acc: 0.3057 - val_loss: 1.8201 - val_acc: 0.2667\n",
      "Epoch 88/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.7060 - acc: 0.3043 - val_loss: 1.8117 - val_acc: 0.2433\n",
      "Epoch 89/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.7042 - acc: 0.3043 - val_loss: 1.8179 - val_acc: 0.2200\n",
      "Epoch 90/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.7025 - acc: 0.2814 - val_loss: 1.8158 - val_acc: 0.2233\n",
      "Epoch 91/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.7015 - acc: 0.3086 - val_loss: 1.8191 - val_acc: 0.2167\n",
      "Epoch 92/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.6983 - acc: 0.3129 - val_loss: 1.8229 - val_acc: 0.2067\n",
      "Epoch 93/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.6978 - acc: 0.3071 - val_loss: 1.8179 - val_acc: 0.2733\n",
      "Epoch 94/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.6967 - acc: 0.3157 - val_loss: 1.8194 - val_acc: 0.2133\n",
      "Epoch 95/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.6940 - acc: 0.3057 - val_loss: 1.8190 - val_acc: 0.2767\n",
      "Epoch 96/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.6946 - acc: 0.2957 - val_loss: 1.8105 - val_acc: 0.2267\n",
      "Epoch 97/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.6928 - acc: 0.3000 - val_loss: 1.8237 - val_acc: 0.2367\n",
      "Epoch 98/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.6920 - acc: 0.3000 - val_loss: 1.8134 - val_acc: 0.2167\n",
      "Epoch 99/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.6899 - acc: 0.3100 - val_loss: 1.8264 - val_acc: 0.2200\n",
      "Epoch 100/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.6888 - acc: 0.3114 - val_loss: 1.8227 - val_acc: 0.2267\n",
      "Epoch 101/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.6875 - acc: 0.3129 - val_loss: 1.8203 - val_acc: 0.2200\n",
      "Epoch 102/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.6875 - acc: 0.3014 - val_loss: 1.8218 - val_acc: 0.2300\n",
      "Epoch 103/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.6841 - acc: 0.3000 - val_loss: 1.8110 - val_acc: 0.2500\n",
      "Epoch 104/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.6840 - acc: 0.3171 - val_loss: 1.8130 - val_acc: 0.2233\n",
      "Epoch 105/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.6818 - acc: 0.3029 - val_loss: 1.8070 - val_acc: 0.2067\n",
      "Epoch 106/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.6811 - acc: 0.3171 - val_loss: 1.8185 - val_acc: 0.2267\n",
      "Epoch 107/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.6802 - acc: 0.3114 - val_loss: 1.8237 - val_acc: 0.2400\n",
      "Epoch 108/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.6781 - acc: 0.3057 - val_loss: 1.8175 - val_acc: 0.2767\n",
      "Epoch 109/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.6781 - acc: 0.3143 - val_loss: 1.8187 - val_acc: 0.2233\n",
      "Epoch 110/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.6774 - acc: 0.3214 - val_loss: 1.8158 - val_acc: 0.2100\n",
      "Epoch 111/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.6774 - acc: 0.3000 - val_loss: 1.8184 - val_acc: 0.2267\n",
      "Epoch 112/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.6744 - acc: 0.3143 - val_loss: 1.8206 - val_acc: 0.2233\n",
      "Epoch 113/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.6736 - acc: 0.3100 - val_loss: 1.8216 - val_acc: 0.2233\n",
      "Epoch 114/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.6723 - acc: 0.3000 - val_loss: 1.8236 - val_acc: 0.2267\n",
      "Epoch 115/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.6710 - acc: 0.3071 - val_loss: 1.8141 - val_acc: 0.2333\n",
      "Epoch 116/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.6703 - acc: 0.3171 - val_loss: 1.8247 - val_acc: 0.2267\n",
      "Epoch 117/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.6692 - acc: 0.3114 - val_loss: 1.8239 - val_acc: 0.2400\n",
      "Epoch 118/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.6681 - acc: 0.3100 - val_loss: 1.8283 - val_acc: 0.2367\n",
      "Epoch 119/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.6670 - acc: 0.3243 - val_loss: 1.8239 - val_acc: 0.2200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.6660 - acc: 0.3143 - val_loss: 1.8210 - val_acc: 0.2200\n",
      "Epoch 121/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.6646 - acc: 0.3043 - val_loss: 1.8119 - val_acc: 0.2233\n",
      "Epoch 122/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.6636 - acc: 0.3186 - val_loss: 1.8204 - val_acc: 0.2133\n",
      "Epoch 123/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.6633 - acc: 0.3100 - val_loss: 1.8142 - val_acc: 0.2200\n",
      "Epoch 124/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.6618 - acc: 0.3114 - val_loss: 1.8213 - val_acc: 0.2167\n",
      "Epoch 125/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.6607 - acc: 0.3257 - val_loss: 1.8227 - val_acc: 0.2300\n",
      "Epoch 126/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.6591 - acc: 0.3100 - val_loss: 1.8252 - val_acc: 0.2267\n",
      "Epoch 127/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.6583 - acc: 0.3100 - val_loss: 1.8154 - val_acc: 0.2300\n",
      "Epoch 128/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.6565 - acc: 0.3271 - val_loss: 1.8292 - val_acc: 0.2300\n",
      "Epoch 129/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.6570 - acc: 0.3143 - val_loss: 1.8206 - val_acc: 0.2133\n",
      "Epoch 130/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.6548 - acc: 0.3214 - val_loss: 1.8133 - val_acc: 0.2533\n",
      "Epoch 131/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.6547 - acc: 0.3214 - val_loss: 1.8211 - val_acc: 0.2500\n",
      "Epoch 132/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.6546 - acc: 0.3200 - val_loss: 1.8143 - val_acc: 0.2267\n",
      "Epoch 133/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.6525 - acc: 0.3129 - val_loss: 1.8340 - val_acc: 0.2400\n",
      "Epoch 134/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.6515 - acc: 0.3271 - val_loss: 1.8231 - val_acc: 0.2700\n",
      "Epoch 135/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.6512 - acc: 0.3300 - val_loss: 1.8245 - val_acc: 0.2300\n",
      "Epoch 136/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.6493 - acc: 0.3214 - val_loss: 1.8175 - val_acc: 0.2200\n",
      "Epoch 137/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.6484 - acc: 0.3186 - val_loss: 1.8221 - val_acc: 0.2233\n",
      "Epoch 138/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.6489 - acc: 0.3286 - val_loss: 1.8223 - val_acc: 0.2167\n",
      "Epoch 139/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.6467 - acc: 0.3200 - val_loss: 1.8476 - val_acc: 0.2333\n",
      "Epoch 140/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.6466 - acc: 0.3186 - val_loss: 1.8181 - val_acc: 0.2167\n",
      "Epoch 141/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.6447 - acc: 0.3243 - val_loss: 1.8305 - val_acc: 0.2233\n",
      "Epoch 142/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.6434 - acc: 0.3286 - val_loss: 1.8219 - val_acc: 0.2633\n",
      "Epoch 143/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.6435 - acc: 0.3314 - val_loss: 1.8356 - val_acc: 0.2467\n",
      "Epoch 144/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.6430 - acc: 0.3357 - val_loss: 1.8271 - val_acc: 0.2267\n",
      "Epoch 145/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.6416 - acc: 0.3257 - val_loss: 1.8237 - val_acc: 0.2233\n",
      "Epoch 146/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.6390 - acc: 0.3343 - val_loss: 1.8355 - val_acc: 0.2233\n",
      "Epoch 147/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.6411 - acc: 0.3057 - val_loss: 1.8344 - val_acc: 0.2267\n",
      "Epoch 148/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.6390 - acc: 0.3186 - val_loss: 1.8282 - val_acc: 0.2467\n",
      "Epoch 149/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.6379 - acc: 0.3243 - val_loss: 1.8247 - val_acc: 0.2233\n",
      "Epoch 150/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.6370 - acc: 0.3214 - val_loss: 1.8290 - val_acc: 0.2200\n",
      "Epoch 151/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.6367 - acc: 0.3257 - val_loss: 1.8254 - val_acc: 0.2267\n",
      "Epoch 152/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.6353 - acc: 0.3171 - val_loss: 1.8304 - val_acc: 0.2233\n",
      "Epoch 153/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.6340 - acc: 0.3386 - val_loss: 1.8290 - val_acc: 0.2267\n",
      "Epoch 154/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.6321 - acc: 0.3471 - val_loss: 1.8369 - val_acc: 0.2267\n",
      "Epoch 155/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.6320 - acc: 0.3243 - val_loss: 1.8206 - val_acc: 0.2333\n",
      "Epoch 156/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.6327 - acc: 0.3314 - val_loss: 1.8360 - val_acc: 0.2267\n",
      "Epoch 157/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.6311 - acc: 0.3286 - val_loss: 1.8269 - val_acc: 0.2133\n",
      "Epoch 158/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.6310 - acc: 0.3329 - val_loss: 1.8343 - val_acc: 0.2300\n",
      "Epoch 159/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.6289 - acc: 0.3286 - val_loss: 1.8349 - val_acc: 0.2433\n",
      "Epoch 160/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.6281 - acc: 0.3300 - val_loss: 1.8336 - val_acc: 0.2233\n",
      "Epoch 161/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.6275 - acc: 0.3214 - val_loss: 1.8414 - val_acc: 0.2267\n",
      "Epoch 162/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.6268 - acc: 0.3257 - val_loss: 1.8375 - val_acc: 0.2267\n",
      "Epoch 163/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.6257 - acc: 0.3371 - val_loss: 1.8367 - val_acc: 0.2300\n",
      "Epoch 164/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.6242 - acc: 0.3343 - val_loss: 1.8283 - val_acc: 0.2067\n",
      "Epoch 165/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.6239 - acc: 0.3171 - val_loss: 1.8414 - val_acc: 0.2367\n",
      "Epoch 166/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.6234 - acc: 0.3300 - val_loss: 1.8363 - val_acc: 0.2233\n",
      "Epoch 167/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.6224 - acc: 0.3257 - val_loss: 1.8406 - val_acc: 0.2567\n",
      "Epoch 168/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.6211 - acc: 0.3343 - val_loss: 1.8460 - val_acc: 0.2200\n",
      "Epoch 169/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.6202 - acc: 0.3371 - val_loss: 1.8544 - val_acc: 0.2233\n",
      "Epoch 170/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.6195 - acc: 0.3371 - val_loss: 1.8384 - val_acc: 0.2167\n",
      "Epoch 171/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.6174 - acc: 0.3229 - val_loss: 1.8530 - val_acc: 0.2633\n",
      "Epoch 172/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.6167 - acc: 0.3371 - val_loss: 1.8416 - val_acc: 0.2133\n",
      "Epoch 173/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.6186 - acc: 0.3400 - val_loss: 1.8407 - val_acc: 0.2367\n",
      "Epoch 174/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.6171 - acc: 0.3300 - val_loss: 1.8433 - val_acc: 0.2200\n",
      "Epoch 175/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.6170 - acc: 0.3300 - val_loss: 1.8418 - val_acc: 0.2200\n",
      "Epoch 176/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.6146 - acc: 0.3229 - val_loss: 1.8453 - val_acc: 0.2633\n",
      "Epoch 177/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.6138 - acc: 0.3357 - val_loss: 1.8401 - val_acc: 0.2167\n",
      "Epoch 178/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.6144 - acc: 0.3386 - val_loss: 1.8442 - val_acc: 0.2300\n",
      "Epoch 179/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 118us/step - loss: 1.6139 - acc: 0.3343 - val_loss: 1.8371 - val_acc: 0.2200\n",
      "Epoch 180/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.6114 - acc: 0.3357 - val_loss: 1.8429 - val_acc: 0.2667\n",
      "Epoch 181/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.6119 - acc: 0.3400 - val_loss: 1.8354 - val_acc: 0.2600\n",
      "Epoch 182/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.6110 - acc: 0.3429 - val_loss: 1.8384 - val_acc: 0.2133\n",
      "Epoch 183/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.6119 - acc: 0.3300 - val_loss: 1.8459 - val_acc: 0.2300\n",
      "Epoch 184/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.6097 - acc: 0.3386 - val_loss: 1.8474 - val_acc: 0.2267\n",
      "Epoch 185/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.6080 - acc: 0.3414 - val_loss: 1.8661 - val_acc: 0.2200\n",
      "Epoch 186/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.6091 - acc: 0.3414 - val_loss: 1.8465 - val_acc: 0.2167\n",
      "Epoch 187/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.6070 - acc: 0.3529 - val_loss: 1.8479 - val_acc: 0.2067\n",
      "Epoch 188/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.6080 - acc: 0.3386 - val_loss: 1.8440 - val_acc: 0.2133\n",
      "Epoch 189/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.6049 - acc: 0.3500 - val_loss: 1.8565 - val_acc: 0.2267\n",
      "Epoch 190/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.6071 - acc: 0.3300 - val_loss: 1.8427 - val_acc: 0.2300\n",
      "Epoch 191/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.6047 - acc: 0.3500 - val_loss: 1.8588 - val_acc: 0.2167\n",
      "Epoch 192/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.6049 - acc: 0.3429 - val_loss: 1.8532 - val_acc: 0.2200\n",
      "Epoch 193/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.6034 - acc: 0.3343 - val_loss: 1.8565 - val_acc: 0.2267\n",
      "Epoch 194/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.6030 - acc: 0.3371 - val_loss: 1.8492 - val_acc: 0.2267\n",
      "Epoch 195/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.6023 - acc: 0.3457 - val_loss: 1.8475 - val_acc: 0.2433\n",
      "Epoch 196/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.6021 - acc: 0.3500 - val_loss: 1.8494 - val_acc: 0.2167\n",
      "Epoch 197/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.6007 - acc: 0.3429 - val_loss: 1.8512 - val_acc: 0.2300\n",
      "Epoch 198/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.6010 - acc: 0.3371 - val_loss: 1.8629 - val_acc: 0.2133\n",
      "Epoch 199/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.6008 - acc: 0.3371 - val_loss: 1.8586 - val_acc: 0.2233\n",
      "Epoch 200/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5978 - acc: 0.3457 - val_loss: 1.8636 - val_acc: 0.2600\n",
      "Epoch 201/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5992 - acc: 0.3457 - val_loss: 1.8496 - val_acc: 0.2133\n",
      "Epoch 202/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5985 - acc: 0.3443 - val_loss: 1.8517 - val_acc: 0.2133\n",
      "Epoch 203/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5969 - acc: 0.3314 - val_loss: 1.8595 - val_acc: 0.2300\n",
      "Epoch 204/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5958 - acc: 0.3514 - val_loss: 1.8492 - val_acc: 0.2100\n",
      "Epoch 205/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5959 - acc: 0.3386 - val_loss: 1.8531 - val_acc: 0.2200\n",
      "Epoch 206/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.5951 - acc: 0.3514 - val_loss: 1.8490 - val_acc: 0.2100\n",
      "Epoch 207/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.5952 - acc: 0.3557 - val_loss: 1.8570 - val_acc: 0.2233\n",
      "Epoch 208/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5924 - acc: 0.3400 - val_loss: 1.8574 - val_acc: 0.2267\n",
      "Epoch 209/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5925 - acc: 0.3457 - val_loss: 1.8541 - val_acc: 0.2333\n",
      "Epoch 210/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5920 - acc: 0.3414 - val_loss: 1.8540 - val_acc: 0.2300\n",
      "Epoch 211/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5908 - acc: 0.3357 - val_loss: 1.8477 - val_acc: 0.2600\n",
      "Epoch 212/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5919 - acc: 0.3429 - val_loss: 1.8628 - val_acc: 0.2300\n",
      "Epoch 213/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.5899 - acc: 0.3457 - val_loss: 1.8549 - val_acc: 0.2267\n",
      "Epoch 214/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5912 - acc: 0.3443 - val_loss: 1.8590 - val_acc: 0.2300\n",
      "Epoch 215/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5889 - acc: 0.3486 - val_loss: 1.8645 - val_acc: 0.2700\n",
      "Epoch 216/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5902 - acc: 0.3471 - val_loss: 1.8669 - val_acc: 0.2233\n",
      "Epoch 217/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5887 - acc: 0.3429 - val_loss: 1.8668 - val_acc: 0.2233\n",
      "Epoch 218/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.5882 - acc: 0.3457 - val_loss: 1.8612 - val_acc: 0.2333\n",
      "Epoch 219/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5871 - acc: 0.3471 - val_loss: 1.8705 - val_acc: 0.2200\n",
      "Epoch 220/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5861 - acc: 0.3486 - val_loss: 1.8604 - val_acc: 0.2267\n",
      "Epoch 221/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5862 - acc: 0.3486 - val_loss: 1.8644 - val_acc: 0.2267\n",
      "Epoch 222/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5852 - acc: 0.3471 - val_loss: 1.8780 - val_acc: 0.2467\n",
      "Epoch 223/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5850 - acc: 0.3443 - val_loss: 1.8637 - val_acc: 0.2567\n",
      "Epoch 224/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5852 - acc: 0.3471 - val_loss: 1.8792 - val_acc: 0.2433\n",
      "Epoch 225/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5839 - acc: 0.3443 - val_loss: 1.8594 - val_acc: 0.2200\n",
      "Epoch 226/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.5842 - acc: 0.3443 - val_loss: 1.8717 - val_acc: 0.2267\n",
      "Epoch 227/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.5831 - acc: 0.3486 - val_loss: 1.8663 - val_acc: 0.2133\n",
      "Epoch 228/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5829 - acc: 0.3471 - val_loss: 1.8756 - val_acc: 0.2233\n",
      "Epoch 229/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5808 - acc: 0.3500 - val_loss: 1.8726 - val_acc: 0.2233\n",
      "Epoch 230/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5826 - acc: 0.3429 - val_loss: 1.8662 - val_acc: 0.2133\n",
      "Epoch 231/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5804 - acc: 0.3543 - val_loss: 1.8656 - val_acc: 0.2267\n",
      "Epoch 232/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5816 - acc: 0.3529 - val_loss: 1.8773 - val_acc: 0.2200\n",
      "Epoch 233/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5803 - acc: 0.3486 - val_loss: 1.8825 - val_acc: 0.2267\n",
      "Epoch 234/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5798 - acc: 0.3414 - val_loss: 1.8703 - val_acc: 0.2100\n",
      "Epoch 235/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5783 - acc: 0.3557 - val_loss: 1.8729 - val_acc: 0.2100\n",
      "Epoch 236/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5785 - acc: 0.3400 - val_loss: 1.8680 - val_acc: 0.2200\n",
      "Epoch 237/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5778 - acc: 0.3414 - val_loss: 1.8742 - val_acc: 0.2300\n",
      "Epoch 238/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 117us/step - loss: 1.5781 - acc: 0.3414 - val_loss: 1.8657 - val_acc: 0.2133\n",
      "Epoch 239/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.5777 - acc: 0.3529 - val_loss: 1.8722 - val_acc: 0.2300\n",
      "Epoch 240/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5756 - acc: 0.3500 - val_loss: 1.8785 - val_acc: 0.2567\n",
      "Epoch 241/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5755 - acc: 0.3500 - val_loss: 1.8778 - val_acc: 0.2467\n",
      "Epoch 242/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5750 - acc: 0.3486 - val_loss: 1.8770 - val_acc: 0.2067\n",
      "Epoch 243/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5750 - acc: 0.3586 - val_loss: 1.8844 - val_acc: 0.2167\n",
      "Epoch 244/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5720 - acc: 0.3543 - val_loss: 1.8761 - val_acc: 0.2100\n",
      "Epoch 245/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.5722 - acc: 0.3571 - val_loss: 1.8874 - val_acc: 0.2200\n",
      "Epoch 246/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5717 - acc: 0.3557 - val_loss: 1.8741 - val_acc: 0.2600\n",
      "Epoch 247/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5730 - acc: 0.3543 - val_loss: 1.8665 - val_acc: 0.2200\n",
      "Epoch 248/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.5723 - acc: 0.3486 - val_loss: 1.8731 - val_acc: 0.2333\n",
      "Epoch 249/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5720 - acc: 0.3386 - val_loss: 1.8879 - val_acc: 0.2233\n",
      "Epoch 250/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.5686 - acc: 0.3671 - val_loss: 1.9025 - val_acc: 0.2167\n",
      "Epoch 251/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5712 - acc: 0.3471 - val_loss: 1.8830 - val_acc: 0.2500\n",
      "Epoch 252/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5689 - acc: 0.3629 - val_loss: 1.8774 - val_acc: 0.2300\n",
      "Epoch 253/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5698 - acc: 0.3514 - val_loss: 1.8853 - val_acc: 0.2167\n",
      "Epoch 254/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5684 - acc: 0.3600 - val_loss: 1.8873 - val_acc: 0.2200\n",
      "Epoch 255/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5689 - acc: 0.3429 - val_loss: 1.8747 - val_acc: 0.2233\n",
      "Epoch 256/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5664 - acc: 0.3600 - val_loss: 1.8793 - val_acc: 0.2600\n",
      "Epoch 257/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5675 - acc: 0.3486 - val_loss: 1.8948 - val_acc: 0.2500\n",
      "Epoch 258/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5655 - acc: 0.3600 - val_loss: 1.8979 - val_acc: 0.2600\n",
      "Epoch 259/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5657 - acc: 0.3657 - val_loss: 1.8950 - val_acc: 0.2133\n",
      "Epoch 260/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.5665 - acc: 0.3571 - val_loss: 1.9016 - val_acc: 0.2167\n",
      "Epoch 261/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5646 - acc: 0.3557 - val_loss: 1.8778 - val_acc: 0.2167\n",
      "Epoch 262/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5645 - acc: 0.3586 - val_loss: 1.8884 - val_acc: 0.2133\n",
      "Epoch 263/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5640 - acc: 0.3586 - val_loss: 1.8905 - val_acc: 0.2067\n",
      "Epoch 264/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5647 - acc: 0.3514 - val_loss: 1.8866 - val_acc: 0.2133\n",
      "Epoch 265/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5647 - acc: 0.3643 - val_loss: 1.8958 - val_acc: 0.2233\n",
      "Epoch 266/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5622 - acc: 0.3571 - val_loss: 1.9013 - val_acc: 0.2533\n",
      "Epoch 267/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5621 - acc: 0.3614 - val_loss: 1.8963 - val_acc: 0.2267\n",
      "Epoch 268/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5620 - acc: 0.3586 - val_loss: 1.8787 - val_acc: 0.2167\n",
      "Epoch 269/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5608 - acc: 0.3657 - val_loss: 1.8884 - val_acc: 0.2200\n",
      "Epoch 270/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5602 - acc: 0.3657 - val_loss: 1.8720 - val_acc: 0.2300\n",
      "Epoch 271/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5619 - acc: 0.3657 - val_loss: 1.8953 - val_acc: 0.2400\n",
      "Epoch 272/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.5605 - acc: 0.3543 - val_loss: 1.9074 - val_acc: 0.2233\n",
      "Epoch 273/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5600 - acc: 0.3529 - val_loss: 1.9005 - val_acc: 0.2133\n",
      "Epoch 274/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5597 - acc: 0.3386 - val_loss: 1.8882 - val_acc: 0.2300\n",
      "Epoch 275/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5597 - acc: 0.3557 - val_loss: 1.8962 - val_acc: 0.2133\n",
      "Epoch 276/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5588 - acc: 0.3486 - val_loss: 1.9007 - val_acc: 0.2633\n",
      "Epoch 277/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5589 - acc: 0.3714 - val_loss: 1.8954 - val_acc: 0.2133\n",
      "Epoch 278/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5588 - acc: 0.3571 - val_loss: 1.9065 - val_acc: 0.2300\n",
      "Epoch 279/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5568 - acc: 0.3557 - val_loss: 1.8898 - val_acc: 0.2200\n",
      "Epoch 280/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5569 - acc: 0.3700 - val_loss: 1.8924 - val_acc: 0.2133\n",
      "Epoch 281/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5549 - acc: 0.3543 - val_loss: 1.8945 - val_acc: 0.2367\n",
      "Epoch 282/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5562 - acc: 0.3729 - val_loss: 1.8884 - val_acc: 0.2167\n",
      "Epoch 283/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.5551 - acc: 0.3543 - val_loss: 1.8974 - val_acc: 0.2133\n",
      "Epoch 284/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5551 - acc: 0.3586 - val_loss: 1.9001 - val_acc: 0.2500\n",
      "Epoch 285/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5543 - acc: 0.3571 - val_loss: 1.8939 - val_acc: 0.2267\n",
      "Epoch 286/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5545 - acc: 0.3557 - val_loss: 1.9043 - val_acc: 0.2167\n",
      "Epoch 287/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5536 - acc: 0.3643 - val_loss: 1.9077 - val_acc: 0.2100\n",
      "Epoch 288/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5535 - acc: 0.3529 - val_loss: 1.8991 - val_acc: 0.2167\n",
      "Epoch 289/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5528 - acc: 0.3586 - val_loss: 1.9070 - val_acc: 0.2100\n",
      "Epoch 290/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5524 - acc: 0.3614 - val_loss: 1.9084 - val_acc: 0.2133\n",
      "Epoch 291/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5522 - acc: 0.3586 - val_loss: 1.9095 - val_acc: 0.2167\n",
      "Epoch 292/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.5520 - acc: 0.3557 - val_loss: 1.9023 - val_acc: 0.2467\n",
      "Epoch 293/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5518 - acc: 0.3529 - val_loss: 1.9055 - val_acc: 0.2333\n",
      "Epoch 294/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.5506 - acc: 0.3529 - val_loss: 1.9086 - val_acc: 0.2600\n",
      "Epoch 295/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5510 - acc: 0.3671 - val_loss: 1.9147 - val_acc: 0.2167\n",
      "Epoch 296/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5505 - acc: 0.3557 - val_loss: 1.9144 - val_acc: 0.2100\n",
      "Epoch 297/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 111us/step - loss: 1.5487 - acc: 0.3543 - val_loss: 1.9209 - val_acc: 0.2133\n",
      "Epoch 298/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5487 - acc: 0.3486 - val_loss: 1.9012 - val_acc: 0.2267\n",
      "Epoch 299/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5495 - acc: 0.3643 - val_loss: 1.9196 - val_acc: 0.2300\n",
      "Epoch 300/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5482 - acc: 0.3657 - val_loss: 1.9083 - val_acc: 0.2300\n",
      "Epoch 301/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5480 - acc: 0.3643 - val_loss: 1.8985 - val_acc: 0.2167\n",
      "Epoch 302/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5491 - acc: 0.3600 - val_loss: 1.9147 - val_acc: 0.2133\n",
      "Epoch 303/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5475 - acc: 0.3543 - val_loss: 1.9081 - val_acc: 0.2333\n",
      "Epoch 304/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.5676 - acc: 0.360 - 0s 121us/step - loss: 1.5462 - acc: 0.3629 - val_loss: 1.9073 - val_acc: 0.2167\n",
      "Epoch 305/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5443 - acc: 0.3643 - val_loss: 1.9205 - val_acc: 0.2167\n",
      "Epoch 306/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5470 - acc: 0.3586 - val_loss: 1.9135 - val_acc: 0.2300\n",
      "Epoch 307/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.5446 - acc: 0.3629 - val_loss: 1.9125 - val_acc: 0.2300\n",
      "Epoch 308/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5463 - acc: 0.3600 - val_loss: 1.9178 - val_acc: 0.2300\n",
      "Epoch 309/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5446 - acc: 0.3629 - val_loss: 1.9176 - val_acc: 0.2300\n",
      "Epoch 310/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5458 - acc: 0.3671 - val_loss: 1.9163 - val_acc: 0.2167\n",
      "Epoch 311/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5438 - acc: 0.3514 - val_loss: 1.9110 - val_acc: 0.2267\n",
      "Epoch 312/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5433 - acc: 0.3714 - val_loss: 1.9320 - val_acc: 0.2400\n",
      "Epoch 313/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5395 - acc: 0.3671 - val_loss: 1.9113 - val_acc: 0.2600\n",
      "Epoch 314/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5444 - acc: 0.3686 - val_loss: 1.9184 - val_acc: 0.2267\n",
      "Epoch 315/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5415 - acc: 0.3614 - val_loss: 1.9181 - val_acc: 0.2167\n",
      "Epoch 316/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5414 - acc: 0.3586 - val_loss: 1.9196 - val_acc: 0.2233\n",
      "Epoch 317/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5423 - acc: 0.3614 - val_loss: 1.9267 - val_acc: 0.2267\n",
      "Epoch 318/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5418 - acc: 0.3586 - val_loss: 1.9167 - val_acc: 0.2333\n",
      "Epoch 319/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.5400 - acc: 0.3614 - val_loss: 1.9141 - val_acc: 0.2267\n",
      "Epoch 320/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.5403 - acc: 0.3586 - val_loss: 1.9330 - val_acc: 0.2233\n",
      "Epoch 321/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5403 - acc: 0.3657 - val_loss: 1.9298 - val_acc: 0.2233\n",
      "Epoch 322/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5384 - acc: 0.3586 - val_loss: 1.9272 - val_acc: 0.2533\n",
      "Epoch 323/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5394 - acc: 0.3686 - val_loss: 1.9256 - val_acc: 0.2300\n",
      "Epoch 324/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5381 - acc: 0.3657 - val_loss: 1.9294 - val_acc: 0.2100\n",
      "Epoch 325/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5399 - acc: 0.3571 - val_loss: 1.9176 - val_acc: 0.2167\n",
      "Epoch 326/1000\n",
      "700/700 [==============================] - 0s 170us/step - loss: 1.5376 - acc: 0.3614 - val_loss: 1.9320 - val_acc: 0.2200\n",
      "Epoch 327/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5368 - acc: 0.3729 - val_loss: 1.9448 - val_acc: 0.2300\n",
      "Epoch 328/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5378 - acc: 0.3643 - val_loss: 1.9360 - val_acc: 0.2167\n",
      "Epoch 329/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5365 - acc: 0.3700 - val_loss: 1.9214 - val_acc: 0.2300\n",
      "Epoch 330/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.5363 - acc: 0.3614 - val_loss: 1.9286 - val_acc: 0.2300\n",
      "Epoch 331/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5348 - acc: 0.3686 - val_loss: 1.9157 - val_acc: 0.2167\n",
      "Epoch 332/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5356 - acc: 0.3514 - val_loss: 1.9407 - val_acc: 0.2467\n",
      "Epoch 333/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5370 - acc: 0.3657 - val_loss: 1.9301 - val_acc: 0.2333\n",
      "Epoch 334/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5361 - acc: 0.3557 - val_loss: 1.9355 - val_acc: 0.2267\n",
      "Epoch 335/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.5336 - acc: 0.3743 - val_loss: 1.9314 - val_acc: 0.2567\n",
      "Epoch 336/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5347 - acc: 0.3743 - val_loss: 1.9257 - val_acc: 0.2300\n",
      "Epoch 337/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5342 - acc: 0.3671 - val_loss: 1.9401 - val_acc: 0.2267\n",
      "Epoch 338/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5331 - acc: 0.3757 - val_loss: 1.9312 - val_acc: 0.2133\n",
      "Epoch 339/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5323 - acc: 0.3700 - val_loss: 1.9211 - val_acc: 0.2133\n",
      "Epoch 340/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5340 - acc: 0.3686 - val_loss: 1.9448 - val_acc: 0.2200\n",
      "Epoch 341/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5329 - acc: 0.3786 - val_loss: 1.9322 - val_acc: 0.2267\n",
      "Epoch 342/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5324 - acc: 0.3600 - val_loss: 1.9484 - val_acc: 0.2200\n",
      "Epoch 343/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5322 - acc: 0.3643 - val_loss: 1.9379 - val_acc: 0.2333\n",
      "Epoch 344/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5321 - acc: 0.3671 - val_loss: 1.9487 - val_acc: 0.2200\n",
      "Epoch 345/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5302 - acc: 0.3714 - val_loss: 1.9484 - val_acc: 0.2533\n",
      "Epoch 346/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.5313 - acc: 0.3700 - val_loss: 1.9362 - val_acc: 0.2300\n",
      "Epoch 347/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5290 - acc: 0.3771 - val_loss: 1.9238 - val_acc: 0.2200\n",
      "Epoch 348/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5295 - acc: 0.3614 - val_loss: 1.9390 - val_acc: 0.2100\n",
      "Epoch 349/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5295 - acc: 0.3671 - val_loss: 1.9335 - val_acc: 0.2133\n",
      "Epoch 350/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5293 - acc: 0.3614 - val_loss: 1.9413 - val_acc: 0.2300\n",
      "Epoch 351/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5274 - acc: 0.3686 - val_loss: 1.9315 - val_acc: 0.2267\n",
      "Epoch 352/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5295 - acc: 0.3729 - val_loss: 1.9379 - val_acc: 0.2300\n",
      "Epoch 353/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5267 - acc: 0.3671 - val_loss: 1.9501 - val_acc: 0.2300\n",
      "Epoch 354/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5293 - acc: 0.3714 - val_loss: 1.9433 - val_acc: 0.2300\n",
      "Epoch 355/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5275 - acc: 0.3600 - val_loss: 1.9616 - val_acc: 0.2300\n",
      "Epoch 356/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 120us/step - loss: 1.5274 - acc: 0.3714 - val_loss: 1.9497 - val_acc: 0.2433\n",
      "Epoch 357/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5272 - acc: 0.3714 - val_loss: 1.9427 - val_acc: 0.2300\n",
      "Epoch 358/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5267 - acc: 0.3657 - val_loss: 1.9533 - val_acc: 0.2200\n",
      "Epoch 359/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5269 - acc: 0.3657 - val_loss: 1.9511 - val_acc: 0.2200\n",
      "Epoch 360/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5245 - acc: 0.3714 - val_loss: 1.9520 - val_acc: 0.2300\n",
      "Epoch 361/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5246 - acc: 0.3686 - val_loss: 1.9540 - val_acc: 0.2300\n",
      "Epoch 362/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.5256 - acc: 0.3629 - val_loss: 1.9557 - val_acc: 0.2167\n",
      "Epoch 363/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5229 - acc: 0.3729 - val_loss: 1.9570 - val_acc: 0.2200\n",
      "Epoch 364/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5246 - acc: 0.3514 - val_loss: 1.9421 - val_acc: 0.2300\n",
      "Epoch 365/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.5242 - acc: 0.3800 - val_loss: 1.9542 - val_acc: 0.2267\n",
      "Epoch 366/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5241 - acc: 0.3671 - val_loss: 1.9472 - val_acc: 0.2167\n",
      "Epoch 367/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5239 - acc: 0.3757 - val_loss: 1.9577 - val_acc: 0.2233\n",
      "Epoch 368/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5225 - acc: 0.3771 - val_loss: 1.9558 - val_acc: 0.2200\n",
      "Epoch 369/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5226 - acc: 0.3643 - val_loss: 1.9360 - val_acc: 0.2300\n",
      "Epoch 370/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5215 - acc: 0.3743 - val_loss: 1.9582 - val_acc: 0.2400\n",
      "Epoch 371/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5227 - acc: 0.3643 - val_loss: 1.9566 - val_acc: 0.2267\n",
      "Epoch 372/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5213 - acc: 0.3714 - val_loss: 1.9643 - val_acc: 0.2200\n",
      "Epoch 373/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5224 - acc: 0.3714 - val_loss: 1.9522 - val_acc: 0.2167\n",
      "Epoch 374/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.5214 - acc: 0.3629 - val_loss: 1.9569 - val_acc: 0.2300\n",
      "Epoch 375/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.5197 - acc: 0.3814 - val_loss: 1.9425 - val_acc: 0.2233\n",
      "Epoch 376/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5199 - acc: 0.3729 - val_loss: 1.9544 - val_acc: 0.2067\n",
      "Epoch 377/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5187 - acc: 0.3686 - val_loss: 1.9809 - val_acc: 0.2267\n",
      "Epoch 378/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5198 - acc: 0.3700 - val_loss: 1.9827 - val_acc: 0.2333\n",
      "Epoch 379/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5205 - acc: 0.3643 - val_loss: 1.9589 - val_acc: 0.2400\n",
      "Epoch 380/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5183 - acc: 0.3571 - val_loss: 1.9633 - val_acc: 0.2567\n",
      "Epoch 381/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5196 - acc: 0.3757 - val_loss: 1.9791 - val_acc: 0.2200\n",
      "Epoch 382/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5179 - acc: 0.3686 - val_loss: 1.9641 - val_acc: 0.2167\n",
      "Epoch 383/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5169 - acc: 0.3700 - val_loss: 1.9768 - val_acc: 0.2533\n",
      "Epoch 384/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5182 - acc: 0.3714 - val_loss: 1.9547 - val_acc: 0.2233\n",
      "Epoch 385/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5178 - acc: 0.3743 - val_loss: 1.9628 - val_acc: 0.2200\n",
      "Epoch 386/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5172 - acc: 0.3614 - val_loss: 1.9549 - val_acc: 0.2333\n",
      "Epoch 387/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5169 - acc: 0.3586 - val_loss: 1.9623 - val_acc: 0.2267\n",
      "Epoch 388/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5159 - acc: 0.3643 - val_loss: 1.9740 - val_acc: 0.2533\n",
      "Epoch 389/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.5175 - acc: 0.3771 - val_loss: 1.9569 - val_acc: 0.2233\n",
      "Epoch 390/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5140 - acc: 0.3671 - val_loss: 1.9601 - val_acc: 0.2367\n",
      "Epoch 391/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5146 - acc: 0.3757 - val_loss: 1.9591 - val_acc: 0.2333\n",
      "Epoch 392/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5153 - acc: 0.3700 - val_loss: 1.9650 - val_acc: 0.2233\n",
      "Epoch 393/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5155 - acc: 0.3757 - val_loss: 1.9795 - val_acc: 0.2233\n",
      "Epoch 394/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5150 - acc: 0.3714 - val_loss: 1.9653 - val_acc: 0.2300\n",
      "Epoch 395/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5147 - acc: 0.3729 - val_loss: 1.9626 - val_acc: 0.2233\n",
      "Epoch 396/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5141 - acc: 0.3714 - val_loss: 1.9642 - val_acc: 0.2233\n",
      "Epoch 397/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5129 - acc: 0.3843 - val_loss: 1.9811 - val_acc: 0.2233\n",
      "Epoch 398/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5143 - acc: 0.3614 - val_loss: 1.9619 - val_acc: 0.2267\n",
      "Epoch 399/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5130 - acc: 0.3729 - val_loss: 1.9866 - val_acc: 0.2400\n",
      "Epoch 400/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5135 - acc: 0.3614 - val_loss: 1.9685 - val_acc: 0.2133\n",
      "Epoch 401/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.5133 - acc: 0.3571 - val_loss: 1.9695 - val_acc: 0.2333\n",
      "Epoch 402/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5108 - acc: 0.3786 - val_loss: 1.9761 - val_acc: 0.2267\n",
      "Epoch 403/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5096 - acc: 0.3800 - val_loss: 1.9957 - val_acc: 0.2233\n",
      "Epoch 404/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5111 - acc: 0.3714 - val_loss: 1.9671 - val_acc: 0.2333\n",
      "Epoch 405/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5097 - acc: 0.3786 - val_loss: 1.9853 - val_acc: 0.2333\n",
      "Epoch 406/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5110 - acc: 0.3757 - val_loss: 1.9911 - val_acc: 0.2300\n",
      "Epoch 407/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.5112 - acc: 0.3757 - val_loss: 1.9781 - val_acc: 0.2333\n",
      "Epoch 408/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5107 - acc: 0.3786 - val_loss: 1.9726 - val_acc: 0.2300\n",
      "Epoch 409/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5069 - acc: 0.3729 - val_loss: 1.9926 - val_acc: 0.2300\n",
      "Epoch 410/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5090 - acc: 0.3800 - val_loss: 1.9698 - val_acc: 0.2333\n",
      "Epoch 411/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.5090 - acc: 0.3686 - val_loss: 1.9922 - val_acc: 0.2233\n",
      "Epoch 412/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.5084 - acc: 0.3829 - val_loss: 1.9820 - val_acc: 0.2233\n",
      "Epoch 413/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5063 - acc: 0.3743 - val_loss: 1.9779 - val_acc: 0.2367\n",
      "Epoch 414/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5076 - acc: 0.3743 - val_loss: 1.9940 - val_acc: 0.2300\n",
      "Epoch 415/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 119us/step - loss: 1.5048 - acc: 0.3671 - val_loss: 1.9884 - val_acc: 0.2300\n",
      "Epoch 416/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.5058 - acc: 0.3729 - val_loss: 2.0021 - val_acc: 0.2167\n",
      "Epoch 417/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5068 - acc: 0.3700 - val_loss: 1.9949 - val_acc: 0.2200\n",
      "Epoch 418/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5049 - acc: 0.3786 - val_loss: 1.9821 - val_acc: 0.2267\n",
      "Epoch 419/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5052 - acc: 0.3757 - val_loss: 1.9757 - val_acc: 0.2200\n",
      "Epoch 420/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5048 - acc: 0.3757 - val_loss: 2.0029 - val_acc: 0.2333\n",
      "Epoch 421/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5049 - acc: 0.3771 - val_loss: 1.9771 - val_acc: 0.2400\n",
      "Epoch 422/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5038 - acc: 0.3686 - val_loss: 1.9777 - val_acc: 0.2367\n",
      "Epoch 423/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5035 - acc: 0.3814 - val_loss: 1.9882 - val_acc: 0.2300\n",
      "Epoch 424/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5032 - acc: 0.3671 - val_loss: 1.9655 - val_acc: 0.2200\n",
      "Epoch 425/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5023 - acc: 0.3900 - val_loss: 1.9683 - val_acc: 0.2367\n",
      "Epoch 426/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5016 - acc: 0.3971 - val_loss: 1.9864 - val_acc: 0.2133\n",
      "Epoch 427/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.5015 - acc: 0.3800 - val_loss: 1.9890 - val_acc: 0.2567\n",
      "Epoch 428/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.5020 - acc: 0.3857 - val_loss: 2.0095 - val_acc: 0.2300\n",
      "Epoch 429/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.5021 - acc: 0.3686 - val_loss: 1.9730 - val_acc: 0.2300\n",
      "Epoch 430/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.5012 - acc: 0.3786 - val_loss: 1.9857 - val_acc: 0.2500\n",
      "Epoch 431/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5024 - acc: 0.3771 - val_loss: 1.9914 - val_acc: 0.2300\n",
      "Epoch 432/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5011 - acc: 0.3757 - val_loss: 1.9871 - val_acc: 0.2200\n",
      "Epoch 433/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5002 - acc: 0.3729 - val_loss: 1.9893 - val_acc: 0.2267\n",
      "Epoch 434/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5014 - acc: 0.3729 - val_loss: 2.0006 - val_acc: 0.2233\n",
      "Epoch 435/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4994 - acc: 0.3843 - val_loss: 1.9847 - val_acc: 0.2300\n",
      "Epoch 436/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5010 - acc: 0.3800 - val_loss: 1.9759 - val_acc: 0.2233\n",
      "Epoch 437/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4989 - acc: 0.3886 - val_loss: 2.0065 - val_acc: 0.2200\n",
      "Epoch 438/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4979 - acc: 0.3757 - val_loss: 1.9702 - val_acc: 0.2300\n",
      "Epoch 439/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4978 - acc: 0.3729 - val_loss: 1.9834 - val_acc: 0.2267\n",
      "Epoch 440/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4991 - acc: 0.3743 - val_loss: 1.9837 - val_acc: 0.2300\n",
      "Epoch 441/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4982 - acc: 0.3743 - val_loss: 1.9867 - val_acc: 0.2200\n",
      "Epoch 442/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4973 - acc: 0.3814 - val_loss: 2.0021 - val_acc: 0.2167\n",
      "Epoch 443/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4966 - acc: 0.3786 - val_loss: 1.9957 - val_acc: 0.2400\n",
      "Epoch 444/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.4888 - acc: 0.375 - 0s 119us/step - loss: 1.4977 - acc: 0.3743 - val_loss: 1.9984 - val_acc: 0.2167\n",
      "Epoch 445/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4970 - acc: 0.3729 - val_loss: 1.9994 - val_acc: 0.2333\n",
      "Epoch 446/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4959 - acc: 0.3714 - val_loss: 2.0031 - val_acc: 0.2267\n",
      "Epoch 447/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4954 - acc: 0.3757 - val_loss: 2.0161 - val_acc: 0.2300\n",
      "Epoch 448/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4953 - acc: 0.3786 - val_loss: 2.0018 - val_acc: 0.2200\n",
      "Epoch 449/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4943 - acc: 0.3814 - val_loss: 2.0102 - val_acc: 0.2200\n",
      "Epoch 450/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4955 - acc: 0.3771 - val_loss: 1.9956 - val_acc: 0.2167\n",
      "Epoch 451/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4948 - acc: 0.3757 - val_loss: 1.9987 - val_acc: 0.2200\n",
      "Epoch 452/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4937 - acc: 0.3829 - val_loss: 2.0046 - val_acc: 0.2233\n",
      "Epoch 453/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4935 - acc: 0.3786 - val_loss: 1.9959 - val_acc: 0.2300\n",
      "Epoch 454/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4934 - acc: 0.3771 - val_loss: 2.0020 - val_acc: 0.2200\n",
      "Epoch 455/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.4912 - acc: 0.378 - 0s 116us/step - loss: 1.4931 - acc: 0.3714 - val_loss: 1.9933 - val_acc: 0.2267\n",
      "Epoch 456/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4921 - acc: 0.3800 - val_loss: 1.9953 - val_acc: 0.2400\n",
      "Epoch 457/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4923 - acc: 0.3814 - val_loss: 2.0049 - val_acc: 0.2200\n",
      "Epoch 458/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4928 - acc: 0.3843 - val_loss: 1.9993 - val_acc: 0.2233\n",
      "Epoch 459/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4905 - acc: 0.3829 - val_loss: 2.0002 - val_acc: 0.2433\n",
      "Epoch 460/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4925 - acc: 0.3829 - val_loss: 2.0083 - val_acc: 0.2233\n",
      "Epoch 461/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4908 - acc: 0.3857 - val_loss: 2.0036 - val_acc: 0.2200\n",
      "Epoch 462/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4908 - acc: 0.3814 - val_loss: 1.9978 - val_acc: 0.2233\n",
      "Epoch 463/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4894 - acc: 0.3800 - val_loss: 2.0067 - val_acc: 0.2467\n",
      "Epoch 464/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4894 - acc: 0.3814 - val_loss: 1.9954 - val_acc: 0.2233\n",
      "Epoch 465/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4900 - acc: 0.3843 - val_loss: 2.0033 - val_acc: 0.2233\n",
      "Epoch 466/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4896 - acc: 0.3729 - val_loss: 2.0049 - val_acc: 0.2333\n",
      "Epoch 467/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4897 - acc: 0.3829 - val_loss: 2.0106 - val_acc: 0.2333\n",
      "Epoch 468/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4889 - acc: 0.3743 - val_loss: 2.0016 - val_acc: 0.2233\n",
      "Epoch 469/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4882 - acc: 0.3829 - val_loss: 2.0289 - val_acc: 0.2367\n",
      "Epoch 470/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4893 - acc: 0.3786 - val_loss: 2.0168 - val_acc: 0.2267\n",
      "Epoch 471/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4880 - acc: 0.3886 - val_loss: 2.0112 - val_acc: 0.2267\n",
      "Epoch 472/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4866 - acc: 0.3900 - val_loss: 2.0171 - val_acc: 0.2300\n",
      "Epoch 473/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4873 - acc: 0.3843 - val_loss: 2.0209 - val_acc: 0.2333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 474/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4860 - acc: 0.3829 - val_loss: 2.0022 - val_acc: 0.2333\n",
      "Epoch 475/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4865 - acc: 0.3871 - val_loss: 2.0119 - val_acc: 0.2200\n",
      "Epoch 476/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4856 - acc: 0.3857 - val_loss: 2.0130 - val_acc: 0.2200\n",
      "Epoch 477/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4863 - acc: 0.3814 - val_loss: 2.0156 - val_acc: 0.2200\n",
      "Epoch 478/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4861 - acc: 0.3857 - val_loss: 2.0133 - val_acc: 0.2333\n",
      "Epoch 479/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4855 - acc: 0.3843 - val_loss: 2.0102 - val_acc: 0.2233\n",
      "Epoch 480/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4846 - acc: 0.3900 - val_loss: 2.0171 - val_acc: 0.2333\n",
      "Epoch 481/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4842 - acc: 0.3800 - val_loss: 2.0245 - val_acc: 0.2367\n",
      "Epoch 482/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4828 - acc: 0.3957 - val_loss: 2.0263 - val_acc: 0.2267\n",
      "Epoch 483/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4844 - acc: 0.4000 - val_loss: 2.0236 - val_acc: 0.2333\n",
      "Epoch 484/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4837 - acc: 0.3886 - val_loss: 2.0238 - val_acc: 0.2433\n",
      "Epoch 485/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4832 - acc: 0.3886 - val_loss: 2.0177 - val_acc: 0.2333\n",
      "Epoch 486/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4832 - acc: 0.3786 - val_loss: 2.0125 - val_acc: 0.2467\n",
      "Epoch 487/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4834 - acc: 0.3929 - val_loss: 2.0145 - val_acc: 0.2400\n",
      "Epoch 488/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4829 - acc: 0.3829 - val_loss: 2.0188 - val_acc: 0.2533\n",
      "Epoch 489/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4827 - acc: 0.3814 - val_loss: 2.0101 - val_acc: 0.2367\n",
      "Epoch 490/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4833 - acc: 0.3929 - val_loss: 2.0078 - val_acc: 0.2400\n",
      "Epoch 491/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4831 - acc: 0.3829 - val_loss: 2.0274 - val_acc: 0.2267\n",
      "Epoch 492/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4823 - acc: 0.3814 - val_loss: 2.0087 - val_acc: 0.2367\n",
      "Epoch 493/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4822 - acc: 0.3914 - val_loss: 2.0155 - val_acc: 0.2233\n",
      "Epoch 494/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4828 - acc: 0.3900 - val_loss: 2.0148 - val_acc: 0.2233\n",
      "Epoch 495/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4819 - acc: 0.3929 - val_loss: 2.0265 - val_acc: 0.2300\n",
      "Epoch 496/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4810 - acc: 0.3814 - val_loss: 2.0211 - val_acc: 0.2433\n",
      "Epoch 497/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4796 - acc: 0.3914 - val_loss: 2.0252 - val_acc: 0.2533\n",
      "Epoch 498/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4786 - acc: 0.3829 - val_loss: 2.0571 - val_acc: 0.2333\n",
      "Epoch 499/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4798 - acc: 0.3929 - val_loss: 2.0331 - val_acc: 0.2333\n",
      "Epoch 500/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4807 - acc: 0.3914 - val_loss: 2.0323 - val_acc: 0.2333\n",
      "Epoch 501/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4807 - acc: 0.4000 - val_loss: 2.0343 - val_acc: 0.2267\n",
      "Epoch 502/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4784 - acc: 0.3857 - val_loss: 2.0305 - val_acc: 0.2233\n",
      "Epoch 503/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4790 - acc: 0.3843 - val_loss: 2.0287 - val_acc: 0.2300\n",
      "Epoch 504/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4785 - acc: 0.3914 - val_loss: 2.0344 - val_acc: 0.2233\n",
      "Epoch 505/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4779 - acc: 0.3843 - val_loss: 2.0261 - val_acc: 0.2300\n",
      "Epoch 506/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4779 - acc: 0.3943 - val_loss: 2.0217 - val_acc: 0.2333\n",
      "Epoch 507/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4796 - acc: 0.3900 - val_loss: 2.0276 - val_acc: 0.2267\n",
      "Epoch 508/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4773 - acc: 0.3857 - val_loss: 2.0298 - val_acc: 0.2233\n",
      "Epoch 509/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4767 - acc: 0.3914 - val_loss: 2.0440 - val_acc: 0.2267\n",
      "Epoch 510/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4771 - acc: 0.3843 - val_loss: 2.0317 - val_acc: 0.2233\n",
      "Epoch 511/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4764 - acc: 0.3943 - val_loss: 2.0264 - val_acc: 0.2300\n",
      "Epoch 512/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4765 - acc: 0.3957 - val_loss: 2.0173 - val_acc: 0.2467\n",
      "Epoch 513/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4754 - acc: 0.4000 - val_loss: 2.0257 - val_acc: 0.2500\n",
      "Epoch 514/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4752 - acc: 0.3914 - val_loss: 2.0364 - val_acc: 0.2233\n",
      "Epoch 515/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4757 - acc: 0.3900 - val_loss: 2.0371 - val_acc: 0.2300\n",
      "Epoch 516/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4769 - acc: 0.3786 - val_loss: 2.0348 - val_acc: 0.2200\n",
      "Epoch 517/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4732 - acc: 0.3857 - val_loss: 2.0426 - val_acc: 0.2467\n",
      "Epoch 518/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4769 - acc: 0.3929 - val_loss: 2.0368 - val_acc: 0.2267\n",
      "Epoch 519/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4750 - acc: 0.4014 - val_loss: 2.0324 - val_acc: 0.2333\n",
      "Epoch 520/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4744 - acc: 0.3886 - val_loss: 2.0387 - val_acc: 0.2333\n",
      "Epoch 521/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4740 - acc: 0.4086 - val_loss: 2.0207 - val_acc: 0.2300\n",
      "Epoch 522/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4753 - acc: 0.3886 - val_loss: 2.0412 - val_acc: 0.2233\n",
      "Epoch 523/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4750 - acc: 0.3843 - val_loss: 2.0395 - val_acc: 0.2267\n",
      "Epoch 524/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4740 - acc: 0.3957 - val_loss: 2.0318 - val_acc: 0.2267\n",
      "Epoch 525/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4721 - acc: 0.3943 - val_loss: 2.0346 - val_acc: 0.2467\n",
      "Epoch 526/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4739 - acc: 0.3929 - val_loss: 2.0348 - val_acc: 0.2300\n",
      "Epoch 527/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4728 - acc: 0.3871 - val_loss: 2.0347 - val_acc: 0.2233\n",
      "Epoch 528/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4719 - acc: 0.3914 - val_loss: 2.0379 - val_acc: 0.2267\n",
      "Epoch 529/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4708 - acc: 0.3871 - val_loss: 2.0420 - val_acc: 0.2267\n",
      "Epoch 530/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4713 - acc: 0.3971 - val_loss: 2.0508 - val_acc: 0.2367\n",
      "Epoch 531/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4715 - acc: 0.3886 - val_loss: 2.0382 - val_acc: 0.2433\n",
      "Epoch 532/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4720 - acc: 0.4000 - val_loss: 2.0441 - val_acc: 0.2367\n",
      "Epoch 533/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 118us/step - loss: 1.4712 - acc: 0.3943 - val_loss: 2.0344 - val_acc: 0.2233\n",
      "Epoch 534/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4717 - acc: 0.3957 - val_loss: 2.0346 - val_acc: 0.2300\n",
      "Epoch 535/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4702 - acc: 0.4000 - val_loss: 2.0547 - val_acc: 0.2367\n",
      "Epoch 536/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4698 - acc: 0.3986 - val_loss: 2.0542 - val_acc: 0.2233\n",
      "Epoch 537/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4705 - acc: 0.3971 - val_loss: 2.0353 - val_acc: 0.2300\n",
      "Epoch 538/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4697 - acc: 0.3914 - val_loss: 2.0463 - val_acc: 0.2367\n",
      "Epoch 539/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4723 - acc: 0.3914 - val_loss: 2.0357 - val_acc: 0.2233\n",
      "Epoch 540/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4705 - acc: 0.3943 - val_loss: 2.0487 - val_acc: 0.2233\n",
      "Epoch 541/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4696 - acc: 0.3971 - val_loss: 2.0497 - val_acc: 0.2267\n",
      "Epoch 542/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4693 - acc: 0.3971 - val_loss: 2.0529 - val_acc: 0.2400\n",
      "Epoch 543/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4702 - acc: 0.3929 - val_loss: 2.0393 - val_acc: 0.2233\n",
      "Epoch 544/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4685 - acc: 0.3914 - val_loss: 2.0341 - val_acc: 0.2300\n",
      "Epoch 545/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4693 - acc: 0.4014 - val_loss: 2.0423 - val_acc: 0.2300\n",
      "Epoch 546/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4660 - acc: 0.4000 - val_loss: 2.0558 - val_acc: 0.2400\n",
      "Epoch 547/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4685 - acc: 0.4000 - val_loss: 2.0594 - val_acc: 0.2333\n",
      "Epoch 548/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4669 - acc: 0.3943 - val_loss: 2.0380 - val_acc: 0.2233\n",
      "Epoch 549/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4674 - acc: 0.3986 - val_loss: 2.0367 - val_acc: 0.2267\n",
      "Epoch 550/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4664 - acc: 0.3957 - val_loss: 2.0526 - val_acc: 0.2300\n",
      "Epoch 551/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4677 - acc: 0.3986 - val_loss: 2.0438 - val_acc: 0.2267\n",
      "Epoch 552/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4657 - acc: 0.3986 - val_loss: 2.0469 - val_acc: 0.2267\n",
      "Epoch 553/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4684 - acc: 0.3971 - val_loss: 2.0432 - val_acc: 0.2267\n",
      "Epoch 554/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4654 - acc: 0.3971 - val_loss: 2.0582 - val_acc: 0.2333\n",
      "Epoch 555/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4666 - acc: 0.4000 - val_loss: 2.0532 - val_acc: 0.2400\n",
      "Epoch 556/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4647 - acc: 0.3971 - val_loss: 2.0492 - val_acc: 0.2400\n",
      "Epoch 557/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4639 - acc: 0.4071 - val_loss: 2.0642 - val_acc: 0.2467\n",
      "Epoch 558/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4658 - acc: 0.3971 - val_loss: 2.0491 - val_acc: 0.2300\n",
      "Epoch 559/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4640 - acc: 0.3986 - val_loss: 2.0519 - val_acc: 0.2467\n",
      "Epoch 560/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4638 - acc: 0.3986 - val_loss: 2.0564 - val_acc: 0.2500\n",
      "Epoch 561/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4651 - acc: 0.4100 - val_loss: 2.0459 - val_acc: 0.2267\n",
      "Epoch 562/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4645 - acc: 0.4014 - val_loss: 2.0413 - val_acc: 0.2267\n",
      "Epoch 563/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4636 - acc: 0.3957 - val_loss: 2.0464 - val_acc: 0.2267\n",
      "Epoch 564/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4637 - acc: 0.4014 - val_loss: 2.0619 - val_acc: 0.2267\n",
      "Epoch 565/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4628 - acc: 0.4029 - val_loss: 2.0465 - val_acc: 0.2300\n",
      "Epoch 566/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4647 - acc: 0.4029 - val_loss: 2.0619 - val_acc: 0.2233\n",
      "Epoch 567/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4624 - acc: 0.4086 - val_loss: 2.0550 - val_acc: 0.2300\n",
      "Epoch 568/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4623 - acc: 0.4100 - val_loss: 2.0579 - val_acc: 0.2400\n",
      "Epoch 569/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4617 - acc: 0.4000 - val_loss: 2.0510 - val_acc: 0.2500\n",
      "Epoch 570/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4612 - acc: 0.4114 - val_loss: 2.0594 - val_acc: 0.2267\n",
      "Epoch 571/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4611 - acc: 0.4029 - val_loss: 2.0577 - val_acc: 0.2267\n",
      "Epoch 572/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4604 - acc: 0.3986 - val_loss: 2.0513 - val_acc: 0.2367\n",
      "Epoch 573/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4595 - acc: 0.4086 - val_loss: 2.0681 - val_acc: 0.2467\n",
      "Epoch 574/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4624 - acc: 0.4000 - val_loss: 2.0474 - val_acc: 0.2533\n",
      "Epoch 575/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4623 - acc: 0.4100 - val_loss: 2.0539 - val_acc: 0.2267\n",
      "Epoch 576/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4609 - acc: 0.3929 - val_loss: 2.0537 - val_acc: 0.2300\n",
      "Epoch 577/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4609 - acc: 0.4000 - val_loss: 2.0539 - val_acc: 0.2300\n",
      "Epoch 578/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4603 - acc: 0.4043 - val_loss: 2.0538 - val_acc: 0.2300\n",
      "Epoch 579/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4608 - acc: 0.4057 - val_loss: 2.0510 - val_acc: 0.2267\n",
      "Epoch 580/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4597 - acc: 0.4043 - val_loss: 2.0647 - val_acc: 0.2300\n",
      "Epoch 581/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4596 - acc: 0.4014 - val_loss: 2.0613 - val_acc: 0.2500\n",
      "Epoch 582/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4595 - acc: 0.4014 - val_loss: 2.0598 - val_acc: 0.2267\n",
      "Epoch 583/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4588 - acc: 0.4014 - val_loss: 2.0611 - val_acc: 0.2267\n",
      "Epoch 584/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4598 - acc: 0.3986 - val_loss: 2.0650 - val_acc: 0.2267\n",
      "Epoch 585/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4582 - acc: 0.4029 - val_loss: 2.0629 - val_acc: 0.2300\n",
      "Epoch 586/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.4573 - acc: 0.4043 - val_loss: 2.0642 - val_acc: 0.2467\n",
      "Epoch 587/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4598 - acc: 0.4100 - val_loss: 2.0669 - val_acc: 0.2333\n",
      "Epoch 588/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4586 - acc: 0.4014 - val_loss: 2.0691 - val_acc: 0.2300\n",
      "Epoch 589/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4577 - acc: 0.4029 - val_loss: 2.0676 - val_acc: 0.2267\n",
      "Epoch 590/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4580 - acc: 0.4043 - val_loss: 2.0604 - val_acc: 0.2300\n",
      "Epoch 591/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4579 - acc: 0.4043 - val_loss: 2.0696 - val_acc: 0.2267\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 131us/step - loss: 1.4568 - acc: 0.4029 - val_loss: 2.0655 - val_acc: 0.2300\n",
      "Epoch 593/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4572 - acc: 0.4029 - val_loss: 2.0570 - val_acc: 0.2267\n",
      "Epoch 594/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4565 - acc: 0.4114 - val_loss: 2.0601 - val_acc: 0.2333\n",
      "Epoch 595/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4566 - acc: 0.4029 - val_loss: 2.0684 - val_acc: 0.2467\n",
      "Epoch 596/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4563 - acc: 0.4014 - val_loss: 2.0578 - val_acc: 0.2300\n",
      "Epoch 597/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4549 - acc: 0.4071 - val_loss: 2.0574 - val_acc: 0.2500\n",
      "Epoch 598/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4563 - acc: 0.3943 - val_loss: 2.0634 - val_acc: 0.2267\n",
      "Epoch 599/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4566 - acc: 0.3986 - val_loss: 2.0574 - val_acc: 0.2333\n",
      "Epoch 600/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4552 - acc: 0.4071 - val_loss: 2.0687 - val_acc: 0.2333\n",
      "Epoch 601/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4546 - acc: 0.4129 - val_loss: 2.0688 - val_acc: 0.2300\n",
      "Epoch 602/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4550 - acc: 0.4014 - val_loss: 2.0645 - val_acc: 0.2333\n",
      "Epoch 603/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4552 - acc: 0.4043 - val_loss: 2.0600 - val_acc: 0.2333\n",
      "Epoch 604/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4552 - acc: 0.4000 - val_loss: 2.0599 - val_acc: 0.2367\n",
      "Epoch 605/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4538 - acc: 0.4043 - val_loss: 2.0640 - val_acc: 0.2300\n",
      "Epoch 606/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4544 - acc: 0.4071 - val_loss: 2.0531 - val_acc: 0.2333\n",
      "Epoch 607/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4545 - acc: 0.4071 - val_loss: 2.0659 - val_acc: 0.2267\n",
      "Epoch 608/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4541 - acc: 0.4100 - val_loss: 2.0599 - val_acc: 0.2333\n",
      "Epoch 609/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4524 - acc: 0.4071 - val_loss: 2.0739 - val_acc: 0.2533\n",
      "Epoch 610/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4532 - acc: 0.4086 - val_loss: 2.0747 - val_acc: 0.2300\n",
      "Epoch 611/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4532 - acc: 0.4057 - val_loss: 2.0775 - val_acc: 0.2300\n",
      "Epoch 612/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4532 - acc: 0.4086 - val_loss: 2.0676 - val_acc: 0.2333\n",
      "Epoch 613/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4531 - acc: 0.4043 - val_loss: 2.0697 - val_acc: 0.2300\n",
      "Epoch 614/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4519 - acc: 0.4071 - val_loss: 2.0779 - val_acc: 0.2500\n",
      "Epoch 615/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4528 - acc: 0.4129 - val_loss: 2.0631 - val_acc: 0.2533\n",
      "Epoch 616/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4520 - acc: 0.4100 - val_loss: 2.0826 - val_acc: 0.2300\n",
      "Epoch 617/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4504 - acc: 0.4114 - val_loss: 2.0771 - val_acc: 0.2500\n",
      "Epoch 618/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4517 - acc: 0.4014 - val_loss: 2.0703 - val_acc: 0.2333\n",
      "Epoch 619/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4503 - acc: 0.4071 - val_loss: 2.0809 - val_acc: 0.2300\n",
      "Epoch 620/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4513 - acc: 0.4071 - val_loss: 2.0683 - val_acc: 0.2300\n",
      "Epoch 621/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4511 - acc: 0.4171 - val_loss: 2.0862 - val_acc: 0.2333\n",
      "Epoch 622/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4504 - acc: 0.4129 - val_loss: 2.0803 - val_acc: 0.2300\n",
      "Epoch 623/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4494 - acc: 0.4143 - val_loss: 2.0775 - val_acc: 0.2267\n",
      "Epoch 624/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4505 - acc: 0.4129 - val_loss: 2.0794 - val_acc: 0.2300\n",
      "Epoch 625/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4503 - acc: 0.3957 - val_loss: 2.0855 - val_acc: 0.2333\n",
      "Epoch 626/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4497 - acc: 0.3986 - val_loss: 2.0642 - val_acc: 0.2367\n",
      "Epoch 627/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4504 - acc: 0.4129 - val_loss: 2.0751 - val_acc: 0.2300\n",
      "Epoch 628/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4482 - acc: 0.4100 - val_loss: 2.0612 - val_acc: 0.2333\n",
      "Epoch 629/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4499 - acc: 0.4057 - val_loss: 2.0790 - val_acc: 0.2300\n",
      "Epoch 630/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4485 - acc: 0.4071 - val_loss: 2.0655 - val_acc: 0.2300\n",
      "Epoch 631/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4492 - acc: 0.4014 - val_loss: 2.0910 - val_acc: 0.2300\n",
      "Epoch 632/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4493 - acc: 0.4057 - val_loss: 2.0846 - val_acc: 0.2333\n",
      "Epoch 633/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4480 - acc: 0.4129 - val_loss: 2.0927 - val_acc: 0.2300\n",
      "Epoch 634/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4481 - acc: 0.4129 - val_loss: 2.0820 - val_acc: 0.2300\n",
      "Epoch 635/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4468 - acc: 0.4057 - val_loss: 2.0740 - val_acc: 0.2567\n",
      "Epoch 636/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4490 - acc: 0.4157 - val_loss: 2.0773 - val_acc: 0.2300\n",
      "Epoch 637/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4477 - acc: 0.4071 - val_loss: 2.0788 - val_acc: 0.2367\n",
      "Epoch 638/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4477 - acc: 0.4114 - val_loss: 2.0911 - val_acc: 0.2300\n",
      "Epoch 639/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4476 - acc: 0.4114 - val_loss: 2.0920 - val_acc: 0.2267\n",
      "Epoch 640/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4465 - acc: 0.4200 - val_loss: 2.0680 - val_acc: 0.2367\n",
      "Epoch 641/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4462 - acc: 0.4071 - val_loss: 2.0846 - val_acc: 0.2400\n",
      "Epoch 642/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4475 - acc: 0.4086 - val_loss: 2.0915 - val_acc: 0.2433\n",
      "Epoch 643/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4466 - acc: 0.4086 - val_loss: 2.0954 - val_acc: 0.2333\n",
      "Epoch 644/1000\n",
      "700/700 [==============================] - 0s 222us/step - loss: 1.4465 - acc: 0.4086 - val_loss: 2.0825 - val_acc: 0.2333\n",
      "Epoch 645/1000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.4459 - acc: 0.4143 - val_loss: 2.0905 - val_acc: 0.2333\n",
      "Epoch 646/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.4744 - acc: 0.398 - 0s 133us/step - loss: 1.4439 - acc: 0.4043 - val_loss: 2.0833 - val_acc: 0.2533\n",
      "Epoch 647/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4448 - acc: 0.4129 - val_loss: 2.0828 - val_acc: 0.2300\n",
      "Epoch 648/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4457 - acc: 0.4100 - val_loss: 2.0969 - val_acc: 0.2367\n",
      "Epoch 649/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4440 - acc: 0.3986 - val_loss: 2.0926 - val_acc: 0.2333\n",
      "Epoch 650/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.4458 - acc: 0.4100 - val_loss: 2.0859 - val_acc: 0.2333\n",
      "Epoch 651/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 149us/step - loss: 1.4444 - acc: 0.4100 - val_loss: 2.0978 - val_acc: 0.2367\n",
      "Epoch 652/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4457 - acc: 0.4129 - val_loss: 2.0834 - val_acc: 0.2333\n",
      "Epoch 653/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4439 - acc: 0.4186 - val_loss: 2.0892 - val_acc: 0.2433\n",
      "Epoch 654/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4443 - acc: 0.4100 - val_loss: 2.0740 - val_acc: 0.2467\n",
      "Epoch 655/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4431 - acc: 0.4043 - val_loss: 2.0849 - val_acc: 0.2400\n",
      "Epoch 656/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4455 - acc: 0.4129 - val_loss: 2.0949 - val_acc: 0.2433\n",
      "Epoch 657/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4434 - acc: 0.4129 - val_loss: 2.0864 - val_acc: 0.2300\n",
      "Epoch 658/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4435 - acc: 0.4043 - val_loss: 2.0872 - val_acc: 0.2367\n",
      "Epoch 659/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4429 - acc: 0.4171 - val_loss: 2.0899 - val_acc: 0.2367\n",
      "Epoch 660/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4435 - acc: 0.4129 - val_loss: 2.0913 - val_acc: 0.2333\n",
      "Epoch 661/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4445 - acc: 0.4086 - val_loss: 2.0851 - val_acc: 0.2300\n",
      "Epoch 662/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4436 - acc: 0.4000 - val_loss: 2.0903 - val_acc: 0.2300\n",
      "Epoch 663/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4429 - acc: 0.4114 - val_loss: 2.1056 - val_acc: 0.2333\n",
      "Epoch 664/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4420 - acc: 0.4129 - val_loss: 2.0907 - val_acc: 0.2333\n",
      "Epoch 665/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4422 - acc: 0.4129 - val_loss: 2.0991 - val_acc: 0.2333\n",
      "Epoch 666/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4415 - acc: 0.4143 - val_loss: 2.0909 - val_acc: 0.2533\n",
      "Epoch 667/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4433 - acc: 0.4100 - val_loss: 2.0855 - val_acc: 0.2367\n",
      "Epoch 668/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4396 - acc: 0.4114 - val_loss: 2.1052 - val_acc: 0.2567\n",
      "Epoch 669/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4406 - acc: 0.4114 - val_loss: 2.1006 - val_acc: 0.2333\n",
      "Epoch 670/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4420 - acc: 0.4114 - val_loss: 2.0923 - val_acc: 0.2333\n",
      "Epoch 671/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4402 - acc: 0.4157 - val_loss: 2.0920 - val_acc: 0.2533\n",
      "Epoch 672/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4410 - acc: 0.4129 - val_loss: 2.0998 - val_acc: 0.2300\n",
      "Epoch 673/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4411 - acc: 0.4171 - val_loss: 2.0936 - val_acc: 0.2367\n",
      "Epoch 674/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4400 - acc: 0.4129 - val_loss: 2.1134 - val_acc: 0.2433\n",
      "Epoch 675/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4393 - acc: 0.4171 - val_loss: 2.1122 - val_acc: 0.2567\n",
      "Epoch 676/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4394 - acc: 0.4114 - val_loss: 2.0907 - val_acc: 0.2500\n",
      "Epoch 677/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4384 - acc: 0.4114 - val_loss: 2.1116 - val_acc: 0.2333\n",
      "Epoch 678/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4381 - acc: 0.4157 - val_loss: 2.0860 - val_acc: 0.2233\n",
      "Epoch 679/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4394 - acc: 0.4157 - val_loss: 2.1012 - val_acc: 0.2333\n",
      "Epoch 680/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4406 - acc: 0.4086 - val_loss: 2.1013 - val_acc: 0.2367\n",
      "Epoch 681/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4398 - acc: 0.4157 - val_loss: 2.0932 - val_acc: 0.2367\n",
      "Epoch 682/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4387 - acc: 0.4200 - val_loss: 2.0950 - val_acc: 0.2567\n",
      "Epoch 683/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4381 - acc: 0.4057 - val_loss: 2.0891 - val_acc: 0.2467\n",
      "Epoch 684/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4350 - acc: 0.4086 - val_loss: 2.1007 - val_acc: 0.2600\n",
      "Epoch 685/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4380 - acc: 0.4043 - val_loss: 2.0961 - val_acc: 0.2533\n",
      "Epoch 686/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4379 - acc: 0.4186 - val_loss: 2.1165 - val_acc: 0.2467\n",
      "Epoch 687/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4379 - acc: 0.4143 - val_loss: 2.0882 - val_acc: 0.2300\n",
      "Epoch 688/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4382 - acc: 0.4129 - val_loss: 2.0943 - val_acc: 0.2400\n",
      "Epoch 689/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4373 - acc: 0.4143 - val_loss: 2.1028 - val_acc: 0.2367\n",
      "Epoch 690/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4369 - acc: 0.4143 - val_loss: 2.1101 - val_acc: 0.2300\n",
      "Epoch 691/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4363 - acc: 0.4186 - val_loss: 2.1077 - val_acc: 0.2367\n",
      "Epoch 692/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4366 - acc: 0.4143 - val_loss: 2.0920 - val_acc: 0.2333\n",
      "Epoch 693/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4374 - acc: 0.4100 - val_loss: 2.0930 - val_acc: 0.2400\n",
      "Epoch 694/1000\n",
      "700/700 [==============================] - 0s 157us/step - loss: 1.4360 - acc: 0.4200 - val_loss: 2.1176 - val_acc: 0.2467\n",
      "Epoch 695/1000\n",
      "700/700 [==============================] - 0s 162us/step - loss: 1.4376 - acc: 0.4157 - val_loss: 2.0986 - val_acc: 0.2533\n",
      "Epoch 696/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4349 - acc: 0.4200 - val_loss: 2.1088 - val_acc: 0.2367\n",
      "Epoch 697/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4362 - acc: 0.4086 - val_loss: 2.1164 - val_acc: 0.2500\n",
      "Epoch 698/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4357 - acc: 0.4243 - val_loss: 2.1049 - val_acc: 0.2500\n",
      "Epoch 699/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4355 - acc: 0.4186 - val_loss: 2.1096 - val_acc: 0.2333\n",
      "Epoch 700/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4354 - acc: 0.4143 - val_loss: 2.1054 - val_acc: 0.2500\n",
      "Epoch 701/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4342 - acc: 0.4214 - val_loss: 2.1012 - val_acc: 0.2500\n",
      "Epoch 702/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4354 - acc: 0.4157 - val_loss: 2.1028 - val_acc: 0.2367\n",
      "Epoch 703/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4341 - acc: 0.4229 - val_loss: 2.1244 - val_acc: 0.2300\n",
      "Epoch 704/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4350 - acc: 0.4100 - val_loss: 2.1053 - val_acc: 0.2500\n",
      "Epoch 705/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4347 - acc: 0.4129 - val_loss: 2.0994 - val_acc: 0.2333\n",
      "Epoch 706/1000\n",
      "700/700 [==============================] - 0s 156us/step - loss: 1.4348 - acc: 0.4157 - val_loss: 2.0915 - val_acc: 0.2333\n",
      "Epoch 707/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4342 - acc: 0.4200 - val_loss: 2.1134 - val_acc: 0.2333\n",
      "Epoch 708/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.4343 - acc: 0.4243 - val_loss: 2.1048 - val_acc: 0.2367\n",
      "Epoch 709/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4321 - acc: 0.4229 - val_loss: 2.1205 - val_acc: 0.2500\n",
      "Epoch 710/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 132us/step - loss: 1.4342 - acc: 0.4171 - val_loss: 2.1079 - val_acc: 0.2467\n",
      "Epoch 711/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4329 - acc: 0.4143 - val_loss: 2.1073 - val_acc: 0.2333\n",
      "Epoch 712/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4327 - acc: 0.4114 - val_loss: 2.1132 - val_acc: 0.2567\n",
      "Epoch 713/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4336 - acc: 0.4157 - val_loss: 2.0970 - val_acc: 0.2400\n",
      "Epoch 714/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4328 - acc: 0.4229 - val_loss: 2.1078 - val_acc: 0.2333\n",
      "Epoch 715/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4305 - acc: 0.4214 - val_loss: 2.1062 - val_acc: 0.2600\n",
      "Epoch 716/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4333 - acc: 0.4114 - val_loss: 2.1163 - val_acc: 0.2333\n",
      "Epoch 717/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4323 - acc: 0.4157 - val_loss: 2.1124 - val_acc: 0.2400\n",
      "Epoch 718/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4313 - acc: 0.4157 - val_loss: 2.1346 - val_acc: 0.2533\n",
      "Epoch 719/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4328 - acc: 0.4143 - val_loss: 2.1285 - val_acc: 0.2300\n",
      "Epoch 720/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4324 - acc: 0.4114 - val_loss: 2.1165 - val_acc: 0.2367\n",
      "Epoch 721/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4317 - acc: 0.4157 - val_loss: 2.1144 - val_acc: 0.2467\n",
      "Epoch 722/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4312 - acc: 0.4157 - val_loss: 2.1160 - val_acc: 0.2333\n",
      "Epoch 723/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4310 - acc: 0.4186 - val_loss: 2.1049 - val_acc: 0.2367\n",
      "Epoch 724/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4308 - acc: 0.4186 - val_loss: 2.1221 - val_acc: 0.2300\n",
      "Epoch 725/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.4303 - acc: 0.4186 - val_loss: 2.1263 - val_acc: 0.2400\n",
      "Epoch 726/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4303 - acc: 0.4229 - val_loss: 2.1142 - val_acc: 0.2367\n",
      "Epoch 727/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4299 - acc: 0.4200 - val_loss: 2.1392 - val_acc: 0.2333\n",
      "Epoch 728/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4302 - acc: 0.4200 - val_loss: 2.1097 - val_acc: 0.2367\n",
      "Epoch 729/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4297 - acc: 0.4186 - val_loss: 2.1308 - val_acc: 0.2467\n",
      "Epoch 730/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4296 - acc: 0.4186 - val_loss: 2.1348 - val_acc: 0.2300\n",
      "Epoch 731/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4303 - acc: 0.4057 - val_loss: 2.1201 - val_acc: 0.2333\n",
      "Epoch 732/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4285 - acc: 0.4214 - val_loss: 2.1170 - val_acc: 0.2367\n",
      "Epoch 733/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4290 - acc: 0.4300 - val_loss: 2.1212 - val_acc: 0.2333\n",
      "Epoch 734/1000\n",
      "700/700 [==============================] - 0s 277us/step - loss: 1.4297 - acc: 0.4171 - val_loss: 2.1294 - val_acc: 0.2333\n",
      "Epoch 735/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4284 - acc: 0.4200 - val_loss: 2.1203 - val_acc: 0.2400\n",
      "Epoch 736/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4276 - acc: 0.4243 - val_loss: 2.1153 - val_acc: 0.2367\n",
      "Epoch 737/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4290 - acc: 0.4200 - val_loss: 2.1315 - val_acc: 0.2433\n",
      "Epoch 738/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4292 - acc: 0.4214 - val_loss: 2.1195 - val_acc: 0.2467\n",
      "Epoch 739/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4275 - acc: 0.4271 - val_loss: 2.1267 - val_acc: 0.2333\n",
      "Epoch 740/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4278 - acc: 0.4200 - val_loss: 2.1166 - val_acc: 0.2333\n",
      "Epoch 741/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4275 - acc: 0.4171 - val_loss: 2.1294 - val_acc: 0.2533\n",
      "Epoch 742/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4279 - acc: 0.4143 - val_loss: 2.1201 - val_acc: 0.2567\n",
      "Epoch 743/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4267 - acc: 0.4214 - val_loss: 2.1166 - val_acc: 0.2600\n",
      "Epoch 744/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4284 - acc: 0.4143 - val_loss: 2.1154 - val_acc: 0.2467\n",
      "Epoch 745/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4242 - acc: 0.4314 - val_loss: 2.1295 - val_acc: 0.2533\n",
      "Epoch 746/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4281 - acc: 0.4257 - val_loss: 2.1180 - val_acc: 0.2333\n",
      "Epoch 747/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4278 - acc: 0.4129 - val_loss: 2.1235 - val_acc: 0.2433\n",
      "Epoch 748/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4258 - acc: 0.4171 - val_loss: 2.1392 - val_acc: 0.2500\n",
      "Epoch 749/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4248 - acc: 0.4171 - val_loss: 2.1075 - val_acc: 0.2367\n",
      "Epoch 750/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4268 - acc: 0.4286 - val_loss: 2.1150 - val_acc: 0.2367\n",
      "Epoch 751/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4247 - acc: 0.4129 - val_loss: 2.1252 - val_acc: 0.2333\n",
      "Epoch 752/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4260 - acc: 0.4229 - val_loss: 2.1265 - val_acc: 0.2367\n",
      "Epoch 753/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4247 - acc: 0.4200 - val_loss: 2.1476 - val_acc: 0.2333\n",
      "Epoch 754/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4263 - acc: 0.4243 - val_loss: 2.1306 - val_acc: 0.2400\n",
      "Epoch 755/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4248 - acc: 0.4329 - val_loss: 2.1280 - val_acc: 0.2533\n",
      "Epoch 756/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.4247 - acc: 0.4171 - val_loss: 2.1258 - val_acc: 0.2367\n",
      "Epoch 757/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.4259 - acc: 0.4214 - val_loss: 2.1309 - val_acc: 0.2367\n",
      "Epoch 758/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.4246 - acc: 0.4257 - val_loss: 2.1306 - val_acc: 0.2333\n",
      "Epoch 759/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.4250 - acc: 0.4214 - val_loss: 2.1278 - val_acc: 0.2333\n",
      "Epoch 760/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4244 - acc: 0.4271 - val_loss: 2.1240 - val_acc: 0.2367\n",
      "Epoch 761/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4244 - acc: 0.4200 - val_loss: 2.1480 - val_acc: 0.2433\n",
      "Epoch 762/1000\n",
      "700/700 [==============================] - 0s 246us/step - loss: 1.4253 - acc: 0.4186 - val_loss: 2.1391 - val_acc: 0.2367\n",
      "Epoch 763/1000\n",
      "700/700 [==============================] - 0s 219us/step - loss: 1.4243 - acc: 0.4229 - val_loss: 2.1256 - val_acc: 0.2333\n",
      "Epoch 764/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4255 - acc: 0.4286 - val_loss: 2.1419 - val_acc: 0.2367\n",
      "Epoch 765/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4230 - acc: 0.4157 - val_loss: 2.1547 - val_acc: 0.2300\n",
      "Epoch 766/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.4245 - acc: 0.4157 - val_loss: 2.1282 - val_acc: 0.2400\n",
      "Epoch 767/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4244 - acc: 0.4214 - val_loss: 2.1276 - val_acc: 0.2367\n",
      "Epoch 768/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4231 - acc: 0.4286 - val_loss: 2.1233 - val_acc: 0.2400\n",
      "Epoch 769/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 166us/step - loss: 1.4232 - acc: 0.4214 - val_loss: 2.1312 - val_acc: 0.2367\n",
      "Epoch 770/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4227 - acc: 0.4200 - val_loss: 2.1204 - val_acc: 0.2400\n",
      "Epoch 771/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4220 - acc: 0.4214 - val_loss: 2.1367 - val_acc: 0.2367\n",
      "Epoch 772/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4229 - acc: 0.4229 - val_loss: 2.1349 - val_acc: 0.2367\n",
      "Epoch 773/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4228 - acc: 0.4243 - val_loss: 2.1441 - val_acc: 0.2467\n",
      "Epoch 774/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4216 - acc: 0.4286 - val_loss: 2.1398 - val_acc: 0.2367\n",
      "Epoch 775/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4206 - acc: 0.4214 - val_loss: 2.1410 - val_acc: 0.2533\n",
      "Epoch 776/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4218 - acc: 0.4214 - val_loss: 2.1323 - val_acc: 0.2367\n",
      "Epoch 777/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4205 - acc: 0.4286 - val_loss: 2.1472 - val_acc: 0.2400\n",
      "Epoch 778/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4216 - acc: 0.4200 - val_loss: 2.1388 - val_acc: 0.2367\n",
      "Epoch 779/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4220 - acc: 0.4286 - val_loss: 2.1482 - val_acc: 0.2333\n",
      "Epoch 780/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4217 - acc: 0.4157 - val_loss: 2.1287 - val_acc: 0.2367\n",
      "Epoch 781/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4225 - acc: 0.4171 - val_loss: 2.1336 - val_acc: 0.2433\n",
      "Epoch 782/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4213 - acc: 0.4157 - val_loss: 2.1201 - val_acc: 0.2400\n",
      "Epoch 783/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4213 - acc: 0.4286 - val_loss: 2.1405 - val_acc: 0.2433\n",
      "Epoch 784/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4207 - acc: 0.4329 - val_loss: 2.1464 - val_acc: 0.2333\n",
      "Epoch 785/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4208 - acc: 0.4257 - val_loss: 2.1540 - val_acc: 0.2367\n",
      "Epoch 786/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4209 - acc: 0.4200 - val_loss: 2.1386 - val_acc: 0.2500\n",
      "Epoch 787/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4212 - acc: 0.4157 - val_loss: 2.1262 - val_acc: 0.2400\n",
      "Epoch 788/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4205 - acc: 0.4257 - val_loss: 2.1372 - val_acc: 0.2400\n",
      "Epoch 789/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4199 - acc: 0.4157 - val_loss: 2.1365 - val_acc: 0.2367\n",
      "Epoch 790/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4201 - acc: 0.4300 - val_loss: 2.1416 - val_acc: 0.2433\n",
      "Epoch 791/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4191 - acc: 0.4171 - val_loss: 2.1430 - val_acc: 0.2533\n",
      "Epoch 792/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4200 - acc: 0.4171 - val_loss: 2.1322 - val_acc: 0.2400\n",
      "Epoch 793/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4190 - acc: 0.4271 - val_loss: 2.1521 - val_acc: 0.2467\n",
      "Epoch 794/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4197 - acc: 0.4214 - val_loss: 2.1434 - val_acc: 0.2367\n",
      "Epoch 795/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4191 - acc: 0.4271 - val_loss: 2.1393 - val_acc: 0.2367\n",
      "Epoch 796/1000\n",
      "700/700 [==============================] - 0s 153us/step - loss: 1.4187 - acc: 0.4243 - val_loss: 2.1415 - val_acc: 0.2367\n",
      "Epoch 797/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4191 - acc: 0.4143 - val_loss: 2.1477 - val_acc: 0.2367\n",
      "Epoch 798/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4187 - acc: 0.4329 - val_loss: 2.1489 - val_acc: 0.2367\n",
      "Epoch 799/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4179 - acc: 0.4343 - val_loss: 2.1411 - val_acc: 0.2567\n",
      "Epoch 800/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.4185 - acc: 0.4157 - val_loss: 2.1524 - val_acc: 0.2367\n",
      "Epoch 801/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4190 - acc: 0.4271 - val_loss: 2.1370 - val_acc: 0.2367\n",
      "Epoch 802/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.4188 - acc: 0.4286 - val_loss: 2.1823 - val_acc: 0.2400\n",
      "Epoch 803/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4172 - acc: 0.4286 - val_loss: 2.1438 - val_acc: 0.2533\n",
      "Epoch 804/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4175 - acc: 0.4271 - val_loss: 2.1432 - val_acc: 0.2367\n",
      "Epoch 805/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4169 - acc: 0.4300 - val_loss: 2.1415 - val_acc: 0.2467\n",
      "Epoch 806/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4178 - acc: 0.4314 - val_loss: 2.1416 - val_acc: 0.2400\n",
      "Epoch 807/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4175 - acc: 0.4357 - val_loss: 2.1406 - val_acc: 0.2400\n",
      "Epoch 808/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4171 - acc: 0.4243 - val_loss: 2.1465 - val_acc: 0.2400\n",
      "Epoch 809/1000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 1.4179 - acc: 0.4200 - val_loss: 2.1531 - val_acc: 0.2367\n",
      "Epoch 810/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.4166 - acc: 0.4300 - val_loss: 2.1525 - val_acc: 0.2400\n",
      "Epoch 811/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4169 - acc: 0.4257 - val_loss: 2.1490 - val_acc: 0.2400\n",
      "Epoch 812/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4167 - acc: 0.4300 - val_loss: 2.1381 - val_acc: 0.2367\n",
      "Epoch 813/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4165 - acc: 0.4314 - val_loss: 2.1563 - val_acc: 0.2367\n",
      "Epoch 814/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4156 - acc: 0.4200 - val_loss: 2.1478 - val_acc: 0.2567\n",
      "Epoch 815/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.4169 - acc: 0.4243 - val_loss: 2.1481 - val_acc: 0.2467\n",
      "Epoch 816/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.4162 - acc: 0.4329 - val_loss: 2.1459 - val_acc: 0.2400\n",
      "Epoch 817/1000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.4144 - acc: 0.4286 - val_loss: 2.1500 - val_acc: 0.2367\n",
      "Epoch 818/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4149 - acc: 0.4300 - val_loss: 2.1575 - val_acc: 0.2367\n",
      "Epoch 819/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.4135 - acc: 0.4357 - val_loss: 2.1629 - val_acc: 0.2533\n",
      "Epoch 820/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.4160 - acc: 0.4271 - val_loss: 2.1550 - val_acc: 0.2633\n",
      "Epoch 821/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4157 - acc: 0.4286 - val_loss: 2.1599 - val_acc: 0.2433\n",
      "Epoch 822/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4158 - acc: 0.4286 - val_loss: 2.1505 - val_acc: 0.2400\n",
      "Epoch 823/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.4143 - acc: 0.4243 - val_loss: 2.1557 - val_acc: 0.2400\n",
      "Epoch 824/1000\n",
      "700/700 [==============================] - 0s 344us/step - loss: 1.4135 - acc: 0.4300 - val_loss: 2.1548 - val_acc: 0.2400\n",
      "Epoch 825/1000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.4140 - acc: 0.4286 - val_loss: 2.1730 - val_acc: 0.2400\n",
      "Epoch 826/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4150 - acc: 0.4214 - val_loss: 2.1591 - val_acc: 0.2400\n",
      "Epoch 827/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.4138 - acc: 0.4300 - val_loss: 2.1644 - val_acc: 0.2367\n",
      "Epoch 828/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 144us/step - loss: 1.4145 - acc: 0.4329 - val_loss: 2.1478 - val_acc: 0.2333\n",
      "Epoch 829/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4138 - acc: 0.4300 - val_loss: 2.1518 - val_acc: 0.2467\n",
      "Epoch 830/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4129 - acc: 0.4286 - val_loss: 2.1562 - val_acc: 0.2367\n",
      "Epoch 831/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4130 - acc: 0.4400 - val_loss: 2.1646 - val_acc: 0.2433\n",
      "Epoch 832/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4137 - acc: 0.4314 - val_loss: 2.1706 - val_acc: 0.2400\n",
      "Epoch 833/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4136 - acc: 0.4286 - val_loss: 2.1774 - val_acc: 0.2367\n",
      "Epoch 834/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4136 - acc: 0.4300 - val_loss: 2.1848 - val_acc: 0.2400\n",
      "Epoch 835/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4125 - acc: 0.4229 - val_loss: 2.1537 - val_acc: 0.2367\n",
      "Epoch 836/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4124 - acc: 0.4314 - val_loss: 2.1616 - val_acc: 0.2400\n",
      "Epoch 837/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4130 - acc: 0.4271 - val_loss: 2.1507 - val_acc: 0.2367\n",
      "Epoch 838/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4137 - acc: 0.4286 - val_loss: 2.1678 - val_acc: 0.2400\n",
      "Epoch 839/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4114 - acc: 0.4271 - val_loss: 2.1594 - val_acc: 0.2400\n",
      "Epoch 840/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4110 - acc: 0.4314 - val_loss: 2.1516 - val_acc: 0.2500\n",
      "Epoch 841/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4119 - acc: 0.4314 - val_loss: 2.1577 - val_acc: 0.2367\n",
      "Epoch 842/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4127 - acc: 0.4271 - val_loss: 2.1692 - val_acc: 0.2400\n",
      "Epoch 843/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4118 - acc: 0.4257 - val_loss: 2.1568 - val_acc: 0.2367\n",
      "Epoch 844/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4107 - acc: 0.4300 - val_loss: 2.1736 - val_acc: 0.2367\n",
      "Epoch 845/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4113 - acc: 0.4314 - val_loss: 2.1511 - val_acc: 0.2400\n",
      "Epoch 846/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.4119 - acc: 0.4329 - val_loss: 2.1600 - val_acc: 0.2367\n",
      "Epoch 847/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4101 - acc: 0.4200 - val_loss: 2.1668 - val_acc: 0.2333\n",
      "Epoch 848/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4106 - acc: 0.4329 - val_loss: 2.1643 - val_acc: 0.2533\n",
      "Epoch 849/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4113 - acc: 0.4257 - val_loss: 2.1666 - val_acc: 0.2400\n",
      "Epoch 850/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4096 - acc: 0.4229 - val_loss: 2.1604 - val_acc: 0.2367\n",
      "Epoch 851/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4097 - acc: 0.4200 - val_loss: 2.1575 - val_acc: 0.2333\n",
      "Epoch 852/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4115 - acc: 0.4300 - val_loss: 2.1621 - val_acc: 0.2333\n",
      "Epoch 853/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4091 - acc: 0.4229 - val_loss: 2.1649 - val_acc: 0.2333\n",
      "Epoch 854/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.4071 - acc: 0.4357 - val_loss: 2.1874 - val_acc: 0.2533\n",
      "Epoch 855/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4100 - acc: 0.4200 - val_loss: 2.1608 - val_acc: 0.2333\n",
      "Epoch 856/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.4101 - acc: 0.4286 - val_loss: 2.1769 - val_acc: 0.2433\n",
      "Epoch 857/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4098 - acc: 0.4243 - val_loss: 2.1676 - val_acc: 0.2467\n",
      "Epoch 858/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4093 - acc: 0.4329 - val_loss: 2.1654 - val_acc: 0.2367\n",
      "Epoch 859/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4076 - acc: 0.4371 - val_loss: 2.1664 - val_acc: 0.2367\n",
      "Epoch 860/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4086 - acc: 0.4286 - val_loss: 2.1908 - val_acc: 0.2400\n",
      "Epoch 861/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.4090 - acc: 0.4357 - val_loss: 2.1734 - val_acc: 0.2467\n",
      "Epoch 862/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4100 - acc: 0.4186 - val_loss: 2.1805 - val_acc: 0.2400\n",
      "Epoch 863/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4083 - acc: 0.4314 - val_loss: 2.1793 - val_acc: 0.2533\n",
      "Epoch 864/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4080 - acc: 0.4329 - val_loss: 2.1730 - val_acc: 0.2533\n",
      "Epoch 865/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4072 - acc: 0.4357 - val_loss: 2.1783 - val_acc: 0.2633\n",
      "Epoch 866/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4075 - acc: 0.4314 - val_loss: 2.1492 - val_acc: 0.2467\n",
      "Epoch 867/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4078 - acc: 0.4343 - val_loss: 2.1801 - val_acc: 0.2367\n",
      "Epoch 868/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4084 - acc: 0.4329 - val_loss: 2.1720 - val_acc: 0.2400\n",
      "Epoch 869/1000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.4077 - acc: 0.4357 - val_loss: 2.1700 - val_acc: 0.2333\n",
      "Epoch 870/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4059 - acc: 0.4314 - val_loss: 2.1815 - val_acc: 0.2400\n",
      "Epoch 871/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4074 - acc: 0.4329 - val_loss: 2.1859 - val_acc: 0.2433\n",
      "Epoch 872/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4062 - acc: 0.4271 - val_loss: 2.1716 - val_acc: 0.2600\n",
      "Epoch 873/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4071 - acc: 0.4329 - val_loss: 2.1525 - val_acc: 0.2333\n",
      "Epoch 874/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4075 - acc: 0.4300 - val_loss: 2.1642 - val_acc: 0.2333\n",
      "Epoch 875/1000\n",
      "700/700 [==============================] - 0s 206us/step - loss: 1.4067 - acc: 0.4357 - val_loss: 2.1842 - val_acc: 0.2400\n",
      "Epoch 876/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.4061 - acc: 0.4300 - val_loss: 2.1650 - val_acc: 0.2433\n",
      "Epoch 877/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4059 - acc: 0.4300 - val_loss: 2.1840 - val_acc: 0.2367\n",
      "Epoch 878/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4071 - acc: 0.4286 - val_loss: 2.1808 - val_acc: 0.2367\n",
      "Epoch 879/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.4035 - acc: 0.4371 - val_loss: 2.1832 - val_acc: 0.2300\n",
      "Epoch 880/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.4081 - acc: 0.4271 - val_loss: 2.1711 - val_acc: 0.2333\n",
      "Epoch 881/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4061 - acc: 0.4386 - val_loss: 2.1956 - val_acc: 0.2400\n",
      "Epoch 882/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4063 - acc: 0.4329 - val_loss: 2.1845 - val_acc: 0.2467\n",
      "Epoch 883/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4070 - acc: 0.4214 - val_loss: 2.1614 - val_acc: 0.2333\n",
      "Epoch 884/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4049 - acc: 0.4243 - val_loss: 2.1899 - val_acc: 0.2567\n",
      "Epoch 885/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4060 - acc: 0.4286 - val_loss: 2.1555 - val_acc: 0.2400\n",
      "Epoch 886/1000\n",
      "700/700 [==============================] - 0s 167us/step - loss: 1.4063 - acc: 0.4329 - val_loss: 2.1851 - val_acc: 0.2467\n",
      "Epoch 887/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 143us/step - loss: 1.4053 - acc: 0.4329 - val_loss: 2.1726 - val_acc: 0.2333\n",
      "Epoch 888/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4054 - acc: 0.4357 - val_loss: 2.1773 - val_acc: 0.2400\n",
      "Epoch 889/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4034 - acc: 0.4429 - val_loss: 2.1905 - val_acc: 0.2567\n",
      "Epoch 890/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4055 - acc: 0.4371 - val_loss: 2.1757 - val_acc: 0.2533\n",
      "Epoch 891/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4052 - acc: 0.4257 - val_loss: 2.1800 - val_acc: 0.2467\n",
      "Epoch 892/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4052 - acc: 0.4300 - val_loss: 2.1852 - val_acc: 0.2433\n",
      "Epoch 893/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.4047 - acc: 0.4329 - val_loss: 2.1909 - val_acc: 0.2400\n",
      "Epoch 894/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4049 - acc: 0.4343 - val_loss: 2.1779 - val_acc: 0.2333\n",
      "Epoch 895/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4040 - acc: 0.4314 - val_loss: 2.1821 - val_acc: 0.2467\n",
      "Epoch 896/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.4039 - acc: 0.4329 - val_loss: 2.1853 - val_acc: 0.2567\n",
      "Epoch 897/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4043 - acc: 0.4343 - val_loss: 2.1905 - val_acc: 0.2567\n",
      "Epoch 898/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4039 - acc: 0.4386 - val_loss: 2.1980 - val_acc: 0.2433\n",
      "Epoch 899/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4042 - acc: 0.4243 - val_loss: 2.1723 - val_acc: 0.2433\n",
      "Epoch 900/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4029 - acc: 0.4429 - val_loss: 2.1774 - val_acc: 0.2433\n",
      "Epoch 901/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4024 - acc: 0.4357 - val_loss: 2.1895 - val_acc: 0.2600\n",
      "Epoch 902/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4028 - acc: 0.4314 - val_loss: 2.1829 - val_acc: 0.2433\n",
      "Epoch 903/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4019 - acc: 0.4357 - val_loss: 2.1949 - val_acc: 0.2600\n",
      "Epoch 904/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4014 - acc: 0.4329 - val_loss: 2.1780 - val_acc: 0.2400\n",
      "Epoch 905/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4037 - acc: 0.4386 - val_loss: 2.1732 - val_acc: 0.2367\n",
      "Epoch 906/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.4027 - acc: 0.4329 - val_loss: 2.1684 - val_acc: 0.2333\n",
      "Epoch 907/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4029 - acc: 0.4357 - val_loss: 2.1926 - val_acc: 0.2433\n",
      "Epoch 908/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4024 - acc: 0.4386 - val_loss: 2.1802 - val_acc: 0.2400\n",
      "Epoch 909/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.4021 - acc: 0.4357 - val_loss: 2.1815 - val_acc: 0.2400\n",
      "Epoch 910/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4029 - acc: 0.4329 - val_loss: 2.1743 - val_acc: 0.2367\n",
      "Epoch 911/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4018 - acc: 0.4329 - val_loss: 2.1929 - val_acc: 0.2400\n",
      "Epoch 912/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4023 - acc: 0.4343 - val_loss: 2.1803 - val_acc: 0.2333\n",
      "Epoch 913/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4028 - acc: 0.4300 - val_loss: 2.2001 - val_acc: 0.2400\n",
      "Epoch 914/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4009 - acc: 0.4343 - val_loss: 2.1981 - val_acc: 0.2567\n",
      "Epoch 915/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4015 - acc: 0.4314 - val_loss: 2.1869 - val_acc: 0.2433\n",
      "Epoch 916/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4015 - acc: 0.4400 - val_loss: 2.1933 - val_acc: 0.2400\n",
      "Epoch 917/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4002 - acc: 0.4400 - val_loss: 2.1879 - val_acc: 0.2333\n",
      "Epoch 918/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.3997 - acc: 0.4329 - val_loss: 2.1931 - val_acc: 0.2533\n",
      "Epoch 919/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4012 - acc: 0.4257 - val_loss: 2.2034 - val_acc: 0.2400\n",
      "Epoch 920/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4016 - acc: 0.4300 - val_loss: 2.1820 - val_acc: 0.2367\n",
      "Epoch 921/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4014 - acc: 0.4314 - val_loss: 2.1828 - val_acc: 0.2333\n",
      "Epoch 922/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.3993 - acc: 0.4357 - val_loss: 2.1990 - val_acc: 0.2533\n",
      "Epoch 923/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.3992 - acc: 0.4343 - val_loss: 2.1824 - val_acc: 0.2567\n",
      "Epoch 924/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4015 - acc: 0.4400 - val_loss: 2.1903 - val_acc: 0.2333\n",
      "Epoch 925/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.3997 - acc: 0.4343 - val_loss: 2.1952 - val_acc: 0.2367\n",
      "Epoch 926/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.3999 - acc: 0.4400 - val_loss: 2.1873 - val_acc: 0.2433\n",
      "Epoch 927/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.4002 - acc: 0.4286 - val_loss: 2.1903 - val_acc: 0.2367\n",
      "Epoch 928/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.3998 - acc: 0.4386 - val_loss: 2.2032 - val_acc: 0.2433\n",
      "Epoch 929/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4000 - acc: 0.4400 - val_loss: 2.2027 - val_acc: 0.2400\n",
      "Epoch 930/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.3999 - acc: 0.4357 - val_loss: 2.1898 - val_acc: 0.2433\n",
      "Epoch 931/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.3994 - acc: 0.4314 - val_loss: 2.1916 - val_acc: 0.2367\n",
      "Epoch 932/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.3988 - acc: 0.4343 - val_loss: 2.1826 - val_acc: 0.2467\n",
      "Epoch 933/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.3994 - acc: 0.4286 - val_loss: 2.1932 - val_acc: 0.2367\n",
      "Epoch 934/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.3984 - acc: 0.4400 - val_loss: 2.1989 - val_acc: 0.2400\n",
      "Epoch 935/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.3991 - acc: 0.4314 - val_loss: 2.1959 - val_acc: 0.2433\n",
      "Epoch 936/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.3988 - acc: 0.4386 - val_loss: 2.2032 - val_acc: 0.2467\n",
      "Epoch 937/1000\n",
      "700/700 [==============================] - 0s 164us/step - loss: 1.3985 - acc: 0.4371 - val_loss: 2.1972 - val_acc: 0.2367\n",
      "Epoch 938/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.3983 - acc: 0.4386 - val_loss: 2.2046 - val_acc: 0.2467\n",
      "Epoch 939/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.3980 - acc: 0.4343 - val_loss: 2.2094 - val_acc: 0.2600\n",
      "Epoch 940/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.3987 - acc: 0.4343 - val_loss: 2.1907 - val_acc: 0.2367\n",
      "Epoch 941/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.3984 - acc: 0.4314 - val_loss: 2.1952 - val_acc: 0.2400\n",
      "Epoch 942/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.3974 - acc: 0.4371 - val_loss: 2.1817 - val_acc: 0.2300\n",
      "Epoch 943/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.3983 - acc: 0.4414 - val_loss: 2.2029 - val_acc: 0.2367\n",
      "Epoch 944/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.3969 - acc: 0.4371 - val_loss: 2.2058 - val_acc: 0.2433\n",
      "Epoch 945/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.3974 - acc: 0.4357 - val_loss: 2.2008 - val_acc: 0.2400\n",
      "Epoch 946/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 156us/step - loss: 1.3974 - acc: 0.4329 - val_loss: 2.1963 - val_acc: 0.2467\n",
      "Epoch 947/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.3964 - acc: 0.4400 - val_loss: 2.2075 - val_acc: 0.2567\n",
      "Epoch 948/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.3965 - acc: 0.4286 - val_loss: 2.1894 - val_acc: 0.2300\n",
      "Epoch 949/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.3965 - acc: 0.4386 - val_loss: 2.1893 - val_acc: 0.2400\n",
      "Epoch 950/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.3957 - acc: 0.4314 - val_loss: 2.1935 - val_acc: 0.2400\n",
      "Epoch 951/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.3965 - acc: 0.4371 - val_loss: 2.2033 - val_acc: 0.2467\n",
      "Epoch 952/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.3965 - acc: 0.4386 - val_loss: 2.1994 - val_acc: 0.2367\n",
      "Epoch 953/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.3964 - acc: 0.4343 - val_loss: 2.2030 - val_acc: 0.2567\n",
      "Epoch 954/1000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.3968 - acc: 0.4357 - val_loss: 2.1980 - val_acc: 0.2533\n",
      "Epoch 955/1000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.3964 - acc: 0.4400 - val_loss: 2.2069 - val_acc: 0.2400\n",
      "Epoch 956/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.3957 - acc: 0.4400 - val_loss: 2.2117 - val_acc: 0.2400\n",
      "Epoch 957/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.3952 - acc: 0.4357 - val_loss: 2.1977 - val_acc: 0.2367\n",
      "Epoch 958/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.3967 - acc: 0.4343 - val_loss: 2.2261 - val_acc: 0.2533\n",
      "Epoch 959/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.3963 - acc: 0.4357 - val_loss: 2.1934 - val_acc: 0.2467\n",
      "Epoch 960/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.3956 - acc: 0.4343 - val_loss: 2.2132 - val_acc: 0.2367\n",
      "Epoch 961/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.3949 - acc: 0.4400 - val_loss: 2.1805 - val_acc: 0.2467\n",
      "Epoch 962/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.3960 - acc: 0.4343 - val_loss: 2.2013 - val_acc: 0.2400\n",
      "Epoch 963/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.3953 - acc: 0.4343 - val_loss: 2.1971 - val_acc: 0.2467\n",
      "Epoch 964/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.3947 - acc: 0.4343 - val_loss: 2.1894 - val_acc: 0.2467\n",
      "Epoch 965/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.3940 - acc: 0.4400 - val_loss: 2.1971 - val_acc: 0.2467\n",
      "Epoch 966/1000\n",
      "700/700 [==============================] - 0s 156us/step - loss: 1.3952 - acc: 0.4357 - val_loss: 2.2141 - val_acc: 0.2467\n",
      "Epoch 967/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.3950 - acc: 0.4400 - val_loss: 2.2079 - val_acc: 0.2467\n",
      "Epoch 968/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.3941 - acc: 0.4371 - val_loss: 2.1982 - val_acc: 0.2333\n",
      "Epoch 969/1000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.3945 - acc: 0.4400 - val_loss: 2.2026 - val_acc: 0.2400\n",
      "Epoch 970/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.3942 - acc: 0.4371 - val_loss: 2.2124 - val_acc: 0.2333\n",
      "Epoch 971/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.3945 - acc: 0.4400 - val_loss: 2.1982 - val_acc: 0.2433\n",
      "Epoch 972/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.3939 - acc: 0.4371 - val_loss: 2.2133 - val_acc: 0.2367\n",
      "Epoch 973/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.3928 - acc: 0.4371 - val_loss: 2.2077 - val_acc: 0.2433\n",
      "Epoch 974/1000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.3936 - acc: 0.4357 - val_loss: 2.2086 - val_acc: 0.2467\n",
      "Epoch 975/1000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.3936 - acc: 0.4386 - val_loss: 2.2149 - val_acc: 0.2400\n",
      "Epoch 976/1000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.3930 - acc: 0.4414 - val_loss: 2.2041 - val_acc: 0.2467\n",
      "Epoch 977/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.3932 - acc: 0.4329 - val_loss: 2.2024 - val_acc: 0.2367\n",
      "Epoch 978/1000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.3929 - acc: 0.4486 - val_loss: 2.2060 - val_acc: 0.2433\n",
      "Epoch 979/1000\n",
      "700/700 [==============================] - 0s 153us/step - loss: 1.3934 - acc: 0.4357 - val_loss: 2.2044 - val_acc: 0.2433\n",
      "Epoch 980/1000\n",
      "700/700 [==============================] - 0s 157us/step - loss: 1.3934 - acc: 0.4357 - val_loss: 2.2158 - val_acc: 0.2433\n",
      "Epoch 981/1000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.3919 - acc: 0.4357 - val_loss: 2.2222 - val_acc: 0.2400\n",
      "Epoch 982/1000\n",
      "700/700 [==============================] - 0s 161us/step - loss: 1.3929 - acc: 0.4357 - val_loss: 2.2075 - val_acc: 0.2500\n",
      "Epoch 983/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.3927 - acc: 0.4357 - val_loss: 2.2111 - val_acc: 0.2433\n",
      "Epoch 984/1000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.3923 - acc: 0.4343 - val_loss: 2.2061 - val_acc: 0.2467\n",
      "Epoch 985/1000\n",
      "700/700 [==============================] - 0s 160us/step - loss: 1.3918 - acc: 0.4443 - val_loss: 2.2163 - val_acc: 0.2400\n",
      "Epoch 986/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.3921 - acc: 0.4357 - val_loss: 2.2113 - val_acc: 0.2500\n",
      "Epoch 987/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.3915 - acc: 0.4414 - val_loss: 2.2031 - val_acc: 0.2367\n",
      "Epoch 988/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.3911 - acc: 0.4386 - val_loss: 2.2225 - val_acc: 0.2567\n",
      "Epoch 989/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.3930 - acc: 0.4300 - val_loss: 2.2262 - val_acc: 0.2533\n",
      "Epoch 990/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.3915 - acc: 0.4414 - val_loss: 2.2340 - val_acc: 0.2500\n",
      "Epoch 991/1000\n",
      "700/700 [==============================] - 0s 161us/step - loss: 1.3913 - acc: 0.4414 - val_loss: 2.2119 - val_acc: 0.2367\n",
      "Epoch 992/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.3915 - acc: 0.4371 - val_loss: 2.2160 - val_acc: 0.2400\n",
      "Epoch 993/1000\n",
      "700/700 [==============================] - 0s 163us/step - loss: 1.3914 - acc: 0.4486 - val_loss: 2.2096 - val_acc: 0.2467\n",
      "Epoch 994/1000\n",
      "700/700 [==============================] - 0s 180us/step - loss: 1.3912 - acc: 0.4357 - val_loss: 2.2042 - val_acc: 0.2367\n",
      "Epoch 995/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.3918 - acc: 0.4400 - val_loss: 2.2148 - val_acc: 0.2500\n",
      "Epoch 996/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.3902 - acc: 0.4443 - val_loss: 2.2138 - val_acc: 0.2400\n",
      "Epoch 997/1000\n",
      "700/700 [==============================] - 0s 160us/step - loss: 1.3907 - acc: 0.4443 - val_loss: 2.2142 - val_acc: 0.2400\n",
      "Epoch 998/1000\n",
      "700/700 [==============================] - 0s 160us/step - loss: 1.3911 - acc: 0.4371 - val_loss: 2.2271 - val_acc: 0.2500\n",
      "Epoch 999/1000\n",
      "700/700 [==============================] - 0s 166us/step - loss: 1.3908 - acc: 0.4371 - val_loss: 2.2135 - val_acc: 0.2467\n",
      "Epoch 1000/1000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.3906 - acc: 0.4400 - val_loss: 2.2209 - val_acc: 0.2400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa6e5dee710>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "# 1. 데이터셋 준비하기\n",
    "\n",
    "# 훈련셋과 시험셋 로딩\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# 훈련셋과 검증셋 분리\n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "\n",
    "X_train = X_train.reshape(50000, 784).astype('float32') / 255.0\n",
    "X_val = X_val.reshape(10000, 784).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "# 훈련셋, 검증셋 고르기\n",
    "train_rand_idxs = np.random.choice(50000, 700)\n",
    "val_rand_idxs = np.random.choice(10000, 300)\n",
    "\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]\n",
    "\n",
    "# 라벨링 전환\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_val = np_utils.to_categorical(Y_val)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# 3. 모델 엮기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "tb_hist = keras.callbacks.TensorBoard(log_dir='./graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "model.fit(X_train, Y_train, epochs=1000, batch_size=10, validation_data=(X_val, Y_val), callbacks=[tb_hist])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/ipython/ml_learning_space/PythonDeepLearningKeras\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part1-ch01.ipynb  Part2.ipynb  graph  mnist_mlp_model.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard 0.4.0rc2 at http://2106d1994446:6006 (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=/root/ipython/ml_learning_space/PythonDeepLearningKeras/graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ch03. 직접 콜백함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "# 사용자 정의 히스토리 클래스 정의\n",
    "class CustomHistory(keras.callbacks.Callback):\n",
    "    def init(self):\n",
    "        self.losses = []\n",
    "        self.vol_losses = []\n",
    "        self.accs = []\n",
    "        self.vol_accs = []        \n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.vol_losses.append(logs.get('val_loss'))\n",
    "        self.accs.append(logs.get('acc'))\n",
    "        self.vol_accs.append(logs.get('val_acc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs : 0\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 323us/step - loss: 2.2576 - acc: 0.1643 - val_loss: 2.2272 - val_acc: 0.1633\n",
      "epochs : 1\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 2.2067 - acc: 0.1786 - val_loss: 2.1908 - val_acc: 0.1800\n",
      "epochs : 2\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 127us/step - loss: 2.1732 - acc: 0.1814 - val_loss: 2.1640 - val_acc: 0.1833\n",
      "epochs : 3\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 183us/step - loss: 2.1445 - acc: 0.1971 - val_loss: 2.1410 - val_acc: 0.1833\n",
      "epochs : 4\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 136us/step - loss: 2.1186 - acc: 0.1929 - val_loss: 2.1153 - val_acc: 0.2000\n",
      "epochs : 5\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 131us/step - loss: 2.0936 - acc: 0.2029 - val_loss: 2.0953 - val_acc: 0.1967\n",
      "epochs : 6\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 128us/step - loss: 2.0731 - acc: 0.2043 - val_loss: 2.0757 - val_acc: 0.2033\n",
      "epochs : 7\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 128us/step - loss: 2.0530 - acc: 0.2071 - val_loss: 2.0571 - val_acc: 0.2067\n",
      "epochs : 8\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 133us/step - loss: 2.0350 - acc: 0.2200 - val_loss: 2.0402 - val_acc: 0.2033\n",
      "epochs : 9\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 130us/step - loss: 2.0191 - acc: 0.2171 - val_loss: 2.0284 - val_acc: 0.2033\n",
      "epochs : 10\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 131us/step - loss: 2.0047 - acc: 0.2200 - val_loss: 2.0136 - val_acc: 0.2100\n",
      "epochs : 11\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.9918 - acc: 0.2271 - val_loss: 2.0034 - val_acc: 0.2067\n",
      "epochs : 12\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.9797 - acc: 0.2243 - val_loss: 1.9930 - val_acc: 0.2100\n",
      "epochs : 13\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.9687 - acc: 0.2257 - val_loss: 1.9853 - val_acc: 0.2067\n",
      "epochs : 14\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.9580 - acc: 0.2314 - val_loss: 1.9784 - val_acc: 0.2100\n",
      "epochs : 15\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.9489 - acc: 0.2286 - val_loss: 1.9696 - val_acc: 0.2133\n",
      "epochs : 16\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.9398 - acc: 0.2343 - val_loss: 1.9629 - val_acc: 0.2167\n",
      "epochs : 17\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.9315 - acc: 0.2300 - val_loss: 1.9540 - val_acc: 0.2100\n",
      "epochs : 18\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.9233 - acc: 0.2286 - val_loss: 1.9470 - val_acc: 0.2033\n",
      "epochs : 19\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.9152 - acc: 0.2371 - val_loss: 1.9391 - val_acc: 0.2000\n",
      "epochs : 20\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.9093 - acc: 0.2371 - val_loss: 1.9343 - val_acc: 0.2067\n",
      "epochs : 21\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.9018 - acc: 0.2386 - val_loss: 1.9289 - val_acc: 0.2133\n",
      "epochs : 22\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.8950 - acc: 0.2314 - val_loss: 1.9246 - val_acc: 0.1900\n",
      "epochs : 23\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.8895 - acc: 0.2400 - val_loss: 1.9189 - val_acc: 0.2067\n",
      "epochs : 24\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.8829 - acc: 0.2371 - val_loss: 1.9144 - val_acc: 0.2133\n",
      "epochs : 25\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.8777 - acc: 0.2429 - val_loss: 1.9119 - val_acc: 0.2000\n",
      "epochs : 26\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.8719 - acc: 0.2300 - val_loss: 1.9138 - val_acc: 0.2133\n",
      "epochs : 27\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.8666 - acc: 0.2343 - val_loss: 1.9025 - val_acc: 0.2000\n",
      "epochs : 28\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.8613 - acc: 0.2400 - val_loss: 1.9004 - val_acc: 0.1867\n",
      "epochs : 29\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.8560 - acc: 0.2386 - val_loss: 1.8952 - val_acc: 0.2000\n",
      "epochs : 30\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.8513 - acc: 0.2414 - val_loss: 1.8933 - val_acc: 0.2200\n",
      "epochs : 31\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.8468 - acc: 0.2429 - val_loss: 1.8892 - val_acc: 0.1900\n",
      "epochs : 32\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.8427 - acc: 0.2357 - val_loss: 1.8868 - val_acc: 0.1900\n",
      "epochs : 33\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.8380 - acc: 0.2329 - val_loss: 1.8849 - val_acc: 0.2033\n",
      "epochs : 34\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.8332 - acc: 0.2429 - val_loss: 1.8792 - val_acc: 0.1800\n",
      "epochs : 35\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.8291 - acc: 0.2343 - val_loss: 1.8831 - val_acc: 0.2067\n",
      "epochs : 36\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.8259 - acc: 0.2400 - val_loss: 1.8760 - val_acc: 0.2033\n",
      "epochs : 37\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 414us/step - loss: 1.8214 - acc: 0.2371 - val_loss: 1.8759 - val_acc: 0.1967\n",
      "epochs : 38\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.8183 - acc: 0.2414 - val_loss: 1.8703 - val_acc: 0.2033\n",
      "epochs : 39\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.8149 - acc: 0.2343 - val_loss: 1.8665 - val_acc: 0.1933\n",
      "epochs : 40\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.8104 - acc: 0.2429 - val_loss: 1.8683 - val_acc: 0.1967\n",
      "epochs : 41\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.8075 - acc: 0.2400 - val_loss: 1.8599 - val_acc: 0.1933\n",
      "epochs : 42\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.8030 - acc: 0.2600 - val_loss: 1.8682 - val_acc: 0.1867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs : 43\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.8006 - acc: 0.2371 - val_loss: 1.8573 - val_acc: 0.1967\n",
      "epochs : 44\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.7974 - acc: 0.2471 - val_loss: 1.8580 - val_acc: 0.1933\n",
      "epochs : 45\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.7942 - acc: 0.2471 - val_loss: 1.8558 - val_acc: 0.1700\n",
      "epochs : 46\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.7912 - acc: 0.2386 - val_loss: 1.8556 - val_acc: 0.1900\n",
      "epochs : 47\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.7884 - acc: 0.2443 - val_loss: 1.8549 - val_acc: 0.2033\n",
      "epochs : 48\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.7852 - acc: 0.2643 - val_loss: 1.8517 - val_acc: 0.1867\n",
      "epochs : 49\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.7825 - acc: 0.2443 - val_loss: 1.8480 - val_acc: 0.2233\n",
      "epochs : 50\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.7795 - acc: 0.2600 - val_loss: 1.8448 - val_acc: 0.1800\n",
      "epochs : 51\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.7763 - acc: 0.2629 - val_loss: 1.8461 - val_acc: 0.2233\n",
      "epochs : 52\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.7744 - acc: 0.2514 - val_loss: 1.8449 - val_acc: 0.2233\n",
      "epochs : 53\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.7716 - acc: 0.2386 - val_loss: 1.8380 - val_acc: 0.2233\n",
      "epochs : 54\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.7686 - acc: 0.2629 - val_loss: 1.8395 - val_acc: 0.1967\n",
      "epochs : 55\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.7665 - acc: 0.2571 - val_loss: 1.8398 - val_acc: 0.2300\n",
      "epochs : 56\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.7642 - acc: 0.2629 - val_loss: 1.8399 - val_acc: 0.2100\n",
      "epochs : 57\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.7612 - acc: 0.2643 - val_loss: 1.8394 - val_acc: 0.2133\n",
      "epochs : 58\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.7584 - acc: 0.2571 - val_loss: 1.8325 - val_acc: 0.2100\n",
      "epochs : 59\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.7571 - acc: 0.2714 - val_loss: 1.8380 - val_acc: 0.2167\n",
      "epochs : 60\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.7549 - acc: 0.2671 - val_loss: 1.8338 - val_acc: 0.2067\n",
      "epochs : 61\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.7519 - acc: 0.2543 - val_loss: 1.8328 - val_acc: 0.2367\n",
      "epochs : 62\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.7498 - acc: 0.2857 - val_loss: 1.8313 - val_acc: 0.2000\n",
      "epochs : 63\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.7472 - acc: 0.2629 - val_loss: 1.8290 - val_acc: 0.2400\n",
      "epochs : 64\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.7451 - acc: 0.2843 - val_loss: 1.8323 - val_acc: 0.2067\n",
      "epochs : 65\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.7439 - acc: 0.2700 - val_loss: 1.8287 - val_acc: 0.2033\n",
      "epochs : 66\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.7405 - acc: 0.2800 - val_loss: 1.8248 - val_acc: 0.2433\n",
      "epochs : 67\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.7387 - acc: 0.2900 - val_loss: 1.8318 - val_acc: 0.2000\n",
      "epochs : 68\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.7374 - acc: 0.2671 - val_loss: 1.8275 - val_acc: 0.2167\n",
      "epochs : 69\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.7356 - acc: 0.2729 - val_loss: 1.8257 - val_acc: 0.2033\n",
      "epochs : 70\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.7341 - acc: 0.2714 - val_loss: 1.8239 - val_acc: 0.1967\n",
      "epochs : 71\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.7305 - acc: 0.2771 - val_loss: 1.8261 - val_acc: 0.2467\n",
      "epochs : 72\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.7303 - acc: 0.2986 - val_loss: 1.8208 - val_acc: 0.2133\n",
      "epochs : 73\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.7278 - acc: 0.2900 - val_loss: 1.8303 - val_acc: 0.2067\n",
      "epochs : 74\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.7252 - acc: 0.2857 - val_loss: 1.8151 - val_acc: 0.2733\n",
      "epochs : 75\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.7251 - acc: 0.2929 - val_loss: 1.8180 - val_acc: 0.2200\n",
      "epochs : 76\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.7237 - acc: 0.2957 - val_loss: 1.8214 - val_acc: 0.2233\n",
      "epochs : 77\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.7210 - acc: 0.2914 - val_loss: 1.8186 - val_acc: 0.2067\n",
      "epochs : 78\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.7196 - acc: 0.3014 - val_loss: 1.8265 - val_acc: 0.2000\n",
      "epochs : 79\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.7180 - acc: 0.2814 - val_loss: 1.8233 - val_acc: 0.2067\n",
      "epochs : 80\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.7158 - acc: 0.2871 - val_loss: 1.8170 - val_acc: 0.2433\n",
      "epochs : 81\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.7146 - acc: 0.2986 - val_loss: 1.8205 - val_acc: 0.2267\n",
      "epochs : 82\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.7118 - acc: 0.2957 - val_loss: 1.8204 - val_acc: 0.2667\n",
      "epochs : 83\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.7124 - acc: 0.2900 - val_loss: 1.8228 - val_acc: 0.2333\n",
      "epochs : 84\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.7097 - acc: 0.2886 - val_loss: 1.8162 - val_acc: 0.2200\n",
      "epochs : 85\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.7088 - acc: 0.2786 - val_loss: 1.8132 - val_acc: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs : 86\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.7063 - acc: 0.3071 - val_loss: 1.8158 - val_acc: 0.2633\n",
      "epochs : 87\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.7058 - acc: 0.2914 - val_loss: 1.8132 - val_acc: 0.2200\n",
      "epochs : 88\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.7034 - acc: 0.2914 - val_loss: 1.8258 - val_acc: 0.2267\n",
      "epochs : 89\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.7022 - acc: 0.2900 - val_loss: 1.8220 - val_acc: 0.2700\n",
      "epochs : 90\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.7009 - acc: 0.3114 - val_loss: 1.8231 - val_acc: 0.2233\n",
      "epochs : 91\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.6996 - acc: 0.2957 - val_loss: 1.8130 - val_acc: 0.2467\n",
      "epochs : 92\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.6978 - acc: 0.2971 - val_loss: 1.8215 - val_acc: 0.2167\n",
      "epochs : 93\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.6976 - acc: 0.2943 - val_loss: 1.8139 - val_acc: 0.2133\n",
      "epochs : 94\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.6954 - acc: 0.2986 - val_loss: 1.8187 - val_acc: 0.2267\n",
      "epochs : 95\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.6940 - acc: 0.3000 - val_loss: 1.8187 - val_acc: 0.2567\n",
      "epochs : 96\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.6921 - acc: 0.3029 - val_loss: 1.8190 - val_acc: 0.2400\n",
      "epochs : 97\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.6916 - acc: 0.2929 - val_loss: 1.8154 - val_acc: 0.2367\n",
      "epochs : 98\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.6902 - acc: 0.3086 - val_loss: 1.8164 - val_acc: 0.2267\n",
      "epochs : 99\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.6880 - acc: 0.3043 - val_loss: 1.8232 - val_acc: 0.2233\n",
      "epochs : 100\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.6873 - acc: 0.3000 - val_loss: 1.8143 - val_acc: 0.2467\n",
      "epochs : 101\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.6859 - acc: 0.3114 - val_loss: 1.8175 - val_acc: 0.2267\n",
      "epochs : 102\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.6843 - acc: 0.3157 - val_loss: 1.8233 - val_acc: 0.2167\n",
      "epochs : 103\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.6843 - acc: 0.2986 - val_loss: 1.8170 - val_acc: 0.2267\n",
      "epochs : 104\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.6832 - acc: 0.2957 - val_loss: 1.8127 - val_acc: 0.2267\n",
      "epochs : 105\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.6820 - acc: 0.3086 - val_loss: 1.8166 - val_acc: 0.2300\n",
      "epochs : 106\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.6807 - acc: 0.3071 - val_loss: 1.8140 - val_acc: 0.2267\n",
      "epochs : 107\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.6781 - acc: 0.3057 - val_loss: 1.8144 - val_acc: 0.2100\n",
      "epochs : 108\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.6778 - acc: 0.2986 - val_loss: 1.8158 - val_acc: 0.2267\n",
      "epochs : 109\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.6764 - acc: 0.3071 - val_loss: 1.8176 - val_acc: 0.2467\n",
      "epochs : 110\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.6752 - acc: 0.3143 - val_loss: 1.8152 - val_acc: 0.2267\n",
      "epochs : 111\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.6727 - acc: 0.3214 - val_loss: 1.8300 - val_acc: 0.2133\n",
      "epochs : 112\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.6736 - acc: 0.3129 - val_loss: 1.8149 - val_acc: 0.2200\n",
      "epochs : 113\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.6726 - acc: 0.3100 - val_loss: 1.8164 - val_acc: 0.2200\n",
      "epochs : 114\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.6708 - acc: 0.3186 - val_loss: 1.8164 - val_acc: 0.2200\n",
      "epochs : 115\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.6699 - acc: 0.3100 - val_loss: 1.8230 - val_acc: 0.2200\n",
      "epochs : 116\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.6699 - acc: 0.3043 - val_loss: 1.8221 - val_acc: 0.2133\n",
      "epochs : 117\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.6681 - acc: 0.3043 - val_loss: 1.8172 - val_acc: 0.2367\n",
      "epochs : 118\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.6672 - acc: 0.3029 - val_loss: 1.8261 - val_acc: 0.2500\n",
      "epochs : 119\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.6667 - acc: 0.3114 - val_loss: 1.8191 - val_acc: 0.2233\n",
      "epochs : 120\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.6644 - acc: 0.3071 - val_loss: 1.8240 - val_acc: 0.2267\n",
      "epochs : 121\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.6637 - acc: 0.3186 - val_loss: 1.8247 - val_acc: 0.2233\n",
      "epochs : 122\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.6626 - acc: 0.3214 - val_loss: 1.8227 - val_acc: 0.2433\n",
      "epochs : 123\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.6619 - acc: 0.3057 - val_loss: 1.8222 - val_acc: 0.2600\n",
      "epochs : 124\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.6604 - acc: 0.3200 - val_loss: 1.8202 - val_acc: 0.2233\n",
      "epochs : 125\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.6604 - acc: 0.3200 - val_loss: 1.8167 - val_acc: 0.2200\n",
      "epochs : 126\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.6550 - acc: 0.3286 - val_loss: 1.8333 - val_acc: 0.2300\n",
      "epochs : 127\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.6600 - acc: 0.3114 - val_loss: 1.8191 - val_acc: 0.2233\n",
      "epochs : 128\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 115us/step - loss: 1.6564 - acc: 0.3100 - val_loss: 1.8285 - val_acc: 0.2533\n",
      "epochs : 129\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.6546 - acc: 0.3186 - val_loss: 1.8183 - val_acc: 0.2700\n",
      "epochs : 130\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.6550 - acc: 0.3214 - val_loss: 1.8235 - val_acc: 0.2600\n",
      "epochs : 131\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.6543 - acc: 0.3143 - val_loss: 1.8189 - val_acc: 0.2233\n",
      "epochs : 132\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.6520 - acc: 0.3271 - val_loss: 1.8172 - val_acc: 0.2267\n",
      "epochs : 133\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.6510 - acc: 0.3200 - val_loss: 1.8162 - val_acc: 0.2500\n",
      "epochs : 134\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.6511 - acc: 0.3229 - val_loss: 1.8203 - val_acc: 0.2667\n",
      "epochs : 135\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.6507 - acc: 0.3271 - val_loss: 1.8162 - val_acc: 0.2233\n",
      "epochs : 136\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.6492 - acc: 0.3243 - val_loss: 1.8136 - val_acc: 0.2333\n",
      "epochs : 137\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.6487 - acc: 0.3271 - val_loss: 1.8274 - val_acc: 0.2700\n",
      "epochs : 138\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.6480 - acc: 0.3300 - val_loss: 1.8223 - val_acc: 0.2200\n",
      "epochs : 139\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.6476 - acc: 0.3143 - val_loss: 1.8261 - val_acc: 0.2233\n",
      "epochs : 140\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.6456 - acc: 0.3286 - val_loss: 1.8248 - val_acc: 0.2333\n",
      "epochs : 141\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.6451 - acc: 0.3171 - val_loss: 1.8204 - val_acc: 0.2167\n",
      "epochs : 142\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.6435 - acc: 0.3314 - val_loss: 1.8216 - val_acc: 0.2567\n",
      "epochs : 143\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.6425 - acc: 0.3271 - val_loss: 1.8179 - val_acc: 0.2200\n",
      "epochs : 144\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.6414 - acc: 0.3143 - val_loss: 1.8195 - val_acc: 0.2333\n",
      "epochs : 145\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.6408 - acc: 0.3329 - val_loss: 1.8170 - val_acc: 0.2733\n",
      "epochs : 146\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.6402 - acc: 0.3343 - val_loss: 1.8278 - val_acc: 0.2333\n",
      "epochs : 147\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.6393 - acc: 0.3257 - val_loss: 1.8280 - val_acc: 0.2167\n",
      "epochs : 148\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.6380 - acc: 0.3157 - val_loss: 1.8318 - val_acc: 0.2400\n",
      "epochs : 149\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.6384 - acc: 0.3357 - val_loss: 1.8140 - val_acc: 0.2100\n",
      "epochs : 150\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.6357 - acc: 0.3229 - val_loss: 1.8411 - val_acc: 0.2467\n",
      "epochs : 151\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.6348 - acc: 0.3414 - val_loss: 1.8278 - val_acc: 0.2600\n",
      "epochs : 152\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.6349 - acc: 0.3257 - val_loss: 1.8188 - val_acc: 0.2300\n",
      "epochs : 153\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.6345 - acc: 0.3286 - val_loss: 1.8294 - val_acc: 0.2200\n",
      "epochs : 154\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.6321 - acc: 0.3443 - val_loss: 1.8207 - val_acc: 0.2167\n",
      "epochs : 155\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.6327 - acc: 0.3300 - val_loss: 1.8167 - val_acc: 0.2267\n",
      "epochs : 156\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.6321 - acc: 0.3329 - val_loss: 1.8318 - val_acc: 0.2667\n",
      "epochs : 157\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.6311 - acc: 0.3329 - val_loss: 1.8318 - val_acc: 0.2667\n",
      "epochs : 158\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.6294 - acc: 0.3314 - val_loss: 1.8306 - val_acc: 0.2133\n",
      "epochs : 159\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.6301 - acc: 0.3214 - val_loss: 1.8262 - val_acc: 0.2433\n",
      "epochs : 160\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.6273 - acc: 0.3343 - val_loss: 1.8153 - val_acc: 0.2467\n",
      "epochs : 161\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.6285 - acc: 0.3314 - val_loss: 1.8362 - val_acc: 0.2300\n",
      "epochs : 162\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.6274 - acc: 0.3329 - val_loss: 1.8230 - val_acc: 0.2367\n",
      "epochs : 163\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.6247 - acc: 0.3457 - val_loss: 1.8324 - val_acc: 0.2200\n",
      "epochs : 164\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.6266 - acc: 0.3314 - val_loss: 1.8313 - val_acc: 0.2300\n",
      "epochs : 165\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.6230 - acc: 0.3357 - val_loss: 1.8304 - val_acc: 0.2200\n",
      "epochs : 166\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.6245 - acc: 0.3329 - val_loss: 1.8272 - val_acc: 0.2667\n",
      "epochs : 167\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.6239 - acc: 0.3229 - val_loss: 1.8430 - val_acc: 0.2200\n",
      "epochs : 168\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.6216 - acc: 0.3386 - val_loss: 1.8313 - val_acc: 0.2233\n",
      "epochs : 169\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.6222 - acc: 0.3300 - val_loss: 1.8347 - val_acc: 0.2167\n",
      "epochs : 170\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.6224 - acc: 0.3114 - val_loss: 1.8314 - val_acc: 0.2267\n",
      "epochs : 171\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 119us/step - loss: 1.6201 - acc: 0.3314 - val_loss: 1.8299 - val_acc: 0.2167\n",
      "epochs : 172\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.6213 - acc: 0.3171 - val_loss: 1.8463 - val_acc: 0.2233\n",
      "epochs : 173\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.6193 - acc: 0.3314 - val_loss: 1.8391 - val_acc: 0.2167\n",
      "epochs : 174\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.6181 - acc: 0.3371 - val_loss: 1.8431 - val_acc: 0.2167\n",
      "epochs : 175\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.6169 - acc: 0.3157 - val_loss: 1.8306 - val_acc: 0.2567\n",
      "epochs : 176\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.6180 - acc: 0.3214 - val_loss: 1.8346 - val_acc: 0.2433\n",
      "epochs : 177\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.6177 - acc: 0.3314 - val_loss: 1.8343 - val_acc: 0.2233\n",
      "epochs : 178\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.6161 - acc: 0.3314 - val_loss: 1.8358 - val_acc: 0.2167\n",
      "epochs : 179\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.6143 - acc: 0.3271 - val_loss: 1.8374 - val_acc: 0.2233\n",
      "epochs : 180\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.6132 - acc: 0.3443 - val_loss: 1.8453 - val_acc: 0.2333\n",
      "epochs : 181\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.6143 - acc: 0.3343 - val_loss: 1.8358 - val_acc: 0.2267\n",
      "epochs : 182\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.6139 - acc: 0.3243 - val_loss: 1.8457 - val_acc: 0.2133\n",
      "epochs : 183\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.6110 - acc: 0.3486 - val_loss: 1.8515 - val_acc: 0.2700\n",
      "epochs : 184\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.6122 - acc: 0.3286 - val_loss: 1.8414 - val_acc: 0.2467\n",
      "epochs : 185\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.6113 - acc: 0.3271 - val_loss: 1.8383 - val_acc: 0.2233\n",
      "epochs : 186\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.6107 - acc: 0.3271 - val_loss: 1.8395 - val_acc: 0.2167\n",
      "epochs : 187\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.6082 - acc: 0.3314 - val_loss: 1.8472 - val_acc: 0.2100\n",
      "epochs : 188\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.6069 - acc: 0.3329 - val_loss: 1.8504 - val_acc: 0.2700\n",
      "epochs : 189\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.6082 - acc: 0.3386 - val_loss: 1.8442 - val_acc: 0.2167\n",
      "epochs : 190\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.6061 - acc: 0.3286 - val_loss: 1.8421 - val_acc: 0.2167\n",
      "epochs : 191\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.6069 - acc: 0.3300 - val_loss: 1.8493 - val_acc: 0.2133\n",
      "epochs : 192\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.6071 - acc: 0.3329 - val_loss: 1.8462 - val_acc: 0.2167\n",
      "epochs : 193\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.6049 - acc: 0.3414 - val_loss: 1.8584 - val_acc: 0.2167\n",
      "epochs : 194\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.6054 - acc: 0.3271 - val_loss: 1.8471 - val_acc: 0.2233\n",
      "epochs : 195\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.6012 - acc: 0.3429 - val_loss: 1.8731 - val_acc: 0.2233\n",
      "epochs : 196\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.6042 - acc: 0.3371 - val_loss: 1.8471 - val_acc: 0.2167\n",
      "epochs : 197\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.6028 - acc: 0.3271 - val_loss: 1.8469 - val_acc: 0.2167\n",
      "epochs : 198\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.6019 - acc: 0.3314 - val_loss: 1.8460 - val_acc: 0.2133\n",
      "epochs : 199\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.6005 - acc: 0.3386 - val_loss: 1.8556 - val_acc: 0.2267\n",
      "epochs : 200\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.6016 - acc: 0.3371 - val_loss: 1.8448 - val_acc: 0.2167\n",
      "epochs : 201\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5980 - acc: 0.3300 - val_loss: 1.8576 - val_acc: 0.2567\n",
      "epochs : 202\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.5987 - acc: 0.3457 - val_loss: 1.8570 - val_acc: 0.2133\n",
      "epochs : 203\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.6001 - acc: 0.3400 - val_loss: 1.8459 - val_acc: 0.2300\n",
      "epochs : 204\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5975 - acc: 0.3414 - val_loss: 1.8578 - val_acc: 0.2233\n",
      "epochs : 205\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5965 - acc: 0.3400 - val_loss: 1.8585 - val_acc: 0.2633\n",
      "epochs : 206\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5976 - acc: 0.3357 - val_loss: 1.8488 - val_acc: 0.2333\n",
      "epochs : 207\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5973 - acc: 0.3371 - val_loss: 1.8526 - val_acc: 0.2133\n",
      "epochs : 208\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.5959 - acc: 0.3329 - val_loss: 1.8560 - val_acc: 0.2367\n",
      "epochs : 209\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.5934 - acc: 0.3429 - val_loss: 1.8566 - val_acc: 0.2200\n",
      "epochs : 210\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5947 - acc: 0.3343 - val_loss: 1.8579 - val_acc: 0.2267\n",
      "epochs : 211\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5926 - acc: 0.3457 - val_loss: 1.8612 - val_acc: 0.2133\n",
      "epochs : 212\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.5939 - acc: 0.3371 - val_loss: 1.8460 - val_acc: 0.2233\n",
      "epochs : 213\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5935 - acc: 0.3271 - val_loss: 1.8573 - val_acc: 0.2400\n",
      "epochs : 214\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 122us/step - loss: 1.5917 - acc: 0.3414 - val_loss: 1.8478 - val_acc: 0.2633\n",
      "epochs : 215\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5915 - acc: 0.3371 - val_loss: 1.8527 - val_acc: 0.2300\n",
      "epochs : 216\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5904 - acc: 0.3286 - val_loss: 1.8542 - val_acc: 0.2333\n",
      "epochs : 217\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5904 - acc: 0.3400 - val_loss: 1.8536 - val_acc: 0.2233\n",
      "epochs : 218\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5888 - acc: 0.3429 - val_loss: 1.8541 - val_acc: 0.2233\n",
      "epochs : 219\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5890 - acc: 0.3414 - val_loss: 1.8686 - val_acc: 0.2133\n",
      "epochs : 220\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.5879 - acc: 0.3471 - val_loss: 1.8591 - val_acc: 0.2333\n",
      "epochs : 221\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5871 - acc: 0.3457 - val_loss: 1.8565 - val_acc: 0.2600\n",
      "epochs : 222\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5868 - acc: 0.3343 - val_loss: 1.8557 - val_acc: 0.2200\n",
      "epochs : 223\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5877 - acc: 0.3329 - val_loss: 1.8609 - val_acc: 0.2133\n",
      "epochs : 224\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.5869 - acc: 0.3357 - val_loss: 1.8641 - val_acc: 0.2167\n",
      "epochs : 225\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5856 - acc: 0.3414 - val_loss: 1.8587 - val_acc: 0.2233\n",
      "epochs : 226\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5856 - acc: 0.3429 - val_loss: 1.8635 - val_acc: 0.2267\n",
      "epochs : 227\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5838 - acc: 0.3386 - val_loss: 1.8601 - val_acc: 0.2167\n",
      "epochs : 228\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5841 - acc: 0.3386 - val_loss: 1.8652 - val_acc: 0.2200\n",
      "epochs : 229\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5834 - acc: 0.3500 - val_loss: 1.8874 - val_acc: 0.2267\n",
      "epochs : 230\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5837 - acc: 0.3343 - val_loss: 1.8667 - val_acc: 0.2500\n",
      "epochs : 231\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.5824 - acc: 0.3529 - val_loss: 1.8705 - val_acc: 0.2200\n",
      "epochs : 232\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.5821 - acc: 0.3400 - val_loss: 1.8717 - val_acc: 0.2200\n",
      "epochs : 233\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5807 - acc: 0.3386 - val_loss: 1.8718 - val_acc: 0.2167\n",
      "epochs : 234\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5812 - acc: 0.3300 - val_loss: 1.8747 - val_acc: 0.2333\n",
      "epochs : 235\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.5799 - acc: 0.3429 - val_loss: 1.8803 - val_acc: 0.2167\n",
      "epochs : 236\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.5792 - acc: 0.3486 - val_loss: 1.8740 - val_acc: 0.2233\n",
      "epochs : 237\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.5795 - acc: 0.3543 - val_loss: 1.8860 - val_acc: 0.2200\n",
      "epochs : 238\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.5779 - acc: 0.3586 - val_loss: 1.8621 - val_acc: 0.2267\n",
      "epochs : 239\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5790 - acc: 0.3429 - val_loss: 1.8702 - val_acc: 0.2167\n",
      "epochs : 240\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5777 - acc: 0.3414 - val_loss: 1.8764 - val_acc: 0.2367\n",
      "epochs : 241\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5772 - acc: 0.3400 - val_loss: 1.8868 - val_acc: 0.2200\n",
      "epochs : 242\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5771 - acc: 0.3314 - val_loss: 1.8770 - val_acc: 0.2633\n",
      "epochs : 243\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.5761 - acc: 0.3443 - val_loss: 1.8614 - val_acc: 0.2233\n",
      "epochs : 244\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5751 - acc: 0.3486 - val_loss: 1.8707 - val_acc: 0.2167\n",
      "epochs : 245\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5745 - acc: 0.3457 - val_loss: 1.8740 - val_acc: 0.2667\n",
      "epochs : 246\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5738 - acc: 0.3443 - val_loss: 1.8712 - val_acc: 0.2167\n",
      "epochs : 247\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.5726 - acc: 0.3586 - val_loss: 1.8840 - val_acc: 0.2133\n",
      "epochs : 248\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.5730 - acc: 0.3386 - val_loss: 1.8715 - val_acc: 0.2400\n",
      "epochs : 249\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5723 - acc: 0.3486 - val_loss: 1.8760 - val_acc: 0.2233\n",
      "epochs : 250\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5733 - acc: 0.3529 - val_loss: 1.8914 - val_acc: 0.2233\n",
      "epochs : 251\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5721 - acc: 0.3543 - val_loss: 1.8715 - val_acc: 0.2067\n",
      "epochs : 252\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5709 - acc: 0.3429 - val_loss: 1.8755 - val_acc: 0.2133\n",
      "epochs : 253\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5706 - acc: 0.3471 - val_loss: 1.8770 - val_acc: 0.2333\n",
      "epochs : 254\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5705 - acc: 0.3500 - val_loss: 1.8763 - val_acc: 0.2667\n",
      "epochs : 255\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.5706 - acc: 0.3429 - val_loss: 1.8955 - val_acc: 0.2300\n",
      "epochs : 256\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5690 - acc: 0.3514 - val_loss: 1.8846 - val_acc: 0.2567\n",
      "epochs : 257\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 125us/step - loss: 1.5702 - acc: 0.3500 - val_loss: 1.8809 - val_acc: 0.2200\n",
      "epochs : 258\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5687 - acc: 0.3557 - val_loss: 1.9035 - val_acc: 0.2200\n",
      "epochs : 259\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5684 - acc: 0.3300 - val_loss: 1.8769 - val_acc: 0.2233\n",
      "epochs : 260\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.5680 - acc: 0.3471 - val_loss: 1.8780 - val_acc: 0.2300\n",
      "epochs : 261\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.5671 - acc: 0.3457 - val_loss: 1.8842 - val_acc: 0.2267\n",
      "epochs : 262\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.5670 - acc: 0.3557 - val_loss: 1.8799 - val_acc: 0.2233\n",
      "epochs : 263\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5656 - acc: 0.3429 - val_loss: 1.8775 - val_acc: 0.2267\n",
      "epochs : 264\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.5657 - acc: 0.3500 - val_loss: 1.8852 - val_acc: 0.2200\n",
      "epochs : 265\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5655 - acc: 0.3486 - val_loss: 1.8804 - val_acc: 0.2167\n",
      "epochs : 266\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.5647 - acc: 0.3500 - val_loss: 1.8918 - val_acc: 0.2200\n",
      "epochs : 267\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5647 - acc: 0.3514 - val_loss: 1.8856 - val_acc: 0.2133\n",
      "epochs : 268\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5646 - acc: 0.3429 - val_loss: 1.8929 - val_acc: 0.2533\n",
      "epochs : 269\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.5641 - acc: 0.3586 - val_loss: 1.8987 - val_acc: 0.2167\n",
      "epochs : 270\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5628 - acc: 0.3429 - val_loss: 1.8954 - val_acc: 0.2200\n",
      "epochs : 271\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.5624 - acc: 0.3486 - val_loss: 1.8906 - val_acc: 0.2133\n",
      "epochs : 272\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.5613 - acc: 0.3657 - val_loss: 1.8884 - val_acc: 0.2133\n",
      "epochs : 273\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5611 - acc: 0.3414 - val_loss: 1.8898 - val_acc: 0.2667\n",
      "epochs : 274\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5611 - acc: 0.3514 - val_loss: 1.8897 - val_acc: 0.2067\n",
      "epochs : 275\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5594 - acc: 0.3371 - val_loss: 1.8955 - val_acc: 0.2700\n",
      "epochs : 276\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5612 - acc: 0.3557 - val_loss: 1.8933 - val_acc: 0.2300\n",
      "epochs : 277\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5593 - acc: 0.3586 - val_loss: 1.8846 - val_acc: 0.2300\n",
      "epochs : 278\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5590 - acc: 0.3600 - val_loss: 1.8945 - val_acc: 0.2167\n",
      "epochs : 279\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5591 - acc: 0.3471 - val_loss: 1.9099 - val_acc: 0.2233\n",
      "epochs : 280\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.5583 - acc: 0.3557 - val_loss: 1.9000 - val_acc: 0.2333\n",
      "epochs : 281\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5578 - acc: 0.3586 - val_loss: 1.8961 - val_acc: 0.2133\n",
      "epochs : 282\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.5586 - acc: 0.3486 - val_loss: 1.8882 - val_acc: 0.2167\n",
      "epochs : 283\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5572 - acc: 0.3529 - val_loss: 1.8987 - val_acc: 0.2167\n",
      "epochs : 284\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5567 - acc: 0.3571 - val_loss: 1.9141 - val_acc: 0.2133\n",
      "epochs : 285\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5574 - acc: 0.3486 - val_loss: 1.9035 - val_acc: 0.2100\n",
      "epochs : 286\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5550 - acc: 0.3529 - val_loss: 1.8915 - val_acc: 0.2300\n",
      "epochs : 287\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5546 - acc: 0.3686 - val_loss: 1.8909 - val_acc: 0.2200\n",
      "epochs : 288\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5543 - acc: 0.3700 - val_loss: 1.9010 - val_acc: 0.2400\n",
      "epochs : 289\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5537 - acc: 0.3557 - val_loss: 1.9066 - val_acc: 0.2267\n",
      "epochs : 290\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5523 - acc: 0.3671 - val_loss: 1.9079 - val_acc: 0.2233\n",
      "epochs : 291\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.5534 - acc: 0.3543 - val_loss: 1.8995 - val_acc: 0.2233\n",
      "epochs : 292\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.5528 - acc: 0.3500 - val_loss: 1.8877 - val_acc: 0.2100\n",
      "epochs : 293\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.5521 - acc: 0.3500 - val_loss: 1.9045 - val_acc: 0.2300\n",
      "epochs : 294\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5519 - acc: 0.3614 - val_loss: 1.9156 - val_acc: 0.2233\n",
      "epochs : 295\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5516 - acc: 0.3671 - val_loss: 1.9056 - val_acc: 0.2300\n",
      "epochs : 296\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5500 - acc: 0.3600 - val_loss: 1.8952 - val_acc: 0.2067\n",
      "epochs : 297\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5532 - acc: 0.3571 - val_loss: 1.9069 - val_acc: 0.2133\n",
      "epochs : 298\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.5511 - acc: 0.3629 - val_loss: 1.9039 - val_acc: 0.2133\n",
      "epochs : 299\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5489 - acc: 0.3586 - val_loss: 1.9124 - val_acc: 0.2100\n",
      "epochs : 300\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 123us/step - loss: 1.5493 - acc: 0.3529 - val_loss: 1.8929 - val_acc: 0.2300\n",
      "epochs : 301\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.5503 - acc: 0.3571 - val_loss: 1.8969 - val_acc: 0.2200\n",
      "epochs : 302\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5497 - acc: 0.3614 - val_loss: 1.9063 - val_acc: 0.2267\n",
      "epochs : 303\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.5485 - acc: 0.3571 - val_loss: 1.9093 - val_acc: 0.2200\n",
      "epochs : 304\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5480 - acc: 0.3586 - val_loss: 1.9059 - val_acc: 0.2167\n",
      "epochs : 305\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5483 - acc: 0.3514 - val_loss: 1.8954 - val_acc: 0.2300\n",
      "epochs : 306\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5485 - acc: 0.3657 - val_loss: 1.9110 - val_acc: 0.2267\n",
      "epochs : 307\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.5464 - acc: 0.3614 - val_loss: 1.9080 - val_acc: 0.2233\n",
      "epochs : 308\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5464 - acc: 0.3557 - val_loss: 1.9162 - val_acc: 0.2333\n",
      "epochs : 309\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5463 - acc: 0.3600 - val_loss: 1.9170 - val_acc: 0.2333\n",
      "epochs : 310\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5458 - acc: 0.3657 - val_loss: 1.9367 - val_acc: 0.2200\n",
      "epochs : 311\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.5463 - acc: 0.3543 - val_loss: 1.9210 - val_acc: 0.2333\n",
      "epochs : 312\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.5439 - acc: 0.3671 - val_loss: 1.9186 - val_acc: 0.2200\n",
      "epochs : 313\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 166us/step - loss: 1.5454 - acc: 0.3686 - val_loss: 1.9189 - val_acc: 0.2233\n",
      "epochs : 314\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.5113 - acc: 0.372 - 0s 119us/step - loss: 1.5436 - acc: 0.3586 - val_loss: 1.9038 - val_acc: 0.2133\n",
      "epochs : 315\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5440 - acc: 0.3543 - val_loss: 1.9094 - val_acc: 0.2433\n",
      "epochs : 316\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.5441 - acc: 0.3643 - val_loss: 1.9089 - val_acc: 0.2300\n",
      "epochs : 317\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.5420 - acc: 0.3700 - val_loss: 1.9221 - val_acc: 0.2267\n",
      "epochs : 318\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.5424 - acc: 0.3500 - val_loss: 1.9210 - val_acc: 0.2233\n",
      "epochs : 319\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.5418 - acc: 0.3700 - val_loss: 1.9324 - val_acc: 0.2300\n",
      "epochs : 320\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5409 - acc: 0.3643 - val_loss: 1.9164 - val_acc: 0.2100\n",
      "epochs : 321\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5408 - acc: 0.3629 - val_loss: 1.9195 - val_acc: 0.2333\n",
      "epochs : 322\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5411 - acc: 0.3529 - val_loss: 1.9067 - val_acc: 0.2167\n",
      "epochs : 323\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5408 - acc: 0.3586 - val_loss: 1.9142 - val_acc: 0.2167\n",
      "epochs : 324\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5409 - acc: 0.3571 - val_loss: 1.9263 - val_acc: 0.2200\n",
      "epochs : 325\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5397 - acc: 0.3614 - val_loss: 1.9107 - val_acc: 0.2233\n",
      "epochs : 326\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5395 - acc: 0.3600 - val_loss: 1.9155 - val_acc: 0.2200\n",
      "epochs : 327\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.5393 - acc: 0.3629 - val_loss: 1.9322 - val_acc: 0.2533\n",
      "epochs : 328\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5405 - acc: 0.3657 - val_loss: 1.9256 - val_acc: 0.2233\n",
      "epochs : 329\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5378 - acc: 0.3743 - val_loss: 1.9235 - val_acc: 0.2167\n",
      "epochs : 330\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5358 - acc: 0.3700 - val_loss: 1.9342 - val_acc: 0.2333\n",
      "epochs : 331\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5383 - acc: 0.3714 - val_loss: 1.9291 - val_acc: 0.2233\n",
      "epochs : 332\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5367 - acc: 0.3643 - val_loss: 1.9402 - val_acc: 0.2200\n",
      "epochs : 333\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5366 - acc: 0.3657 - val_loss: 1.9357 - val_acc: 0.2100\n",
      "epochs : 334\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5368 - acc: 0.3671 - val_loss: 1.9281 - val_acc: 0.2333\n",
      "epochs : 335\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5370 - acc: 0.3486 - val_loss: 1.9417 - val_acc: 0.2100\n",
      "epochs : 336\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5360 - acc: 0.3700 - val_loss: 1.9294 - val_acc: 0.2267\n",
      "epochs : 337\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5348 - acc: 0.3671 - val_loss: 1.9295 - val_acc: 0.2167\n",
      "epochs : 338\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.5341 - acc: 0.3543 - val_loss: 1.9229 - val_acc: 0.2333\n",
      "epochs : 339\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 159us/step - loss: 1.5350 - acc: 0.3714 - val_loss: 1.9337 - val_acc: 0.2200\n",
      "epochs : 340\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5322 - acc: 0.3771 - val_loss: 1.9164 - val_acc: 0.2167\n",
      "epochs : 341\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.5326 - acc: 0.3643 - val_loss: 1.9619 - val_acc: 0.2300\n",
      "epochs : 342\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 162us/step - loss: 1.5306 - acc: 0.3743 - val_loss: 1.9348 - val_acc: 0.2100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs : 343\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5350 - acc: 0.3657 - val_loss: 1.9193 - val_acc: 0.2167\n",
      "epochs : 344\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5326 - acc: 0.3657 - val_loss: 1.9491 - val_acc: 0.2167\n",
      "epochs : 345\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5326 - acc: 0.3657 - val_loss: 1.9428 - val_acc: 0.2233\n",
      "epochs : 346\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5317 - acc: 0.3671 - val_loss: 1.9409 - val_acc: 0.2100\n",
      "epochs : 347\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5315 - acc: 0.3657 - val_loss: 1.9372 - val_acc: 0.2400\n",
      "epochs : 348\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5318 - acc: 0.3671 - val_loss: 1.9238 - val_acc: 0.2133\n",
      "epochs : 349\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5301 - acc: 0.3643 - val_loss: 1.9344 - val_acc: 0.2433\n",
      "epochs : 350\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5300 - acc: 0.3643 - val_loss: 1.9524 - val_acc: 0.2233\n",
      "epochs : 351\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5309 - acc: 0.3757 - val_loss: 1.9371 - val_acc: 0.2067\n",
      "epochs : 352\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5296 - acc: 0.3729 - val_loss: 1.9549 - val_acc: 0.2133\n",
      "epochs : 353\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5296 - acc: 0.3600 - val_loss: 1.9407 - val_acc: 0.2100\n",
      "epochs : 354\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5290 - acc: 0.3671 - val_loss: 1.9408 - val_acc: 0.2133\n",
      "epochs : 355\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5282 - acc: 0.3643 - val_loss: 1.9422 - val_acc: 0.2167\n",
      "epochs : 356\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5278 - acc: 0.3671 - val_loss: 1.9400 - val_acc: 0.2267\n",
      "epochs : 357\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5279 - acc: 0.3829 - val_loss: 1.9404 - val_acc: 0.2400\n",
      "epochs : 358\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5285 - acc: 0.3600 - val_loss: 1.9374 - val_acc: 0.2300\n",
      "epochs : 359\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5264 - acc: 0.3714 - val_loss: 1.9432 - val_acc: 0.2167\n",
      "epochs : 360\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5267 - acc: 0.3700 - val_loss: 1.9432 - val_acc: 0.2200\n",
      "epochs : 361\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5251 - acc: 0.3600 - val_loss: 1.9509 - val_acc: 0.2433\n",
      "epochs : 362\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5239 - acc: 0.3643 - val_loss: 1.9453 - val_acc: 0.2600\n",
      "epochs : 363\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5268 - acc: 0.3714 - val_loss: 1.9498 - val_acc: 0.2300\n",
      "epochs : 364\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5246 - acc: 0.3686 - val_loss: 1.9425 - val_acc: 0.2200\n",
      "epochs : 365\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5238 - acc: 0.3714 - val_loss: 1.9490 - val_acc: 0.2167\n",
      "epochs : 366\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5243 - acc: 0.3671 - val_loss: 1.9474 - val_acc: 0.2267\n",
      "epochs : 367\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5234 - acc: 0.3700 - val_loss: 1.9429 - val_acc: 0.2300\n",
      "epochs : 368\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.5220 - acc: 0.3714 - val_loss: 1.9393 - val_acc: 0.2267\n",
      "epochs : 369\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.5232 - acc: 0.3614 - val_loss: 1.9493 - val_acc: 0.2300\n",
      "epochs : 370\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5220 - acc: 0.3700 - val_loss: 1.9602 - val_acc: 0.2233\n",
      "epochs : 371\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5229 - acc: 0.3686 - val_loss: 1.9560 - val_acc: 0.2200\n",
      "epochs : 372\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5215 - acc: 0.3629 - val_loss: 1.9497 - val_acc: 0.2200\n",
      "epochs : 373\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5220 - acc: 0.3600 - val_loss: 1.9566 - val_acc: 0.2400\n",
      "epochs : 374\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5211 - acc: 0.3671 - val_loss: 1.9576 - val_acc: 0.2333\n",
      "epochs : 375\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5204 - acc: 0.3686 - val_loss: 1.9586 - val_acc: 0.2200\n",
      "epochs : 376\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5209 - acc: 0.3686 - val_loss: 1.9481 - val_acc: 0.2233\n",
      "epochs : 377\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5209 - acc: 0.3629 - val_loss: 1.9476 - val_acc: 0.2267\n",
      "epochs : 378\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5201 - acc: 0.3700 - val_loss: 1.9519 - val_acc: 0.2333\n",
      "epochs : 379\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5198 - acc: 0.3629 - val_loss: 1.9496 - val_acc: 0.2400\n",
      "epochs : 380\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5181 - acc: 0.3714 - val_loss: 1.9687 - val_acc: 0.2333\n",
      "epochs : 381\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5198 - acc: 0.3729 - val_loss: 1.9578 - val_acc: 0.2233\n",
      "epochs : 382\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5178 - acc: 0.3686 - val_loss: 1.9484 - val_acc: 0.2233\n",
      "epochs : 383\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5184 - acc: 0.3786 - val_loss: 1.9481 - val_acc: 0.2267\n",
      "epochs : 384\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 1.5172 - acc: 0.3729 - val_loss: 1.9628 - val_acc: 0.2267\n",
      "epochs : 385\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 119us/step - loss: 1.5166 - acc: 0.3700 - val_loss: 1.9588 - val_acc: 0.2333\n",
      "epochs : 386\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5163 - acc: 0.3643 - val_loss: 1.9496 - val_acc: 0.2400\n",
      "epochs : 387\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5166 - acc: 0.3671 - val_loss: 1.9512 - val_acc: 0.2167\n",
      "epochs : 388\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5152 - acc: 0.3771 - val_loss: 1.9690 - val_acc: 0.2400\n",
      "epochs : 389\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5151 - acc: 0.3614 - val_loss: 1.9488 - val_acc: 0.2267\n",
      "epochs : 390\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5150 - acc: 0.3686 - val_loss: 1.9621 - val_acc: 0.2233\n",
      "epochs : 391\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5151 - acc: 0.3700 - val_loss: 1.9541 - val_acc: 0.2300\n",
      "epochs : 392\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5134 - acc: 0.3686 - val_loss: 1.9588 - val_acc: 0.2200\n",
      "epochs : 393\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5139 - acc: 0.3786 - val_loss: 1.9712 - val_acc: 0.2167\n",
      "epochs : 394\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.5134 - acc: 0.3757 - val_loss: 1.9603 - val_acc: 0.2200\n",
      "epochs : 395\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5129 - acc: 0.3671 - val_loss: 1.9577 - val_acc: 0.2233\n",
      "epochs : 396\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5123 - acc: 0.3757 - val_loss: 1.9581 - val_acc: 0.2367\n",
      "epochs : 397\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5136 - acc: 0.3786 - val_loss: 1.9635 - val_acc: 0.2233\n",
      "epochs : 398\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5106 - acc: 0.3729 - val_loss: 1.9579 - val_acc: 0.2367\n",
      "epochs : 399\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5116 - acc: 0.3871 - val_loss: 1.9460 - val_acc: 0.2367\n",
      "epochs : 400\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5119 - acc: 0.3714 - val_loss: 1.9675 - val_acc: 0.2300\n",
      "epochs : 401\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5120 - acc: 0.3800 - val_loss: 1.9775 - val_acc: 0.2133\n",
      "epochs : 402\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5119 - acc: 0.3800 - val_loss: 1.9766 - val_acc: 0.2133\n",
      "epochs : 403\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.5120 - acc: 0.3729 - val_loss: 1.9747 - val_acc: 0.2233\n",
      "epochs : 404\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 168us/step - loss: 1.5100 - acc: 0.3729 - val_loss: 1.9623 - val_acc: 0.2233\n",
      "epochs : 405\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5104 - acc: 0.3771 - val_loss: 1.9707 - val_acc: 0.2167\n",
      "epochs : 406\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5098 - acc: 0.3686 - val_loss: 1.9640 - val_acc: 0.2133\n",
      "epochs : 407\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5098 - acc: 0.3743 - val_loss: 1.9647 - val_acc: 0.2333\n",
      "epochs : 408\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.5085 - acc: 0.3757 - val_loss: 1.9752 - val_acc: 0.2400\n",
      "epochs : 409\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5089 - acc: 0.3686 - val_loss: 1.9751 - val_acc: 0.2333\n",
      "epochs : 410\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5077 - acc: 0.3800 - val_loss: 1.9688 - val_acc: 0.2433\n",
      "epochs : 411\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5090 - acc: 0.3757 - val_loss: 1.9855 - val_acc: 0.2167\n",
      "epochs : 412\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5075 - acc: 0.3729 - val_loss: 1.9728 - val_acc: 0.2200\n",
      "epochs : 413\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5061 - acc: 0.3771 - val_loss: 1.9764 - val_acc: 0.2367\n",
      "epochs : 414\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5093 - acc: 0.3814 - val_loss: 1.9599 - val_acc: 0.2233\n",
      "epochs : 415\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.5076 - acc: 0.3643 - val_loss: 1.9697 - val_acc: 0.2333\n",
      "epochs : 416\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5040 - acc: 0.3900 - val_loss: 1.9847 - val_acc: 0.2400\n",
      "epochs : 417\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.5066 - acc: 0.3771 - val_loss: 1.9744 - val_acc: 0.2267\n",
      "epochs : 418\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5064 - acc: 0.3700 - val_loss: 1.9757 - val_acc: 0.2300\n",
      "epochs : 419\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5054 - acc: 0.3743 - val_loss: 1.9987 - val_acc: 0.2467\n",
      "epochs : 420\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5068 - acc: 0.3729 - val_loss: 1.9947 - val_acc: 0.2367\n",
      "epochs : 421\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5056 - acc: 0.3700 - val_loss: 1.9733 - val_acc: 0.2167\n",
      "epochs : 422\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5034 - acc: 0.3771 - val_loss: 1.9659 - val_acc: 0.2333\n",
      "epochs : 423\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5043 - acc: 0.3786 - val_loss: 1.9849 - val_acc: 0.2267\n",
      "epochs : 424\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5030 - acc: 0.3729 - val_loss: 1.9867 - val_acc: 0.2400\n",
      "epochs : 425\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.5048 - acc: 0.3829 - val_loss: 2.0011 - val_acc: 0.2400\n",
      "epochs : 426\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.5028 - acc: 0.3771 - val_loss: 1.9818 - val_acc: 0.2333\n",
      "epochs : 427\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5022 - acc: 0.3714 - val_loss: 1.9730 - val_acc: 0.2200\n",
      "epochs : 428\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 113us/step - loss: 1.5028 - acc: 0.3829 - val_loss: 1.9773 - val_acc: 0.2367\n",
      "epochs : 429\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5019 - acc: 0.3843 - val_loss: 1.9773 - val_acc: 0.2200\n",
      "epochs : 430\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5022 - acc: 0.3886 - val_loss: 1.9803 - val_acc: 0.2233\n",
      "epochs : 431\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5029 - acc: 0.3729 - val_loss: 1.9893 - val_acc: 0.2233\n",
      "epochs : 432\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4999 - acc: 0.3800 - val_loss: 1.9751 - val_acc: 0.2333\n",
      "epochs : 433\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5018 - acc: 0.3814 - val_loss: 1.9847 - val_acc: 0.2200\n",
      "epochs : 434\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5007 - acc: 0.3729 - val_loss: 1.9872 - val_acc: 0.2167\n",
      "epochs : 435\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5012 - acc: 0.3829 - val_loss: 1.9783 - val_acc: 0.2233\n",
      "epochs : 436\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5007 - acc: 0.3771 - val_loss: 1.9849 - val_acc: 0.2233\n",
      "epochs : 437\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5001 - acc: 0.3886 - val_loss: 1.9823 - val_acc: 0.2233\n",
      "epochs : 438\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4996 - acc: 0.3814 - val_loss: 1.9774 - val_acc: 0.2367\n",
      "epochs : 439\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4998 - acc: 0.3786 - val_loss: 1.9793 - val_acc: 0.2233\n",
      "epochs : 440\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4997 - acc: 0.3814 - val_loss: 1.9801 - val_acc: 0.2300\n",
      "epochs : 441\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 160us/step - loss: 1.4996 - acc: 0.3943 - val_loss: 1.9954 - val_acc: 0.2167\n",
      "epochs : 442\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4986 - acc: 0.3757 - val_loss: 1.9794 - val_acc: 0.2367\n",
      "epochs : 443\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4982 - acc: 0.3757 - val_loss: 1.9940 - val_acc: 0.2333\n",
      "epochs : 444\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4974 - acc: 0.3714 - val_loss: 1.9820 - val_acc: 0.2233\n",
      "epochs : 445\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4983 - acc: 0.3814 - val_loss: 1.9824 - val_acc: 0.2167\n",
      "epochs : 446\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4967 - acc: 0.3729 - val_loss: 1.9970 - val_acc: 0.2433\n",
      "epochs : 447\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4975 - acc: 0.3857 - val_loss: 1.9753 - val_acc: 0.2233\n",
      "epochs : 448\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4961 - acc: 0.3814 - val_loss: 1.9970 - val_acc: 0.2333\n",
      "epochs : 449\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4965 - acc: 0.3843 - val_loss: 2.0000 - val_acc: 0.2200\n",
      "epochs : 450\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4953 - acc: 0.3700 - val_loss: 1.9830 - val_acc: 0.2267\n",
      "epochs : 451\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4947 - acc: 0.3914 - val_loss: 1.9983 - val_acc: 0.2200\n",
      "epochs : 452\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4969 - acc: 0.3829 - val_loss: 2.0159 - val_acc: 0.2367\n",
      "epochs : 453\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4963 - acc: 0.3857 - val_loss: 1.9900 - val_acc: 0.2333\n",
      "epochs : 454\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4962 - acc: 0.3886 - val_loss: 1.9965 - val_acc: 0.2333\n",
      "epochs : 455\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4958 - acc: 0.3786 - val_loss: 1.9882 - val_acc: 0.2367\n",
      "epochs : 456\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4952 - acc: 0.3857 - val_loss: 1.9802 - val_acc: 0.2233\n",
      "epochs : 457\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4958 - acc: 0.3886 - val_loss: 1.9986 - val_acc: 0.2200\n",
      "epochs : 458\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4944 - acc: 0.3871 - val_loss: 1.9899 - val_acc: 0.2200\n",
      "epochs : 459\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4942 - acc: 0.3871 - val_loss: 1.9986 - val_acc: 0.2233\n",
      "epochs : 460\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4937 - acc: 0.3800 - val_loss: 1.9964 - val_acc: 0.2267\n",
      "epochs : 461\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4927 - acc: 0.3886 - val_loss: 1.9965 - val_acc: 0.2233\n",
      "epochs : 462\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4919 - acc: 0.3857 - val_loss: 1.9922 - val_acc: 0.2400\n",
      "epochs : 463\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4932 - acc: 0.3857 - val_loss: 2.0108 - val_acc: 0.2267\n",
      "epochs : 464\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4937 - acc: 0.3886 - val_loss: 2.0123 - val_acc: 0.2367\n",
      "epochs : 465\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4926 - acc: 0.3843 - val_loss: 1.9907 - val_acc: 0.2367\n",
      "epochs : 466\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4942 - acc: 0.3829 - val_loss: 2.0031 - val_acc: 0.2300\n",
      "epochs : 467\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4927 - acc: 0.3757 - val_loss: 2.0094 - val_acc: 0.2200\n",
      "epochs : 468\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4916 - acc: 0.3857 - val_loss: 1.9890 - val_acc: 0.2200\n",
      "epochs : 469\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4928 - acc: 0.3886 - val_loss: 2.0058 - val_acc: 0.2300\n",
      "epochs : 470\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4927 - acc: 0.3843 - val_loss: 2.0088 - val_acc: 0.2267\n",
      "epochs : 471\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 115us/step - loss: 1.4904 - acc: 0.3886 - val_loss: 2.0202 - val_acc: 0.2333\n",
      "epochs : 472\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4916 - acc: 0.3800 - val_loss: 1.9987 - val_acc: 0.2233\n",
      "epochs : 473\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4886 - acc: 0.3829 - val_loss: 2.0096 - val_acc: 0.2233\n",
      "epochs : 474\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4913 - acc: 0.3814 - val_loss: 2.0070 - val_acc: 0.2267\n",
      "epochs : 475\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4876 - acc: 0.3914 - val_loss: 2.0069 - val_acc: 0.2233\n",
      "epochs : 476\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4906 - acc: 0.3843 - val_loss: 2.0181 - val_acc: 0.2333\n",
      "epochs : 477\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4895 - acc: 0.3829 - val_loss: 2.0016 - val_acc: 0.2233\n",
      "epochs : 478\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4887 - acc: 0.3886 - val_loss: 2.0232 - val_acc: 0.2300\n",
      "epochs : 479\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4889 - acc: 0.3786 - val_loss: 2.0088 - val_acc: 0.2200\n",
      "epochs : 480\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4887 - acc: 0.3900 - val_loss: 2.0066 - val_acc: 0.2233\n",
      "epochs : 481\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4885 - acc: 0.3871 - val_loss: 2.0119 - val_acc: 0.2167\n",
      "epochs : 482\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4883 - acc: 0.3886 - val_loss: 2.0073 - val_acc: 0.2333\n",
      "epochs : 483\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4878 - acc: 0.3871 - val_loss: 2.0157 - val_acc: 0.2200\n",
      "epochs : 484\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4872 - acc: 0.3914 - val_loss: 2.0150 - val_acc: 0.2233\n",
      "epochs : 485\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4867 - acc: 0.3814 - val_loss: 2.0105 - val_acc: 0.2267\n",
      "epochs : 486\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4860 - acc: 0.4000 - val_loss: 2.0128 - val_acc: 0.2367\n",
      "epochs : 487\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4879 - acc: 0.3829 - val_loss: 2.0125 - val_acc: 0.2267\n",
      "epochs : 488\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4866 - acc: 0.3900 - val_loss: 2.0168 - val_acc: 0.2300\n",
      "epochs : 489\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4870 - acc: 0.3886 - val_loss: 2.0143 - val_acc: 0.2300\n",
      "epochs : 490\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4858 - acc: 0.3929 - val_loss: 2.0155 - val_acc: 0.2300\n",
      "epochs : 491\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4851 - acc: 0.3857 - val_loss: 2.0094 - val_acc: 0.2367\n",
      "epochs : 492\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 157us/step - loss: 1.4840 - acc: 0.3900 - val_loss: 2.0149 - val_acc: 0.2333\n",
      "epochs : 493\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 153us/step - loss: 1.4863 - acc: 0.3814 - val_loss: 2.0173 - val_acc: 0.2267\n",
      "epochs : 494\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4858 - acc: 0.3814 - val_loss: 2.0224 - val_acc: 0.2233\n",
      "epochs : 495\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4846 - acc: 0.3843 - val_loss: 2.0185 - val_acc: 0.2267\n",
      "epochs : 496\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4852 - acc: 0.3929 - val_loss: 2.0052 - val_acc: 0.2267\n",
      "epochs : 497\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4841 - acc: 0.3843 - val_loss: 1.9972 - val_acc: 0.2233\n",
      "epochs : 498\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4847 - acc: 0.3929 - val_loss: 2.0184 - val_acc: 0.2267\n",
      "epochs : 499\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4835 - acc: 0.3914 - val_loss: 2.0265 - val_acc: 0.2300\n",
      "epochs : 500\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4833 - acc: 0.3857 - val_loss: 2.0234 - val_acc: 0.2333\n",
      "epochs : 501\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4845 - acc: 0.3871 - val_loss: 2.0063 - val_acc: 0.2233\n",
      "epochs : 502\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4844 - acc: 0.3829 - val_loss: 2.0128 - val_acc: 0.2333\n",
      "epochs : 503\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4837 - acc: 0.3971 - val_loss: 2.0360 - val_acc: 0.2233\n",
      "epochs : 504\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4834 - acc: 0.3843 - val_loss: 2.0257 - val_acc: 0.2233\n",
      "epochs : 505\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4834 - acc: 0.3957 - val_loss: 2.0273 - val_acc: 0.2233\n",
      "epochs : 506\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4825 - acc: 0.3786 - val_loss: 2.0345 - val_acc: 0.2267\n",
      "epochs : 507\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4824 - acc: 0.3900 - val_loss: 2.0206 - val_acc: 0.2333\n",
      "epochs : 508\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4811 - acc: 0.3957 - val_loss: 2.0197 - val_acc: 0.2200\n",
      "epochs : 509\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4807 - acc: 0.3971 - val_loss: 2.0198 - val_acc: 0.2267\n",
      "epochs : 510\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4819 - acc: 0.3957 - val_loss: 2.0344 - val_acc: 0.2167\n",
      "epochs : 511\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4822 - acc: 0.3957 - val_loss: 2.0209 - val_acc: 0.2233\n",
      "epochs : 512\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4816 - acc: 0.3914 - val_loss: 2.0293 - val_acc: 0.2333\n",
      "epochs : 513\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4786 - acc: 0.3957 - val_loss: 2.0312 - val_acc: 0.2267\n",
      "epochs : 514\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 123us/step - loss: 1.4805 - acc: 0.3900 - val_loss: 2.0211 - val_acc: 0.2400\n",
      "epochs : 515\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4797 - acc: 0.3943 - val_loss: 2.0189 - val_acc: 0.2267\n",
      "epochs : 516\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4797 - acc: 0.3871 - val_loss: 2.0291 - val_acc: 0.2300\n",
      "epochs : 517\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4797 - acc: 0.3900 - val_loss: 2.0258 - val_acc: 0.2267\n",
      "epochs : 518\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4793 - acc: 0.3929 - val_loss: 2.0335 - val_acc: 0.2233\n",
      "epochs : 519\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4779 - acc: 0.3929 - val_loss: 2.0215 - val_acc: 0.2433\n",
      "epochs : 520\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4791 - acc: 0.3957 - val_loss: 2.0354 - val_acc: 0.2433\n",
      "epochs : 521\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4790 - acc: 0.3886 - val_loss: 2.0374 - val_acc: 0.2267\n",
      "epochs : 522\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4790 - acc: 0.3929 - val_loss: 2.0231 - val_acc: 0.2233\n",
      "epochs : 523\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4793 - acc: 0.4057 - val_loss: 2.0252 - val_acc: 0.2333\n",
      "epochs : 524\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4782 - acc: 0.3843 - val_loss: 2.0455 - val_acc: 0.2233\n",
      "epochs : 525\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4776 - acc: 0.4029 - val_loss: 2.0334 - val_acc: 0.2300\n",
      "epochs : 526\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 173us/step - loss: 1.4769 - acc: 0.4000 - val_loss: 2.0406 - val_acc: 0.2300\n",
      "epochs : 527\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4767 - acc: 0.3900 - val_loss: 2.0386 - val_acc: 0.2433\n",
      "epochs : 528\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4777 - acc: 0.3943 - val_loss: 2.0325 - val_acc: 0.2300\n",
      "epochs : 529\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4763 - acc: 0.3957 - val_loss: 2.0325 - val_acc: 0.2233\n",
      "epochs : 530\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4760 - acc: 0.3871 - val_loss: 2.0237 - val_acc: 0.2300\n",
      "epochs : 531\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4762 - acc: 0.3857 - val_loss: 2.0307 - val_acc: 0.2300\n",
      "epochs : 532\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4772 - acc: 0.3900 - val_loss: 2.0250 - val_acc: 0.2300\n",
      "epochs : 533\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4759 - acc: 0.3943 - val_loss: 2.0441 - val_acc: 0.2367\n",
      "epochs : 534\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4752 - acc: 0.3943 - val_loss: 2.0450 - val_acc: 0.2267\n",
      "epochs : 535\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4750 - acc: 0.3929 - val_loss: 2.0353 - val_acc: 0.2233\n",
      "epochs : 536\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4756 - acc: 0.3871 - val_loss: 2.0367 - val_acc: 0.2267\n",
      "epochs : 537\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4749 - acc: 0.3871 - val_loss: 2.0373 - val_acc: 0.2300\n",
      "epochs : 538\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4744 - acc: 0.3929 - val_loss: 2.0251 - val_acc: 0.2333\n",
      "epochs : 539\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4745 - acc: 0.3943 - val_loss: 2.0335 - val_acc: 0.2300\n",
      "epochs : 540\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4739 - acc: 0.3986 - val_loss: 2.0425 - val_acc: 0.2433\n",
      "epochs : 541\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4731 - acc: 0.3957 - val_loss: 2.0433 - val_acc: 0.2267\n",
      "epochs : 542\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4745 - acc: 0.3886 - val_loss: 2.0437 - val_acc: 0.2267\n",
      "epochs : 543\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4726 - acc: 0.3900 - val_loss: 2.0484 - val_acc: 0.2300\n",
      "epochs : 544\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4734 - acc: 0.4000 - val_loss: 2.0392 - val_acc: 0.2267\n",
      "epochs : 545\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4729 - acc: 0.3914 - val_loss: 2.0370 - val_acc: 0.2267\n",
      "epochs : 546\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4718 - acc: 0.3986 - val_loss: 2.0376 - val_acc: 0.2267\n",
      "epochs : 547\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4734 - acc: 0.4000 - val_loss: 2.0316 - val_acc: 0.2200\n",
      "epochs : 548\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4742 - acc: 0.3943 - val_loss: 2.0328 - val_acc: 0.2300\n",
      "epochs : 549\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4728 - acc: 0.3986 - val_loss: 2.0366 - val_acc: 0.2367\n",
      "epochs : 550\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4722 - acc: 0.3929 - val_loss: 2.0453 - val_acc: 0.2267\n",
      "epochs : 551\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4714 - acc: 0.3957 - val_loss: 2.0404 - val_acc: 0.2467\n",
      "epochs : 552\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4717 - acc: 0.4029 - val_loss: 2.0475 - val_acc: 0.2267\n",
      "epochs : 553\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4694 - acc: 0.4043 - val_loss: 2.0546 - val_acc: 0.2267\n",
      "epochs : 554\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4721 - acc: 0.3900 - val_loss: 2.0364 - val_acc: 0.2267\n",
      "epochs : 555\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4715 - acc: 0.4000 - val_loss: 2.0419 - val_acc: 0.2267\n",
      "epochs : 556\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4703 - acc: 0.3943 - val_loss: 2.0453 - val_acc: 0.2433\n",
      "epochs : 557\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 124us/step - loss: 1.4690 - acc: 0.4029 - val_loss: 2.0396 - val_acc: 0.2467\n",
      "epochs : 558\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4718 - acc: 0.3943 - val_loss: 2.0493 - val_acc: 0.2333\n",
      "epochs : 559\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4691 - acc: 0.3986 - val_loss: 2.0454 - val_acc: 0.2433\n",
      "epochs : 560\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4693 - acc: 0.3986 - val_loss: 2.0570 - val_acc: 0.2333\n",
      "epochs : 561\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4693 - acc: 0.3943 - val_loss: 2.0506 - val_acc: 0.2333\n",
      "epochs : 562\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4689 - acc: 0.3957 - val_loss: 2.0446 - val_acc: 0.2267\n",
      "epochs : 563\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4699 - acc: 0.4114 - val_loss: 2.0472 - val_acc: 0.2233\n",
      "epochs : 564\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4679 - acc: 0.4000 - val_loss: 2.0489 - val_acc: 0.2400\n",
      "epochs : 565\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4677 - acc: 0.4029 - val_loss: 2.0465 - val_acc: 0.2333\n",
      "epochs : 566\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4690 - acc: 0.4043 - val_loss: 2.0482 - val_acc: 0.2300\n",
      "epochs : 567\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4684 - acc: 0.4000 - val_loss: 2.0515 - val_acc: 0.2233\n",
      "epochs : 568\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4678 - acc: 0.4029 - val_loss: 2.0577 - val_acc: 0.2400\n",
      "epochs : 569\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4669 - acc: 0.3971 - val_loss: 2.0449 - val_acc: 0.2267\n",
      "epochs : 570\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4682 - acc: 0.4029 - val_loss: 2.0495 - val_acc: 0.2267\n",
      "epochs : 571\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4669 - acc: 0.4114 - val_loss: 2.0546 - val_acc: 0.2267\n",
      "epochs : 572\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4673 - acc: 0.3971 - val_loss: 2.0454 - val_acc: 0.2267\n",
      "epochs : 573\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4653 - acc: 0.4071 - val_loss: 2.0523 - val_acc: 0.2333\n",
      "epochs : 574\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4668 - acc: 0.4029 - val_loss: 2.0492 - val_acc: 0.2233\n",
      "epochs : 575\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4676 - acc: 0.3971 - val_loss: 2.0521 - val_acc: 0.2233\n",
      "epochs : 576\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4657 - acc: 0.4057 - val_loss: 2.0570 - val_acc: 0.2267\n",
      "epochs : 577\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4672 - acc: 0.4057 - val_loss: 2.0426 - val_acc: 0.2233\n",
      "epochs : 578\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4654 - acc: 0.4071 - val_loss: 2.0569 - val_acc: 0.2267\n",
      "epochs : 579\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4654 - acc: 0.3986 - val_loss: 2.0470 - val_acc: 0.2267\n",
      "epochs : 580\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4651 - acc: 0.3957 - val_loss: 2.0564 - val_acc: 0.2333\n",
      "epochs : 581\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4657 - acc: 0.3957 - val_loss: 2.0469 - val_acc: 0.2433\n",
      "epochs : 582\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4652 - acc: 0.4014 - val_loss: 2.0518 - val_acc: 0.2400\n",
      "epochs : 583\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4646 - acc: 0.3914 - val_loss: 2.0525 - val_acc: 0.2400\n",
      "epochs : 584\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4647 - acc: 0.3986 - val_loss: 2.0532 - val_acc: 0.2300\n",
      "epochs : 585\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4642 - acc: 0.4000 - val_loss: 2.0509 - val_acc: 0.2267\n",
      "epochs : 586\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4630 - acc: 0.4029 - val_loss: 2.0496 - val_acc: 0.2200\n",
      "epochs : 587\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4629 - acc: 0.4014 - val_loss: 2.0719 - val_acc: 0.2500\n",
      "epochs : 588\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4635 - acc: 0.3957 - val_loss: 2.0492 - val_acc: 0.2500\n",
      "epochs : 589\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4647 - acc: 0.3971 - val_loss: 2.0569 - val_acc: 0.2233\n",
      "epochs : 590\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4627 - acc: 0.4029 - val_loss: 2.0669 - val_acc: 0.2233\n",
      "epochs : 591\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4632 - acc: 0.4029 - val_loss: 2.0534 - val_acc: 0.2333\n",
      "epochs : 592\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4633 - acc: 0.3971 - val_loss: 2.0564 - val_acc: 0.2300\n",
      "epochs : 593\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4629 - acc: 0.4071 - val_loss: 2.0699 - val_acc: 0.2333\n",
      "epochs : 594\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4627 - acc: 0.4000 - val_loss: 2.0491 - val_acc: 0.2467\n",
      "epochs : 595\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4625 - acc: 0.4014 - val_loss: 2.0528 - val_acc: 0.2300\n",
      "epochs : 596\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4629 - acc: 0.4071 - val_loss: 2.0543 - val_acc: 0.2233\n",
      "epochs : 597\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4628 - acc: 0.4029 - val_loss: 2.0620 - val_acc: 0.2267\n",
      "epochs : 598\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4625 - acc: 0.4043 - val_loss: 2.0534 - val_acc: 0.2267\n",
      "epochs : 599\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4617 - acc: 0.4071 - val_loss: 2.0623 - val_acc: 0.2500\n",
      "epochs : 600\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 121us/step - loss: 1.4612 - acc: 0.4129 - val_loss: 2.0641 - val_acc: 0.2500\n",
      "epochs : 601\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4617 - acc: 0.4000 - val_loss: 2.0627 - val_acc: 0.2367\n",
      "epochs : 602\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4616 - acc: 0.4029 - val_loss: 2.0696 - val_acc: 0.2367\n",
      "epochs : 603\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4610 - acc: 0.3986 - val_loss: 2.0725 - val_acc: 0.2400\n",
      "epochs : 604\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4616 - acc: 0.4086 - val_loss: 2.0750 - val_acc: 0.2267\n",
      "epochs : 605\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4600 - acc: 0.4071 - val_loss: 2.0700 - val_acc: 0.2333\n",
      "epochs : 606\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4598 - acc: 0.3971 - val_loss: 2.0567 - val_acc: 0.2233\n",
      "epochs : 607\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4586 - acc: 0.4043 - val_loss: 2.0629 - val_acc: 0.2533\n",
      "epochs : 608\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4614 - acc: 0.4057 - val_loss: 2.0634 - val_acc: 0.2300\n",
      "epochs : 609\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4597 - acc: 0.4043 - val_loss: 2.0683 - val_acc: 0.2333\n",
      "epochs : 610\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4576 - acc: 0.4157 - val_loss: 2.0570 - val_acc: 0.2500\n",
      "epochs : 611\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4594 - acc: 0.4000 - val_loss: 2.0613 - val_acc: 0.2300\n",
      "epochs : 612\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4574 - acc: 0.4100 - val_loss: 2.0636 - val_acc: 0.2500\n",
      "epochs : 613\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4585 - acc: 0.4014 - val_loss: 2.0598 - val_acc: 0.2300\n",
      "epochs : 614\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4582 - acc: 0.3957 - val_loss: 2.0666 - val_acc: 0.2500\n",
      "epochs : 615\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4594 - acc: 0.3957 - val_loss: 2.0593 - val_acc: 0.2300\n",
      "epochs : 616\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4581 - acc: 0.4043 - val_loss: 2.0662 - val_acc: 0.2267\n",
      "epochs : 617\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4574 - acc: 0.4014 - val_loss: 2.0731 - val_acc: 0.2367\n",
      "epochs : 618\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4574 - acc: 0.4129 - val_loss: 2.0631 - val_acc: 0.2267\n",
      "epochs : 619\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4589 - acc: 0.3986 - val_loss: 2.0577 - val_acc: 0.2300\n",
      "epochs : 620\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4575 - acc: 0.4100 - val_loss: 2.0652 - val_acc: 0.2267\n",
      "epochs : 621\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4535 - acc: 0.4086 - val_loss: 2.0668 - val_acc: 0.2500\n",
      "epochs : 622\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4564 - acc: 0.4114 - val_loss: 2.0649 - val_acc: 0.2533\n",
      "epochs : 623\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4583 - acc: 0.4043 - val_loss: 2.0612 - val_acc: 0.2300\n",
      "epochs : 624\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4573 - acc: 0.4057 - val_loss: 2.0694 - val_acc: 0.2367\n",
      "epochs : 625\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4568 - acc: 0.4029 - val_loss: 2.0660 - val_acc: 0.2367\n",
      "epochs : 626\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4557 - acc: 0.4086 - val_loss: 2.0805 - val_acc: 0.2233\n",
      "epochs : 627\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4552 - acc: 0.4029 - val_loss: 2.0823 - val_acc: 0.2333\n",
      "epochs : 628\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4539 - acc: 0.4071 - val_loss: 2.0728 - val_acc: 0.2300\n",
      "epochs : 629\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4557 - acc: 0.4057 - val_loss: 2.0580 - val_acc: 0.2267\n",
      "epochs : 630\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4548 - acc: 0.4057 - val_loss: 2.0614 - val_acc: 0.2300\n",
      "epochs : 631\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4548 - acc: 0.4114 - val_loss: 2.0636 - val_acc: 0.2367\n",
      "epochs : 632\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4549 - acc: 0.3971 - val_loss: 2.0689 - val_acc: 0.2533\n",
      "epochs : 633\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4550 - acc: 0.4057 - val_loss: 2.0720 - val_acc: 0.2300\n",
      "epochs : 634\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.4543 - acc: 0.4157 - val_loss: 2.0661 - val_acc: 0.2267\n",
      "epochs : 635\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4556 - acc: 0.4071 - val_loss: 2.0946 - val_acc: 0.2333\n",
      "epochs : 636\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4544 - acc: 0.4129 - val_loss: 2.0725 - val_acc: 0.2500\n",
      "epochs : 637\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4544 - acc: 0.4029 - val_loss: 2.0806 - val_acc: 0.2267\n",
      "epochs : 638\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4524 - acc: 0.4157 - val_loss: 2.0722 - val_acc: 0.2567\n",
      "epochs : 639\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4547 - acc: 0.4114 - val_loss: 2.0762 - val_acc: 0.2300\n",
      "epochs : 640\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4534 - acc: 0.4057 - val_loss: 2.0754 - val_acc: 0.2533\n",
      "epochs : 641\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4539 - acc: 0.4057 - val_loss: 2.0758 - val_acc: 0.2267\n",
      "epochs : 642\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4527 - acc: 0.4086 - val_loss: 2.0801 - val_acc: 0.2333\n",
      "epochs : 643\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 116us/step - loss: 1.4537 - acc: 0.4114 - val_loss: 2.0840 - val_acc: 0.2267\n",
      "epochs : 644\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4529 - acc: 0.4029 - val_loss: 2.0699 - val_acc: 0.2267\n",
      "epochs : 645\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4520 - acc: 0.4100 - val_loss: 2.0927 - val_acc: 0.2467\n",
      "epochs : 646\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4530 - acc: 0.4057 - val_loss: 2.0715 - val_acc: 0.2300\n",
      "epochs : 647\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4524 - acc: 0.4086 - val_loss: 2.0693 - val_acc: 0.2267\n",
      "epochs : 648\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4524 - acc: 0.4043 - val_loss: 2.0792 - val_acc: 0.2300\n",
      "epochs : 649\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4520 - acc: 0.4086 - val_loss: 2.0724 - val_acc: 0.2267\n",
      "epochs : 650\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4517 - acc: 0.4071 - val_loss: 2.0724 - val_acc: 0.2267\n",
      "epochs : 651\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4521 - acc: 0.4100 - val_loss: 2.0774 - val_acc: 0.2333\n",
      "epochs : 652\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4519 - acc: 0.4029 - val_loss: 2.0866 - val_acc: 0.2267\n",
      "epochs : 653\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4506 - acc: 0.4100 - val_loss: 2.0805 - val_acc: 0.2267\n",
      "epochs : 654\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4506 - acc: 0.4129 - val_loss: 2.0805 - val_acc: 0.2300\n",
      "epochs : 655\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4505 - acc: 0.4143 - val_loss: 2.0745 - val_acc: 0.2333\n",
      "epochs : 656\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4506 - acc: 0.4071 - val_loss: 2.0724 - val_acc: 0.2267\n",
      "epochs : 657\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.4497 - acc: 0.4129 - val_loss: 2.0732 - val_acc: 0.2533\n",
      "epochs : 658\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4494 - acc: 0.4129 - val_loss: 2.0800 - val_acc: 0.2500\n",
      "epochs : 659\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4476 - acc: 0.4071 - val_loss: 2.0929 - val_acc: 0.2367\n",
      "epochs : 660\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4490 - acc: 0.4143 - val_loss: 2.0749 - val_acc: 0.2433\n",
      "epochs : 661\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4503 - acc: 0.4143 - val_loss: 2.0868 - val_acc: 0.2300\n",
      "epochs : 662\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4496 - acc: 0.4043 - val_loss: 2.0778 - val_acc: 0.2233\n",
      "epochs : 663\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4487 - acc: 0.4086 - val_loss: 2.0946 - val_acc: 0.2333\n",
      "epochs : 664\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4489 - acc: 0.4100 - val_loss: 2.0826 - val_acc: 0.2233\n",
      "epochs : 665\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4483 - acc: 0.4043 - val_loss: 2.0908 - val_acc: 0.2300\n",
      "epochs : 666\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4487 - acc: 0.4100 - val_loss: 2.0887 - val_acc: 0.2233\n",
      "epochs : 667\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4479 - acc: 0.4086 - val_loss: 2.0807 - val_acc: 0.2333\n",
      "epochs : 668\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4489 - acc: 0.4043 - val_loss: 2.0908 - val_acc: 0.2267\n",
      "epochs : 669\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4483 - acc: 0.4143 - val_loss: 2.0851 - val_acc: 0.2200\n",
      "epochs : 670\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4471 - acc: 0.4057 - val_loss: 2.0714 - val_acc: 0.2500\n",
      "epochs : 671\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4473 - acc: 0.4157 - val_loss: 2.0885 - val_acc: 0.2333\n",
      "epochs : 672\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4478 - acc: 0.4157 - val_loss: 2.0965 - val_acc: 0.2467\n",
      "epochs : 673\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4473 - acc: 0.4086 - val_loss: 2.0954 - val_acc: 0.2300\n",
      "epochs : 674\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4471 - acc: 0.4100 - val_loss: 2.0922 - val_acc: 0.2300\n",
      "epochs : 675\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4473 - acc: 0.4014 - val_loss: 2.0863 - val_acc: 0.2267\n",
      "epochs : 676\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4470 - acc: 0.4229 - val_loss: 2.0900 - val_acc: 0.2233\n",
      "epochs : 677\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4463 - acc: 0.4100 - val_loss: 2.0915 - val_acc: 0.2267\n",
      "epochs : 678\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4472 - acc: 0.4114 - val_loss: 2.1027 - val_acc: 0.2233\n",
      "epochs : 679\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4449 - acc: 0.4057 - val_loss: 2.1086 - val_acc: 0.2333\n",
      "epochs : 680\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 208us/step - loss: 1.4468 - acc: 0.4071 - val_loss: 2.0904 - val_acc: 0.2200\n",
      "epochs : 681\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4463 - acc: 0.4057 - val_loss: 2.0912 - val_acc: 0.2267\n",
      "epochs : 682\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4457 - acc: 0.4071 - val_loss: 2.0846 - val_acc: 0.2267\n",
      "epochs : 683\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4456 - acc: 0.4129 - val_loss: 2.0908 - val_acc: 0.2267\n",
      "epochs : 684\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4453 - acc: 0.4100 - val_loss: 2.0912 - val_acc: 0.2333\n",
      "epochs : 685\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4455 - acc: 0.4143 - val_loss: 2.0888 - val_acc: 0.2267\n",
      "epochs : 686\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 124us/step - loss: 1.4457 - acc: 0.4100 - val_loss: 2.0905 - val_acc: 0.2267\n",
      "epochs : 687\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4459 - acc: 0.4114 - val_loss: 2.0947 - val_acc: 0.2233\n",
      "epochs : 688\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4450 - acc: 0.4229 - val_loss: 2.0860 - val_acc: 0.2333\n",
      "epochs : 689\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4441 - acc: 0.4143 - val_loss: 2.0907 - val_acc: 0.2533\n",
      "epochs : 690\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4450 - acc: 0.4157 - val_loss: 2.0907 - val_acc: 0.2333\n",
      "epochs : 691\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4445 - acc: 0.4129 - val_loss: 2.0919 - val_acc: 0.2233\n",
      "epochs : 692\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4430 - acc: 0.4200 - val_loss: 2.1096 - val_acc: 0.2300\n",
      "epochs : 693\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4436 - acc: 0.4071 - val_loss: 2.1080 - val_acc: 0.2233\n",
      "epochs : 694\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4416 - acc: 0.4171 - val_loss: 2.1123 - val_acc: 0.2567\n",
      "epochs : 695\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4436 - acc: 0.4114 - val_loss: 2.0983 - val_acc: 0.2333\n",
      "epochs : 696\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4444 - acc: 0.4086 - val_loss: 2.1026 - val_acc: 0.2300\n",
      "epochs : 697\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4426 - acc: 0.4171 - val_loss: 2.1034 - val_acc: 0.2500\n",
      "epochs : 698\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4432 - acc: 0.4157 - val_loss: 2.1048 - val_acc: 0.2333\n",
      "epochs : 699\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4436 - acc: 0.4129 - val_loss: 2.0963 - val_acc: 0.2300\n",
      "epochs : 700\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4423 - acc: 0.4129 - val_loss: 2.1023 - val_acc: 0.2300\n",
      "epochs : 701\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4423 - acc: 0.4171 - val_loss: 2.1053 - val_acc: 0.2300\n",
      "epochs : 702\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4419 - acc: 0.4171 - val_loss: 2.0953 - val_acc: 0.2333\n",
      "epochs : 703\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4419 - acc: 0.4171 - val_loss: 2.1082 - val_acc: 0.2233\n",
      "epochs : 704\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4422 - acc: 0.4086 - val_loss: 2.1194 - val_acc: 0.2300\n",
      "epochs : 705\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4422 - acc: 0.4100 - val_loss: 2.1030 - val_acc: 0.2267\n",
      "epochs : 706\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4395 - acc: 0.4143 - val_loss: 2.0948 - val_acc: 0.2567\n",
      "epochs : 707\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 162us/step - loss: 1.4422 - acc: 0.4243 - val_loss: 2.0937 - val_acc: 0.2300\n",
      "epochs : 708\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4422 - acc: 0.4129 - val_loss: 2.0986 - val_acc: 0.2200\n",
      "epochs : 709\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4414 - acc: 0.4114 - val_loss: 2.1068 - val_acc: 0.2333\n",
      "epochs : 710\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4392 - acc: 0.4143 - val_loss: 2.1030 - val_acc: 0.2300\n",
      "epochs : 711\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4408 - acc: 0.4086 - val_loss: 2.1086 - val_acc: 0.2233\n",
      "epochs : 712\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4405 - acc: 0.4157 - val_loss: 2.1007 - val_acc: 0.2333\n",
      "epochs : 713\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4405 - acc: 0.4129 - val_loss: 2.1093 - val_acc: 0.2367\n",
      "epochs : 714\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4397 - acc: 0.4086 - val_loss: 2.0918 - val_acc: 0.2300\n",
      "epochs : 715\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4408 - acc: 0.4057 - val_loss: 2.1097 - val_acc: 0.2233\n",
      "epochs : 716\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4393 - acc: 0.4129 - val_loss: 2.0921 - val_acc: 0.2267\n",
      "epochs : 717\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4393 - acc: 0.4200 - val_loss: 2.1134 - val_acc: 0.2333\n",
      "epochs : 718\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4396 - acc: 0.4157 - val_loss: 2.1081 - val_acc: 0.2333\n",
      "epochs : 719\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4380 - acc: 0.4186 - val_loss: 2.1194 - val_acc: 0.2233\n",
      "epochs : 720\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4374 - acc: 0.4114 - val_loss: 2.1076 - val_acc: 0.2533\n",
      "epochs : 721\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4394 - acc: 0.4071 - val_loss: 2.1194 - val_acc: 0.2333\n",
      "epochs : 722\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4387 - acc: 0.4214 - val_loss: 2.1073 - val_acc: 0.2367\n",
      "epochs : 723\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4377 - acc: 0.4157 - val_loss: 2.1056 - val_acc: 0.2500\n",
      "epochs : 724\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4378 - acc: 0.4157 - val_loss: 2.1140 - val_acc: 0.2533\n",
      "epochs : 725\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4397 - acc: 0.4171 - val_loss: 2.1047 - val_acc: 0.2267\n",
      "epochs : 726\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4382 - acc: 0.4129 - val_loss: 2.0949 - val_acc: 0.2300\n",
      "epochs : 727\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4378 - acc: 0.4200 - val_loss: 2.1135 - val_acc: 0.2333\n",
      "epochs : 728\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4380 - acc: 0.4143 - val_loss: 2.1135 - val_acc: 0.2333\n",
      "epochs : 729\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 127us/step - loss: 1.4378 - acc: 0.4186 - val_loss: 2.1160 - val_acc: 0.2367\n",
      "epochs : 730\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4374 - acc: 0.4214 - val_loss: 2.1024 - val_acc: 0.2333\n",
      "epochs : 731\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4377 - acc: 0.4114 - val_loss: 2.1111 - val_acc: 0.2300\n",
      "epochs : 732\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4366 - acc: 0.4200 - val_loss: 2.1013 - val_acc: 0.2300\n",
      "epochs : 733\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4354 - acc: 0.4129 - val_loss: 2.1120 - val_acc: 0.2300\n",
      "epochs : 734\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4368 - acc: 0.4200 - val_loss: 2.1090 - val_acc: 0.2500\n",
      "epochs : 735\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4377 - acc: 0.4171 - val_loss: 2.1120 - val_acc: 0.2300\n",
      "epochs : 736\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4369 - acc: 0.4186 - val_loss: 2.1130 - val_acc: 0.2333\n",
      "epochs : 737\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4338 - acc: 0.4114 - val_loss: 2.1207 - val_acc: 0.2567\n",
      "epochs : 738\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4375 - acc: 0.4071 - val_loss: 2.1197 - val_acc: 0.2333\n",
      "epochs : 739\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4356 - acc: 0.4157 - val_loss: 2.1092 - val_acc: 0.2267\n",
      "epochs : 740\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4356 - acc: 0.4243 - val_loss: 2.1229 - val_acc: 0.2333\n",
      "epochs : 741\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4357 - acc: 0.4129 - val_loss: 2.1230 - val_acc: 0.2300\n",
      "epochs : 742\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4353 - acc: 0.4214 - val_loss: 2.1256 - val_acc: 0.2467\n",
      "epochs : 743\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4345 - acc: 0.4186 - val_loss: 2.1059 - val_acc: 0.2533\n",
      "epochs : 744\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4351 - acc: 0.4143 - val_loss: 2.1208 - val_acc: 0.2333\n",
      "epochs : 745\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4351 - acc: 0.4200 - val_loss: 2.1090 - val_acc: 0.2300\n",
      "epochs : 746\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 177us/step - loss: 1.4327 - acc: 0.4171 - val_loss: 2.1110 - val_acc: 0.2267\n",
      "epochs : 747\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4349 - acc: 0.4100 - val_loss: 2.1127 - val_acc: 0.2300\n",
      "epochs : 748\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4335 - acc: 0.4143 - val_loss: 2.1234 - val_acc: 0.2300\n",
      "epochs : 749\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4333 - acc: 0.4100 - val_loss: 2.1244 - val_acc: 0.2367\n",
      "epochs : 750\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4348 - acc: 0.4129 - val_loss: 2.1064 - val_acc: 0.2300\n",
      "epochs : 751\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4349 - acc: 0.4129 - val_loss: 2.1099 - val_acc: 0.2267\n",
      "epochs : 752\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4344 - acc: 0.4200 - val_loss: 2.1329 - val_acc: 0.2300\n",
      "epochs : 753\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4330 - acc: 0.4200 - val_loss: 2.1152 - val_acc: 0.2567\n",
      "epochs : 754\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4336 - acc: 0.4100 - val_loss: 2.1072 - val_acc: 0.2300\n",
      "epochs : 755\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4319 - acc: 0.4171 - val_loss: 2.1131 - val_acc: 0.2333\n",
      "epochs : 756\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4345 - acc: 0.4200 - val_loss: 2.1226 - val_acc: 0.2300\n",
      "epochs : 757\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4323 - acc: 0.4157 - val_loss: 2.1077 - val_acc: 0.2267\n",
      "epochs : 758\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4328 - acc: 0.4171 - val_loss: 2.1310 - val_acc: 0.2333\n",
      "epochs : 759\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4322 - acc: 0.4200 - val_loss: 2.1311 - val_acc: 0.2300\n",
      "epochs : 760\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4329 - acc: 0.4171 - val_loss: 2.1154 - val_acc: 0.2300\n",
      "epochs : 761\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4320 - acc: 0.4186 - val_loss: 2.1209 - val_acc: 0.2533\n",
      "epochs : 762\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4303 - acc: 0.4200 - val_loss: 2.1224 - val_acc: 0.2533\n",
      "epochs : 763\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4313 - acc: 0.4086 - val_loss: 2.1211 - val_acc: 0.2333\n",
      "epochs : 764\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4313 - acc: 0.4171 - val_loss: 2.1107 - val_acc: 0.2300\n",
      "epochs : 765\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4309 - acc: 0.4243 - val_loss: 2.1417 - val_acc: 0.2333\n",
      "epochs : 766\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4312 - acc: 0.4257 - val_loss: 2.1235 - val_acc: 0.2300\n",
      "epochs : 767\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4303 - acc: 0.4200 - val_loss: 2.1282 - val_acc: 0.2367\n",
      "epochs : 768\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4313 - acc: 0.4143 - val_loss: 2.1186 - val_acc: 0.2300\n",
      "epochs : 769\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4313 - acc: 0.4157 - val_loss: 2.1311 - val_acc: 0.2300\n",
      "epochs : 770\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4314 - acc: 0.4171 - val_loss: 2.1344 - val_acc: 0.2333\n",
      "epochs : 771\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4307 - acc: 0.4171 - val_loss: 2.1235 - val_acc: 0.2300\n",
      "epochs : 772\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 122us/step - loss: 1.4306 - acc: 0.4200 - val_loss: 2.1237 - val_acc: 0.2333\n",
      "epochs : 773\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4308 - acc: 0.4143 - val_loss: 2.1260 - val_acc: 0.2300\n",
      "epochs : 774\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4308 - acc: 0.4243 - val_loss: 2.1164 - val_acc: 0.2433\n",
      "epochs : 775\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4300 - acc: 0.4157 - val_loss: 2.1226 - val_acc: 0.2333\n",
      "epochs : 776\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4301 - acc: 0.4229 - val_loss: 2.1150 - val_acc: 0.2267\n",
      "epochs : 777\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4290 - acc: 0.4214 - val_loss: 2.1275 - val_acc: 0.2333\n",
      "epochs : 778\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4294 - acc: 0.4214 - val_loss: 2.1308 - val_acc: 0.2300\n",
      "epochs : 779\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4298 - acc: 0.4114 - val_loss: 2.1264 - val_acc: 0.2400\n",
      "epochs : 780\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4290 - acc: 0.4157 - val_loss: 2.1270 - val_acc: 0.2433\n",
      "epochs : 781\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4283 - acc: 0.4200 - val_loss: 2.1290 - val_acc: 0.2333\n",
      "epochs : 782\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4291 - acc: 0.4200 - val_loss: 2.1181 - val_acc: 0.2333\n",
      "epochs : 783\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4287 - acc: 0.4171 - val_loss: 2.1290 - val_acc: 0.2300\n",
      "epochs : 784\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4286 - acc: 0.4214 - val_loss: 2.1303 - val_acc: 0.2333\n",
      "epochs : 785\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4281 - acc: 0.4157 - val_loss: 2.1287 - val_acc: 0.2333\n",
      "epochs : 786\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4281 - acc: 0.4214 - val_loss: 2.1365 - val_acc: 0.2333\n",
      "epochs : 787\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4285 - acc: 0.4243 - val_loss: 2.1254 - val_acc: 0.2333\n",
      "epochs : 788\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4277 - acc: 0.4257 - val_loss: 2.1352 - val_acc: 0.2333\n",
      "epochs : 789\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4279 - acc: 0.4186 - val_loss: 2.1434 - val_acc: 0.2533\n",
      "epochs : 790\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4269 - acc: 0.4186 - val_loss: 2.1211 - val_acc: 0.2367\n",
      "epochs : 791\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4272 - acc: 0.4229 - val_loss: 2.1359 - val_acc: 0.2333\n",
      "epochs : 792\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4271 - acc: 0.4157 - val_loss: 2.1212 - val_acc: 0.2300\n",
      "epochs : 793\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4275 - acc: 0.4143 - val_loss: 2.1309 - val_acc: 0.2333\n",
      "epochs : 794\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4267 - acc: 0.4271 - val_loss: 2.1377 - val_acc: 0.2367\n",
      "epochs : 795\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4264 - acc: 0.4229 - val_loss: 2.1293 - val_acc: 0.2300\n",
      "epochs : 796\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4270 - acc: 0.4186 - val_loss: 2.1272 - val_acc: 0.2300\n",
      "epochs : 797\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4262 - acc: 0.4186 - val_loss: 2.1321 - val_acc: 0.2300\n",
      "epochs : 798\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4257 - acc: 0.4257 - val_loss: 2.1352 - val_acc: 0.2400\n",
      "epochs : 799\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4266 - acc: 0.4157 - val_loss: 2.1436 - val_acc: 0.2433\n",
      "epochs : 800\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4264 - acc: 0.4243 - val_loss: 2.1243 - val_acc: 0.2333\n",
      "epochs : 801\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4249 - acc: 0.4257 - val_loss: 2.1413 - val_acc: 0.2300\n",
      "epochs : 802\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4253 - acc: 0.4200 - val_loss: 2.1398 - val_acc: 0.2333\n",
      "epochs : 803\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4249 - acc: 0.4200 - val_loss: 2.1714 - val_acc: 0.2367\n",
      "epochs : 804\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4269 - acc: 0.4257 - val_loss: 2.1501 - val_acc: 0.2333\n",
      "epochs : 805\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4255 - acc: 0.4229 - val_loss: 2.1322 - val_acc: 0.2367\n",
      "epochs : 806\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4243 - acc: 0.4171 - val_loss: 2.1234 - val_acc: 0.2367\n",
      "epochs : 807\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4256 - acc: 0.4200 - val_loss: 2.1347 - val_acc: 0.2367\n",
      "epochs : 808\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4253 - acc: 0.4300 - val_loss: 2.1308 - val_acc: 0.2433\n",
      "epochs : 809\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4257 - acc: 0.4171 - val_loss: 2.1355 - val_acc: 0.2300\n",
      "epochs : 810\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4249 - acc: 0.4157 - val_loss: 2.1443 - val_acc: 0.2300\n",
      "epochs : 811\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4251 - acc: 0.4171 - val_loss: 2.1358 - val_acc: 0.2367\n",
      "epochs : 812\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4244 - acc: 0.4229 - val_loss: 2.1425 - val_acc: 0.2367\n",
      "epochs : 813\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4218 - acc: 0.4300 - val_loss: 2.1375 - val_acc: 0.2533\n",
      "epochs : 814\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4230 - acc: 0.4157 - val_loss: 2.1561 - val_acc: 0.2333\n",
      "epochs : 815\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 123us/step - loss: 1.4238 - acc: 0.4186 - val_loss: 2.1400 - val_acc: 0.2300\n",
      "epochs : 816\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4240 - acc: 0.4186 - val_loss: 2.1408 - val_acc: 0.2433\n",
      "epochs : 817\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4239 - acc: 0.4314 - val_loss: 2.1338 - val_acc: 0.2367\n",
      "epochs : 818\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4239 - acc: 0.4214 - val_loss: 2.1343 - val_acc: 0.2300\n",
      "epochs : 819\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4234 - acc: 0.4229 - val_loss: 2.1326 - val_acc: 0.2300\n",
      "epochs : 820\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4231 - acc: 0.4214 - val_loss: 2.1399 - val_acc: 0.2367\n",
      "epochs : 821\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4220 - acc: 0.4329 - val_loss: 2.1535 - val_acc: 0.2367\n",
      "epochs : 822\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4230 - acc: 0.4171 - val_loss: 2.1333 - val_acc: 0.2333\n",
      "epochs : 823\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4213 - acc: 0.4329 - val_loss: 2.1427 - val_acc: 0.2367\n",
      "epochs : 824\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4226 - acc: 0.4214 - val_loss: 2.1368 - val_acc: 0.2367\n",
      "epochs : 825\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4222 - acc: 0.4271 - val_loss: 2.1362 - val_acc: 0.2300\n",
      "epochs : 826\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4214 - acc: 0.4229 - val_loss: 2.1508 - val_acc: 0.2367\n",
      "epochs : 827\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4214 - acc: 0.4286 - val_loss: 2.1493 - val_acc: 0.2367\n",
      "epochs : 828\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4215 - acc: 0.4286 - val_loss: 2.1383 - val_acc: 0.2333\n",
      "epochs : 829\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4204 - acc: 0.4186 - val_loss: 2.1387 - val_acc: 0.2267\n",
      "epochs : 830\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4203 - acc: 0.4214 - val_loss: 2.1467 - val_acc: 0.2300\n",
      "epochs : 831\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4199 - acc: 0.4286 - val_loss: 2.1365 - val_acc: 0.2367\n",
      "epochs : 832\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4206 - acc: 0.4229 - val_loss: 2.1372 - val_acc: 0.2333\n",
      "epochs : 833\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4211 - acc: 0.4243 - val_loss: 2.1599 - val_acc: 0.2333\n",
      "epochs : 834\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4202 - acc: 0.4271 - val_loss: 2.1465 - val_acc: 0.2333\n",
      "epochs : 835\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4187 - acc: 0.4200 - val_loss: 2.1477 - val_acc: 0.2333\n",
      "epochs : 836\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4205 - acc: 0.4271 - val_loss: 2.1555 - val_acc: 0.2400\n",
      "epochs : 837\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4204 - acc: 0.4200 - val_loss: 2.1448 - val_acc: 0.2367\n",
      "epochs : 838\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4201 - acc: 0.4271 - val_loss: 2.1506 - val_acc: 0.2367\n",
      "epochs : 839\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4179 - acc: 0.4243 - val_loss: 2.1614 - val_acc: 0.2467\n",
      "epochs : 840\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4190 - acc: 0.4271 - val_loss: 2.1442 - val_acc: 0.2400\n",
      "epochs : 841\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4194 - acc: 0.4243 - val_loss: 2.1490 - val_acc: 0.2367\n",
      "epochs : 842\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4179 - acc: 0.4229 - val_loss: 2.1655 - val_acc: 0.2367\n",
      "epochs : 843\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4186 - acc: 0.4286 - val_loss: 2.1553 - val_acc: 0.2333\n",
      "epochs : 844\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4182 - acc: 0.4271 - val_loss: 2.1777 - val_acc: 0.2367\n",
      "epochs : 845\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4198 - acc: 0.4200 - val_loss: 2.1513 - val_acc: 0.2367\n",
      "epochs : 846\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4186 - acc: 0.4257 - val_loss: 2.1484 - val_acc: 0.2333\n",
      "epochs : 847\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4193 - acc: 0.4229 - val_loss: 2.1500 - val_acc: 0.2367\n",
      "epochs : 848\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4169 - acc: 0.4214 - val_loss: 2.1343 - val_acc: 0.2433\n",
      "epochs : 849\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4192 - acc: 0.4229 - val_loss: 2.1525 - val_acc: 0.2400\n",
      "epochs : 850\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4143 - acc: 0.4286 - val_loss: 2.1443 - val_acc: 0.2500\n",
      "epochs : 851\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4186 - acc: 0.4314 - val_loss: 2.1499 - val_acc: 0.2433\n",
      "epochs : 852\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4179 - acc: 0.4286 - val_loss: 2.1431 - val_acc: 0.2367\n",
      "epochs : 853\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4176 - acc: 0.4200 - val_loss: 2.1627 - val_acc: 0.2367\n",
      "epochs : 854\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4175 - acc: 0.4329 - val_loss: 2.1526 - val_acc: 0.2333\n",
      "epochs : 855\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4164 - acc: 0.4243 - val_loss: 2.1414 - val_acc: 0.2333\n",
      "epochs : 856\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4172 - acc: 0.4257 - val_loss: 2.1393 - val_acc: 0.2300\n",
      "epochs : 857\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4170 - acc: 0.4257 - val_loss: 2.1722 - val_acc: 0.2367\n",
      "epochs : 858\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 183us/step - loss: 1.4177 - acc: 0.4243 - val_loss: 2.1495 - val_acc: 0.2267\n",
      "epochs : 859\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4167 - acc: 0.4171 - val_loss: 2.1621 - val_acc: 0.2400\n",
      "epochs : 860\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4172 - acc: 0.4243 - val_loss: 2.1462 - val_acc: 0.2300\n",
      "epochs : 861\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4168 - acc: 0.4229 - val_loss: 2.1490 - val_acc: 0.2367\n",
      "epochs : 862\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4156 - acc: 0.4300 - val_loss: 2.1511 - val_acc: 0.2433\n",
      "epochs : 863\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4145 - acc: 0.4257 - val_loss: 2.1619 - val_acc: 0.2400\n",
      "epochs : 864\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4169 - acc: 0.4271 - val_loss: 2.1517 - val_acc: 0.2400\n",
      "epochs : 865\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4158 - acc: 0.4329 - val_loss: 2.1498 - val_acc: 0.2500\n",
      "epochs : 866\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4150 - acc: 0.4329 - val_loss: 2.1591 - val_acc: 0.2567\n",
      "epochs : 867\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4154 - acc: 0.4271 - val_loss: 2.1522 - val_acc: 0.2467\n",
      "epochs : 868\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4150 - acc: 0.4257 - val_loss: 2.1465 - val_acc: 0.2500\n",
      "epochs : 869\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4147 - acc: 0.4243 - val_loss: 2.1463 - val_acc: 0.2333\n",
      "epochs : 870\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4152 - acc: 0.4243 - val_loss: 2.1663 - val_acc: 0.2367\n",
      "epochs : 871\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4136 - acc: 0.4271 - val_loss: 2.1470 - val_acc: 0.2367\n",
      "epochs : 872\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4147 - acc: 0.4257 - val_loss: 2.1756 - val_acc: 0.2367\n",
      "epochs : 873\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4149 - acc: 0.4243 - val_loss: 2.1643 - val_acc: 0.2500\n",
      "epochs : 874\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4137 - acc: 0.4286 - val_loss: 2.1567 - val_acc: 0.2400\n",
      "epochs : 875\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4151 - acc: 0.4243 - val_loss: 2.1353 - val_acc: 0.2333\n",
      "epochs : 876\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4136 - acc: 0.4271 - val_loss: 2.1551 - val_acc: 0.2367\n",
      "epochs : 877\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4141 - acc: 0.4229 - val_loss: 2.1494 - val_acc: 0.2367\n",
      "epochs : 878\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4138 - acc: 0.4271 - val_loss: 2.1539 - val_acc: 0.2367\n",
      "epochs : 879\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4116 - acc: 0.4371 - val_loss: 2.1725 - val_acc: 0.2333\n",
      "epochs : 880\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4140 - acc: 0.4229 - val_loss: 2.1541 - val_acc: 0.2333\n",
      "epochs : 881\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4129 - acc: 0.4271 - val_loss: 2.1519 - val_acc: 0.2567\n",
      "epochs : 882\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4125 - acc: 0.4300 - val_loss: 2.1664 - val_acc: 0.2400\n",
      "epochs : 883\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4140 - acc: 0.4271 - val_loss: 2.1847 - val_acc: 0.2333\n",
      "epochs : 884\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4137 - acc: 0.4314 - val_loss: 2.1675 - val_acc: 0.2500\n",
      "epochs : 885\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4128 - acc: 0.4314 - val_loss: 2.1503 - val_acc: 0.2300\n",
      "epochs : 886\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4119 - acc: 0.4300 - val_loss: 2.1561 - val_acc: 0.2333\n",
      "epochs : 887\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4109 - acc: 0.4329 - val_loss: 2.1696 - val_acc: 0.2367\n",
      "epochs : 888\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4117 - acc: 0.4329 - val_loss: 2.1564 - val_acc: 0.2467\n",
      "epochs : 889\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4121 - acc: 0.4286 - val_loss: 2.1579 - val_acc: 0.2333\n",
      "epochs : 890\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4121 - acc: 0.4271 - val_loss: 2.1705 - val_acc: 0.2467\n",
      "epochs : 891\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4110 - acc: 0.4271 - val_loss: 2.1646 - val_acc: 0.2433\n",
      "epochs : 892\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4110 - acc: 0.4229 - val_loss: 2.1677 - val_acc: 0.2367\n",
      "epochs : 893\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4116 - acc: 0.4286 - val_loss: 2.1617 - val_acc: 0.2400\n",
      "epochs : 894\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4120 - acc: 0.4286 - val_loss: 2.1663 - val_acc: 0.2400\n",
      "epochs : 895\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4110 - acc: 0.4371 - val_loss: 2.1484 - val_acc: 0.2333\n",
      "epochs : 896\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4113 - acc: 0.4314 - val_loss: 2.1582 - val_acc: 0.2267\n",
      "epochs : 897\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4115 - acc: 0.4314 - val_loss: 2.1728 - val_acc: 0.2400\n",
      "epochs : 898\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4107 - acc: 0.4300 - val_loss: 2.1674 - val_acc: 0.2533\n",
      "epochs : 899\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4084 - acc: 0.4314 - val_loss: 2.1659 - val_acc: 0.2333\n",
      "epochs : 900\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4119 - acc: 0.4243 - val_loss: 2.1760 - val_acc: 0.2333\n",
      "epochs : 901\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 115us/step - loss: 1.4095 - acc: 0.4329 - val_loss: 2.1581 - val_acc: 0.2400\n",
      "epochs : 902\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4092 - acc: 0.4357 - val_loss: 2.1562 - val_acc: 0.2367\n",
      "epochs : 903\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4095 - acc: 0.4229 - val_loss: 2.1698 - val_acc: 0.2367\n",
      "epochs : 904\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4098 - acc: 0.4286 - val_loss: 2.1690 - val_acc: 0.2433\n",
      "epochs : 905\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4091 - acc: 0.4300 - val_loss: 2.1576 - val_acc: 0.2333\n",
      "epochs : 906\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4090 - acc: 0.4386 - val_loss: 2.1733 - val_acc: 0.2433\n",
      "epochs : 907\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4086 - acc: 0.4343 - val_loss: 2.1715 - val_acc: 0.2400\n",
      "epochs : 908\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4108 - acc: 0.4314 - val_loss: 2.1648 - val_acc: 0.2333\n",
      "epochs : 909\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4091 - acc: 0.4343 - val_loss: 2.1644 - val_acc: 0.2433\n",
      "epochs : 910\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4070 - acc: 0.4300 - val_loss: 2.1840 - val_acc: 0.2533\n",
      "epochs : 911\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4089 - acc: 0.4343 - val_loss: 2.1743 - val_acc: 0.2333\n",
      "epochs : 912\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4096 - acc: 0.4314 - val_loss: 2.1601 - val_acc: 0.2333\n",
      "epochs : 913\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4088 - acc: 0.4271 - val_loss: 2.1715 - val_acc: 0.2333\n",
      "epochs : 914\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4081 - acc: 0.4300 - val_loss: 2.1801 - val_acc: 0.2533\n",
      "epochs : 915\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4071 - acc: 0.4314 - val_loss: 2.1719 - val_acc: 0.2400\n",
      "epochs : 916\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4083 - acc: 0.4329 - val_loss: 2.1840 - val_acc: 0.2467\n",
      "epochs : 917\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4083 - acc: 0.4343 - val_loss: 2.1904 - val_acc: 0.2533\n",
      "epochs : 918\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4092 - acc: 0.4300 - val_loss: 2.1722 - val_acc: 0.2433\n",
      "epochs : 919\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4071 - acc: 0.4243 - val_loss: 2.1693 - val_acc: 0.2400\n",
      "epochs : 920\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4085 - acc: 0.4300 - val_loss: 2.1704 - val_acc: 0.2500\n",
      "epochs : 921\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4074 - acc: 0.4371 - val_loss: 2.1816 - val_acc: 0.2467\n",
      "epochs : 922\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.4288 - acc: 0.416 - 0s 115us/step - loss: 1.4070 - acc: 0.4257 - val_loss: 2.1867 - val_acc: 0.2400\n",
      "epochs : 923\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4083 - acc: 0.4314 - val_loss: 2.1702 - val_acc: 0.2400\n",
      "epochs : 924\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4073 - acc: 0.4257 - val_loss: 2.1725 - val_acc: 0.2400\n",
      "epochs : 925\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4058 - acc: 0.4314 - val_loss: 2.1831 - val_acc: 0.2367\n",
      "epochs : 926\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4082 - acc: 0.4357 - val_loss: 2.1646 - val_acc: 0.2400\n",
      "epochs : 927\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4067 - acc: 0.4271 - val_loss: 2.1715 - val_acc: 0.2467\n",
      "epochs : 928\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4077 - acc: 0.4314 - val_loss: 2.1897 - val_acc: 0.2367\n",
      "epochs : 929\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4059 - acc: 0.4386 - val_loss: 2.1756 - val_acc: 0.2367\n",
      "epochs : 930\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4056 - acc: 0.4257 - val_loss: 2.1770 - val_acc: 0.2400\n",
      "epochs : 931\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4067 - acc: 0.4271 - val_loss: 2.1785 - val_acc: 0.2367\n",
      "epochs : 932\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4065 - acc: 0.4329 - val_loss: 2.1604 - val_acc: 0.2367\n",
      "epochs : 933\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4024 - acc: 0.4286 - val_loss: 2.1743 - val_acc: 0.2367\n",
      "epochs : 934\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4064 - acc: 0.4329 - val_loss: 2.1735 - val_acc: 0.2400\n",
      "epochs : 935\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4049 - acc: 0.4271 - val_loss: 2.1690 - val_acc: 0.2333\n",
      "epochs : 936\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4054 - acc: 0.4286 - val_loss: 2.1608 - val_acc: 0.2367\n",
      "epochs : 937\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4052 - acc: 0.4314 - val_loss: 2.1764 - val_acc: 0.2333\n",
      "epochs : 938\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4057 - acc: 0.4257 - val_loss: 2.1720 - val_acc: 0.2367\n",
      "epochs : 939\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4062 - acc: 0.4357 - val_loss: 2.1752 - val_acc: 0.2400\n",
      "epochs : 940\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4049 - acc: 0.4400 - val_loss: 2.1764 - val_acc: 0.2467\n",
      "epochs : 941\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4050 - acc: 0.4371 - val_loss: 2.1755 - val_acc: 0.2367\n",
      "epochs : 942\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4048 - acc: 0.4314 - val_loss: 2.1777 - val_acc: 0.2433\n",
      "epochs : 943\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4041 - acc: 0.4314 - val_loss: 2.1880 - val_acc: 0.2333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs : 944\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4043 - acc: 0.4386 - val_loss: 2.1833 - val_acc: 0.2333\n",
      "epochs : 945\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4050 - acc: 0.4286 - val_loss: 2.1925 - val_acc: 0.2300\n",
      "epochs : 946\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4036 - acc: 0.4343 - val_loss: 2.1728 - val_acc: 0.2467\n",
      "epochs : 947\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4045 - acc: 0.4271 - val_loss: 2.1723 - val_acc: 0.2333\n",
      "epochs : 948\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4040 - acc: 0.4343 - val_loss: 2.1889 - val_acc: 0.2500\n",
      "epochs : 949\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.4039 - acc: 0.4286 - val_loss: 2.1910 - val_acc: 0.2367\n",
      "epochs : 950\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.4033 - acc: 0.4314 - val_loss: 2.1801 - val_acc: 0.2367\n",
      "epochs : 951\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4045 - acc: 0.4357 - val_loss: 2.1777 - val_acc: 0.2367\n",
      "epochs : 952\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4032 - acc: 0.4257 - val_loss: 2.2068 - val_acc: 0.2400\n",
      "epochs : 953\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4030 - acc: 0.4357 - val_loss: 2.1993 - val_acc: 0.2367\n",
      "epochs : 954\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4027 - acc: 0.4229 - val_loss: 2.1871 - val_acc: 0.2367\n",
      "epochs : 955\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4032 - acc: 0.4357 - val_loss: 2.1919 - val_acc: 0.2367\n",
      "epochs : 956\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4025 - acc: 0.4329 - val_loss: 2.1827 - val_acc: 0.2400\n",
      "epochs : 957\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4026 - acc: 0.4286 - val_loss: 2.2009 - val_acc: 0.2367\n",
      "epochs : 958\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4023 - acc: 0.4314 - val_loss: 2.1834 - val_acc: 0.2467\n",
      "epochs : 959\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4022 - acc: 0.4357 - val_loss: 2.1718 - val_acc: 0.2367\n",
      "epochs : 960\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4021 - acc: 0.4229 - val_loss: 2.1886 - val_acc: 0.2367\n",
      "epochs : 961\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4025 - acc: 0.4386 - val_loss: 2.1887 - val_acc: 0.2433\n",
      "epochs : 962\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4021 - acc: 0.4357 - val_loss: 2.1929 - val_acc: 0.2333\n",
      "epochs : 963\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4030 - acc: 0.4271 - val_loss: 2.1866 - val_acc: 0.2300\n",
      "epochs : 964\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4011 - acc: 0.4386 - val_loss: 2.1978 - val_acc: 0.2333\n",
      "epochs : 965\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4010 - acc: 0.4314 - val_loss: 2.1929 - val_acc: 0.2333\n",
      "epochs : 966\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4017 - acc: 0.4386 - val_loss: 2.1950 - val_acc: 0.2533\n",
      "epochs : 967\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4023 - acc: 0.4343 - val_loss: 2.1834 - val_acc: 0.2333\n",
      "epochs : 968\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4022 - acc: 0.4357 - val_loss: 2.1883 - val_acc: 0.2533\n",
      "epochs : 969\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4014 - acc: 0.4286 - val_loss: 2.1900 - val_acc: 0.2367\n",
      "epochs : 970\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4001 - acc: 0.4300 - val_loss: 2.1850 - val_acc: 0.2400\n",
      "epochs : 971\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4005 - acc: 0.4400 - val_loss: 2.1979 - val_acc: 0.2400\n",
      "epochs : 972\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4004 - acc: 0.4371 - val_loss: 2.1798 - val_acc: 0.2433\n",
      "epochs : 973\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3990 - acc: 0.4429 - val_loss: 2.1904 - val_acc: 0.2533\n",
      "epochs : 974\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4015 - acc: 0.4357 - val_loss: 2.2049 - val_acc: 0.2567\n",
      "epochs : 975\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4013 - acc: 0.4314 - val_loss: 2.1832 - val_acc: 0.2600\n",
      "epochs : 976\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4009 - acc: 0.4357 - val_loss: 2.1824 - val_acc: 0.2433\n",
      "epochs : 977\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4006 - acc: 0.4314 - val_loss: 2.1968 - val_acc: 0.2400\n",
      "epochs : 978\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4002 - acc: 0.4314 - val_loss: 2.1863 - val_acc: 0.2367\n",
      "epochs : 979\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3993 - acc: 0.4371 - val_loss: 2.1786 - val_acc: 0.2433\n",
      "epochs : 980\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4002 - acc: 0.4300 - val_loss: 2.1895 - val_acc: 0.2467\n",
      "epochs : 981\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3997 - acc: 0.4414 - val_loss: 2.1910 - val_acc: 0.2400\n",
      "epochs : 982\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3995 - acc: 0.4357 - val_loss: 2.1916 - val_acc: 0.2467\n",
      "epochs : 983\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3984 - acc: 0.4443 - val_loss: 2.1955 - val_acc: 0.2367\n",
      "epochs : 984\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3975 - acc: 0.4343 - val_loss: 2.1884 - val_acc: 0.2467\n",
      "epochs : 985\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3971 - acc: 0.4314 - val_loss: 2.1966 - val_acc: 0.2367\n",
      "epochs : 986\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 121us/step - loss: 1.4000 - acc: 0.4357 - val_loss: 2.1961 - val_acc: 0.2367\n",
      "epochs : 987\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3997 - acc: 0.4357 - val_loss: 2.1957 - val_acc: 0.2433\n",
      "epochs : 988\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3985 - acc: 0.4314 - val_loss: 2.1971 - val_acc: 0.2333\n",
      "epochs : 989\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3991 - acc: 0.4386 - val_loss: 2.2131 - val_acc: 0.2533\n",
      "epochs : 990\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3985 - acc: 0.4343 - val_loss: 2.2086 - val_acc: 0.2500\n",
      "epochs : 991\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3989 - acc: 0.4243 - val_loss: 2.1836 - val_acc: 0.2400\n",
      "epochs : 992\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3990 - acc: 0.4371 - val_loss: 2.1884 - val_acc: 0.2467\n",
      "epochs : 993\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3989 - acc: 0.4329 - val_loss: 2.1945 - val_acc: 0.2333\n",
      "epochs : 994\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3984 - acc: 0.4371 - val_loss: 2.2104 - val_acc: 0.2433\n",
      "epochs : 995\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3986 - acc: 0.4371 - val_loss: 2.1880 - val_acc: 0.2400\n",
      "epochs : 996\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3986 - acc: 0.4343 - val_loss: 2.1983 - val_acc: 0.2367\n",
      "epochs : 997\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3973 - acc: 0.4371 - val_loss: 2.1992 - val_acc: 0.2433\n",
      "epochs : 998\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3972 - acc: 0.4329 - val_loss: 2.1898 - val_acc: 0.2500\n",
      "epochs : 999\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3961 - acc: 0.4386 - val_loss: 2.1905 - val_acc: 0.2333\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa0AAAEKCAYAAAChTwphAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa6e77aed68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 학습시키기\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "# 1. 데이터셋 준비하기\n",
    "\n",
    "# 훈련셋과 시험셋 로딩\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# 훈련셋과 검증셋 분리\n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "\n",
    "X_train = X_train.reshape(50000, 784).astype('float32') / 255.0\n",
    "X_val = X_val.reshape(10000, 784).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "# 훈련셋, 검증셋 고르기\n",
    "train_rand_idxs = np.random.choice(50000, 700)\n",
    "val_rand_idxs = np.random.choice(10000, 300)\n",
    "\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]\n",
    "\n",
    "# 라벨링 전환\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_val = np_utils.to_categorical(Y_val)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# 3. 모델 엮기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "\n",
    "custom_hist = CustomHistory()\n",
    "custom_hist.init()\n",
    "\n",
    "for epoch_idx in range(1000):\n",
    "    print ('epochs : ' + str(epoch_idx) )\n",
    "    model.fit(X_train, Y_train, epochs=1, batch_size=10, validation_data=(X_val, Y_val), callbacks=[custom_hist])\n",
    "\n",
    "# 5. 모델 학습 과정 표시하기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(custom_hist.losses, 'y', label='train loss')\n",
    "loss_ax.plot(custom_hist.vol_losses, 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(custom_hist.accs, 'b', label='train acc')\n",
    "acc_ax.plot(custom_hist.vol_accs, 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
